; NOTE: Assertions have been autogenerated by utils/update_analyze_test_checks.py
; RUN: opt < %s -cost-model -cost-kind=latency -analyze -mtriple=tpc -mcpu=goya2 | FileCheck %s --check-prefix=LATENCY
; XFAIL: *
target datalayout = "e-p0:32:32:32-p1:32:32:32-p2:32:32:32-p3:64:64:64-i32:32:32-n8:16:32-f16:16:16-f32:32:32-v160:32:32-v256:2048:2048-v2048:2048:2048-v4096:2048:2048-v8192:2048:2048"
target triple = "tpc"


; Function Attrs: nounwind
define dso_local void @main(i32 %aboveZeroScale, i32 %belowZeroScale) local_unnamed_addr #0 {
; LATENCY-LABEL: 'main'
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %0 = tail call <5 x i32> @llvm.tpc.get.index.space.offset()
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %1 = tail call <5 x i32> @llvm.tpc.get.index.space.size()
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %add = add <5 x i32> %1, %0
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %vecext = extractelement <5 x i32> %0, i32 0
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %mul = shl nsw i32 %vecext, 7
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %vecext1 = extractelement <5 x i32> %add, i32 0
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %mul2 = shl nsw i32 %vecext1, 7
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %cmp64 = icmp slt i32 %mul, %mul2
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 1 for instruction: br i1 %cmp64, label %for.body.preheader, label %for.cond.cleanup
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 1 for instruction: br label %for.body
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 1 for instruction: br label %for.cond.cleanup
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 1 for instruction: ret void
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %d.066 = phi i32 [ %add3, %for.body ], [ %mul, %for.body.preheader ]
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %ifmCoords.065 = phi <5 x i32> [ %vecins, %for.body ], [ zeroinitializer, %for.body.preheader ]
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %2 = tail call <64 x float> @llvm.tpc.ld.tnsr.v64f32.i1(<5 x i32> %ifmCoords.065, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %add3 = add nsw i32 %d.066, 128
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %vecins = insertelement <5 x i32> %ifmCoords.065, i32 %add3, i32 1
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %3 = tail call <64 x float> @llvm.tpc.ld.tnsr.v64f32.i1(<5 x i32> %vecins, i8 1, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 6 for instruction: %4 = tail call <64 x float> @llvm.tpc.add.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %3, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 6 for instruction: %5 = tail call <64 x float> @llvm.tpc.sub.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %4, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 6 for instruction: %6 = tail call <64 x float> @llvm.tpc.mul.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %5, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %7 = tail call <64 x float> @llvm.tpc.or.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %6, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %8 = tail call <64 x float> @llvm.tpc.xor.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %7, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %9 = tail call <64 x float> @llvm.tpc.and.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %8, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %add4 = fadd <64 x float> %2, %9
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %sub = fsub <64 x float> %add4, %2
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %mul5 = fmul <64 x float> %2, %sub
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %10 = tail call <64 x float> @llvm.tpc.not.v64f32.v64f32.i1(<64 x float> %mul5, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %11 = tail call <64 x float> @llvm.tpc.sel.eq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %10, <64 x float> %2, <64 x float> %10, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %12 = tail call <64 x float> @llvm.tpc.sel.neq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %11, <64 x float> %2, <64 x float> %11, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %13 = tail call <64 x float> @llvm.tpc.sel.less.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %12, <64 x float> %2, <64 x float> %12, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %14 = tail call <64 x float> @llvm.tpc.sel.grt.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %13, <64 x float> %2, <64 x float> %13, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %15 = tail call <64 x float> @llvm.tpc.sel.geq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %14, <64 x float> %2, <64 x float> %14, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 2 for instruction: tail call void @llvm.tpc.st.tnsr.v64f32(<5 x i32> %vecins, i8 2, <64 x float> %15, i32 0, i1 true, i1 false)
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 4 for instruction: %cmp = icmp slt i32 %add3, %mul2
; LATENCY-NEXT:  Cost Model: Found an estimated cost of 1 for instruction: br i1 %cmp, label %for.body, label %for.cond.cleanup.loopexit, !llvm.loop !3
;
entry:
  %0 = tail call <5 x i32> @llvm.tpc.get.index.space.offset()
  %1 = tail call <5 x i32> @llvm.tpc.get.index.space.size()
  %add = add <5 x i32> %1, %0
  %vecext = extractelement <5 x i32> %0, i32 0
  %mul = shl nsw i32 %vecext, 7
  %vecext1 = extractelement <5 x i32> %add, i32 0
  %mul2 = shl nsw i32 %vecext1, 7
  %cmp64 = icmp slt i32 %mul, %mul2
  br i1 %cmp64, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %entry
  br label %for.body

for.cond.cleanup.loopexit:                        ; preds = %for.body
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %entry
  ret void

for.body:                                         ; preds = %for.body.preheader, %for.body
  %d.066 = phi i32 [ %add3, %for.body ], [ %mul, %for.body.preheader ]
  %ifmCoords.065 = phi <5 x i32> [ %vecins, %for.body ], [ zeroinitializer, %for.body.preheader ]
  %2 = tail call <64 x float> @llvm.tpc.ld.tnsr.v64f32.i1(<5 x i32> %ifmCoords.065, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %add3 = add nsw i32 %d.066, 128
  %vecins = insertelement <5 x i32> %ifmCoords.065, i32 %add3, i32 1
  %3 = tail call <64 x float> @llvm.tpc.ld.tnsr.v64f32.i1(<5 x i32> %vecins, i8 1, i32 0, <64 x float> undef, i1 true, i1 false)
  %4 = tail call <64 x float> @llvm.tpc.add.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %3, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %5 = tail call <64 x float> @llvm.tpc.sub.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %4, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %6 = tail call <64 x float> @llvm.tpc.mul.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %5, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %7 = tail call <64 x float> @llvm.tpc.or.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %6, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %8 = tail call <64 x float> @llvm.tpc.xor.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %7, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %9 = tail call <64 x float> @llvm.tpc.and.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %8, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %add4 = fadd <64 x float> %2, %9
  %sub = fsub <64 x float> %add4, %2
  %mul5 = fmul <64 x float> %2, %sub
  %10 = tail call <64 x float> @llvm.tpc.not.v64f32.v64f32.i1(<64 x float> %mul5, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %11 = tail call <64 x float> @llvm.tpc.sel.eq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %10, <64 x float> %2, <64 x float> %10, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %12 = tail call <64 x float> @llvm.tpc.sel.neq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %11, <64 x float> %2, <64 x float> %11, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %13 = tail call <64 x float> @llvm.tpc.sel.less.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %12, <64 x float> %2, <64 x float> %12, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %14 = tail call <64 x float> @llvm.tpc.sel.grt.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %13, <64 x float> %2, <64 x float> %13, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  %15 = tail call <64 x float> @llvm.tpc.sel.geq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float> %2, <64 x float> %14, <64 x float> %2, <64 x float> %14, i8 0, i32 0, <64 x float> undef, i1 true, i1 false)
  tail call void @llvm.tpc.st.tnsr.v64f32(<5 x i32> %vecins, i8 2, <64 x float> %15, i32 0, i1 true, i1 false)
  %cmp = icmp slt i32 %add3, %mul2
  br i1 %cmp, label %for.body, label %for.cond.cleanup.loopexit, !llvm.loop !3
}

; Function Attrs: nounwind readnone
declare <5 x i32> @llvm.tpc.get.index.space.offset() #1

; Function Attrs: nounwind readnone
declare <5 x i32> @llvm.tpc.get.index.space.size() #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.ld.tnsr.v64f32.i1(<5 x i32>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.add.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.sub.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.mul.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.or.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.xor.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.and.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.not.v64f32.v64f32.i1(<64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.sel.eq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, <64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.sel.neq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, <64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.sel.less.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, <64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.sel.grt.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, <64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind readnone
declare <64 x float> @llvm.tpc.sel.geq.v64f32.v64f32.v64f32.v64f32.v64f32.i1(<64 x float>, <64 x float>, <64 x float>, <64 x float>, i8, i32, <64 x float>, i1, i1) #1

; Function Attrs: nounwind writeonly
declare void @llvm.tpc.st.tnsr.v64f32(<5 x i32>, i8, <64 x float>, i32, i1, i1) #2

attributes #0 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="goya" "target-features"="+dali" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind readnone }
attributes #2 = { nounwind writeonly }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}
!llvm.tpc.scalar_data = !{!2}
!llvm.tpc.vector_data = !{!2}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 7.0.0 (ssh://gerrit:29418/tpc_clang2 80a0a209e04a31e8f0eacc32134ef0a097b5a0c3) (ssh://gerrit:29418/tpc_llvm2 5b9e5d49b2c4f6c56e3964480dbfd179180d341b)"}
!2 = !{i32 0}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.taken", i1 true}
