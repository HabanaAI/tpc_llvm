//===----------------------------------------------------------------------===//
//
//===----------------------------------------------------------------------===//
//
// This contains code to emit Builtin calls as LLVM code.
//
//===----------------------------------------------------------------------===//

#include "CodeGenFunction.h"
#include "clang/AST/Attr.h"
#include "clang/AST/ASTContext.h"
#include "clang/AST/Decl.h"
#include "clang/Basic/TargetBuiltins.h"
#include "llvm/IR/Intrinsics.h"
#include "llvm/IR/IntrinsicsTPC.h"
#include "../lib/Target/TPC/MCTargetDesc/InstructionDB.h"

#ifdef LLVM_TPC_COMPILER
#include "llvm/Target/TPCClangInfo.h"
#endif //LLVM_TPC_COMPILER

#include <map>

using namespace clang;
using namespace CodeGen;
using namespace llvm;

static Value *emitAutogeneratedIntrinsic(CodeGenFunction *CGF, unsigned BuiltinID,
                                         const CallExpr *E,
                                         ReturnValueSlot ReturnValue,
                                         llvm::Triple::ArchType Arch);


static const int32_t Mask64_0[64] = {
   0,  1,  2,  3,  4,  5,  6,  7,
   8,  9, 10, 11, 12, 13, 14, 15,
  16, 17, 18, 19, 20, 21, 22, 23,
  24, 25, 26, 27, 28, 29, 30, 31,
  32, 33, 34, 35, 36, 37, 38, 39,
  40, 41, 42, 43, 44, 45, 46, 47,
  48, 49, 50, 51, 52, 53, 54, 55,
  56, 57, 58, 59, 60, 61, 62, 63
};
static const int32_t Mask64_1[64] = {
   64,  65,  66,  67,  68,  69,  70,  71,
   72,  73,  74,  75,  76,  77,  78,  79,
   80,  81,  82,  83,  84,  85,  86,  87,
   88,  89,  90,  91,  92,  93,  94,  95,
   96,  97,  98,  99, 100, 101, 102, 103,
  104, 105, 106, 107, 108, 109, 110, 111,
  112, 113, 114, 115, 116, 117, 118, 119,
  120, 121, 122, 123, 124, 125, 126, 127
};
static const int32_t Mask64_2[64] = {
  128, 129, 130, 131, 132, 133, 134, 135,
  136, 137, 138, 139, 140, 141, 142, 143,
  144, 145, 146, 147, 148, 149, 150, 151,
  152, 153, 154, 155, 156, 157, 158, 159,
  160, 161, 162, 163, 164, 165, 166, 167,
  168, 169, 170, 171, 172, 173, 174, 175,
  176, 177, 178, 179, 180, 181, 182, 183,
  184, 185, 186, 187, 188, 189, 190, 191
};
static const int32_t Mask64_3[64] = {
  192, 193, 194, 195, 196, 197, 198, 199,
  200, 201, 202, 203, 204, 205, 206, 207,
  208, 209, 210, 211, 212, 213, 214, 215,
  216, 217, 218, 219, 220, 221, 222, 223,
  224, 225, 226, 227, 228, 229, 230, 231,
  232, 233, 234, 235, 236, 237, 238, 239,
  240, 241, 242, 243, 244, 245, 246, 247,
  248, 249, 250, 251, 252, 253, 254, 255
};
static const int32_t Mask128_0[128] = {
  0,   1,   2,   3,   4,   5,   6,   7,
  8,   9,   10,  11,  12,  13,  14,  15,
  16,  17,  18,  19,  20,  21,  22,  23,
  24,  25,  26,  27,  28,  29,  30,  31,
  32,  33,  34,  35,  36,  37,  38,  39,
  40,  41,  42,  43,  44,  45,  46,  47,
  48,  49,  50,  51,  52,  53,  54,  55,
  56,  57,  58,  59,  60,  61,  62,  63,
  64,  65,  66,  67,  68,  69,  70,  71,
  72,  73,  74,  75,  76,  77,  78,  79,
  80,  81,  82,  83,  84,  85,  86,  87,
  88,  89,  90,  91,  92,  93,  94,  95,
  96,  97,  98,  99,  100, 101, 102, 103,
  104, 105, 106, 107, 108, 109, 110, 111,
  112, 113, 114, 115, 116, 117, 118, 119,
  120, 121, 122, 123, 124, 125, 126, 127
};
static const int32_t Mask128_1[128] = {
  128, 129, 130, 131, 132, 133, 134, 135,
  136, 137, 138, 139, 140, 141, 142, 143,
  144, 145, 146, 147, 148, 149, 150, 151,
  152, 153, 154, 155, 156, 157, 158, 159,
  160, 161, 162, 163, 164, 165, 166, 167,
  168, 169, 170, 171, 172, 173, 174, 175,
  176, 177, 178, 179, 180, 181, 182, 183,
  184, 185, 186, 187, 188, 189, 190, 191,
  192, 193, 194, 195, 196, 197, 198, 199,
  200, 201, 202, 203, 204, 205, 206, 207,
  208, 209, 210, 211, 212, 213, 214, 215,
  216, 217, 218, 219, 220, 221, 222, 223,
  224, 225, 226, 227, 228, 229, 230, 231,
  232, 233, 234, 235, 236, 237, 238, 239,
  240, 241, 242, 243, 244, 245, 246, 247,
  248, 249, 250, 251, 252, 253, 254, 255
};

static const int32_t Mask256_0[256] = {
  0,   1,   2,   3,   4,   5,   6,   7,
  8,   9,   10,  11,  12,  13,  14,  15,
  16,  17,  18,  19,  20,  21,  22,  23,
  24,  25,  26,  27,  28,  29,  30,  31,
  32,  33,  34,  35,  36,  37,  38,  39,
  40,  41,  42,  43,  44,  45,  46,  47,
  48,  49,  50,  51,  52,  53,  54,  55,
  56,  57,  58,  59,  60,  61,  62,  63,
  64,  65,  66,  67,  68,  69,  70,  71,
  72,  73,  74,  75,  76,  77,  78,  79,
  80,  81,  82,  83,  84,  85,  86,  87,
  88,  89,  90,  91,  92,  93,  94,  95,
  96,  97,  98,  99,  100, 101, 102, 103,
  104, 105, 106, 107, 108, 109, 110, 111,
  112, 113, 114, 115, 116, 117, 118, 119,
  120, 121, 122, 123, 124, 125, 126, 127,
  128, 129, 130, 131, 132, 133, 134, 135,
  136, 137, 138, 139, 140, 141, 142, 143,
  144, 145, 146, 147, 148, 149, 150, 151,
  152, 153, 154, 155, 156, 157, 158, 159,
  160, 161, 162, 163, 164, 165, 166, 167,
  168, 169, 170, 171, 172, 173, 174, 175,
  176, 177, 178, 179, 180, 181, 182, 183,
  184, 185, 186, 187, 188, 189, 190, 191,
  192, 193, 194, 195, 196, 197, 198, 199,
  200, 201, 202, 203, 204, 205, 206, 207,
  208, 209, 210, 211, 212, 213, 214, 215,
  216, 217, 218, 219, 220, 221, 222, 223,
  224, 225, 226, 227, 228, 229, 230, 231,
  232, 233, 234, 235, 236, 237, 238, 239,
  240, 241, 242, 243, 244, 245, 246, 247,
  248, 249, 250, 251, 252, 253, 254, 255
};

static const int32_t Mask256_1[256] = {
  256, 257, 258, 259, 260, 261, 262, 263,
  264, 265, 266, 267, 268, 269, 270, 271,
  272, 273, 274, 275, 276, 277, 278, 279,
  280, 281, 282, 283, 284, 285, 286, 287,
  288, 289, 290, 291, 292, 293, 294, 295,
  296, 297, 298, 299, 300, 301, 302, 303,
  304, 305, 306, 307, 308, 309, 310, 311,
  312, 313, 314, 315, 316, 317, 318, 319,
  320, 321, 322, 323, 324, 325, 326, 327,
  328, 329, 330, 331, 332, 333, 334, 335,
  336, 337, 338, 339, 340, 341, 342, 343,
  344, 345, 346, 347, 348, 349, 350, 351,
  352, 353, 354, 355, 356, 357, 358, 359,
  360, 361, 362, 363, 364, 365, 366, 367,
  368, 369, 370, 371, 372, 373, 374, 375,
  376, 377, 378, 379, 380, 381, 382, 383,
  384, 385, 386, 387, 388, 389, 390, 391,
  392, 393, 394, 395, 396, 397, 398, 399,
  400, 401, 402, 403, 404, 405, 406, 407,
  408, 409, 410, 411, 412, 413, 414, 415,
  416, 417, 418, 419, 420, 421, 422, 423,
  424, 425, 426, 427, 428, 429, 430, 431,
  432, 433, 434, 435, 436, 437, 438, 439,
  440, 441, 442, 443, 444, 445, 446, 447,
  448, 449, 450, 451, 452, 453, 454, 455,
  456, 457, 458, 459, 460, 461, 462, 463,
  464, 465, 466, 467, 468, 469, 470, 471,
  472, 473, 474, 475, 476, 477, 478, 479,
  480, 481, 482, 483, 484, 485, 486, 487,
  488, 489, 490, 491, 492, 493, 494, 495,
  496, 497, 498, 499, 500, 501, 502, 503,
  504, 505, 506, 507, 508, 509, 510, 511
};

static llvm::Value *getStructFieldFromQuadRegister(CodeGenFunction &CGF,
                                                   llvm::Type *ResultTy, llvm::Value *V) {
  llvm::Type *InputType = V->getType();
  assert(cast<llvm::FixedVectorType>(InputType)->getNumElements() == 256);
  llvm::Value *UV = llvm::UndefValue::get(InputType);
  llvm::Value *Field0 = CGF.Builder.CreateShuffleVector(V, UV, Mask64_0);
  llvm::Value *Field1 = CGF.Builder.CreateShuffleVector(V, UV, Mask64_1);
  llvm::Value *Field2 = CGF.Builder.CreateShuffleVector(V, UV, Mask64_2);
  llvm::Value *Field3 = CGF.Builder.CreateShuffleVector(V, UV, Mask64_3);

  llvm::Value *StructU = llvm::UndefValue::get(ResultTy);
  llvm::Value *Struct0 = CGF.Builder.CreateInsertValue(StructU, Field0, 0ULL);
  llvm::Value *Struct1 = CGF.Builder.CreateInsertValue(Struct0, Field1, 1ULL);
  llvm::Value *Struct2 = CGF.Builder.CreateInsertValue(Struct1, Field2, 2ULL);
  llvm::Value *Struct3 = CGF.Builder.CreateInsertValue(Struct2, Field3, 3ULL);

  return Struct3;
}

static llvm::Value *getStructFieldFromDoubleRegister(CodeGenFunction &CGF,
                                                     llvm::Type *ResultTy, llvm::Value *V) {
  auto *InputType = cast<llvm::FixedVectorType>(V->getType());
  llvm::Type *EltType = InputType->getElementType();
  unsigned NumElements = InputType->getNumElements();
  unsigned ElementSize = EltType->getScalarSizeInBits();
  (void)NumElements;
  assert(NumElements * ElementSize == 2 * 64 * 32);
  llvm::Value *UV = llvm::UndefValue::get(InputType);
  ArrayRef<int32_t> Mask0, Mask1;
  switch (ElementSize) {
  case 32:
    Mask0 = ArrayRef<int32_t>(Mask64_0);
    Mask1 = ArrayRef<int32_t>(Mask64_1);
    break;
  case 16:
    Mask0 = ArrayRef<int32_t>(Mask128_0);
    Mask1 = ArrayRef<int32_t>(Mask128_1);
    break;
  case 8:
    Mask0 = ArrayRef<int32_t>(Mask256_0);
    Mask1 = ArrayRef<int32_t>(Mask256_1);
    break;
  default:
    llvm_unreachable("Unsupported element size");
  }
  llvm::Value *Field0 = CGF.Builder.CreateShuffleVector(V, UV, Mask0);
  llvm::Value *Field1 = CGF.Builder.CreateShuffleVector(V, UV, Mask1);

  llvm::StructType *StTy = cast<llvm::StructType>(ResultTy);
  if (StTy->getContainedType(0) != Field0->getType()) {
    Field0 = CGF.Builder.CreateBitCast(Field0, StTy->getContainedType(0));
  }
  if (StTy->getContainedType(1) != Field1->getType()) {
    Field1 = CGF.Builder.CreateBitCast(Field1, StTy->getContainedType(1));
  }

  llvm::Value *StructU = llvm::UndefValue::get(ResultTy);
  llvm::Value *Struct0 = CGF.Builder.CreateInsertValue(StructU, Field0, 0ULL);
  llvm::Value *Struct1 = CGF.Builder.CreateInsertValue(Struct0, Field1, 1ULL);

  return Struct1;
}

static llvm::Value *getStructFieldFromDoubleScalarRegister(CodeGenFunction &CGF,
                                                           llvm::Type *ResultTy, llvm::Value *V) {
  auto *InputType = cast<llvm::FixedVectorType>(V->getType());
  (void)InputType;
  assert(InputType->getNumElements() == 2);
  llvm::StructType *StTy = cast<llvm::StructType>(ResultTy);
  assert(StTy->getNumElements() == 2);

  llvm::Value *Field0 = CGF.Builder.CreateExtractElement(V, CGF.Builder.getInt32(0));
  llvm::Value *Field1 = CGF.Builder.CreateExtractElement(V, CGF.Builder.getInt32(1));

  if (StTy->getContainedType(0) != Field0->getType()) {
    Field0 = CGF.Builder.CreateTruncOrBitCast(Field0, StTy->getContainedType(0));
  }
  if (StTy->getContainedType(1) != Field1->getType()) {
    Field1 = CGF.Builder.CreateTruncOrBitCast(Field1, StTy->getContainedType(1));
  }

  llvm::Value *StructU = llvm::UndefValue::get(ResultTy);
  llvm::Value *Struct0 = CGF.Builder.CreateInsertValue(StructU, Field0, 0U);
  llvm::Value *Struct1 = CGF.Builder.CreateInsertValue(Struct0, Field1, 1U);

  return Struct1;
}


static llvm::TPCII::OpType getOptypeValue(QualType Ty) {
  BuiltinType::Kind kind;
  if (auto BT = Ty->getAs<BuiltinType>()) {
    kind = BT->getKind();
  } else if (auto VT = Ty->getAs<clang::VectorType>()) {
    //bool256 processing
    if (32 == VT->getNumElements())
      kind = BuiltinType::Bool;
    else
      kind = VT->getElementType()->getAs<BuiltinType>()->getKind();
  } else if (const RecordType * ST = Ty->getAs<clang::RecordType>()) {
    auto FT = ST->getDecl()->field_begin()->getType();
    if(auto BT = FT->getAs<BuiltinType>()) {
      // v2i32
      kind = BT->getKind();
    } else {
      kind =  FT->getAs<clang::VectorType>()->getElementType()->getAs<BuiltinType>()->getKind();
    }
  } else {
    llvm_unreachable("Unexpected type");
  }
//V32c
  switch (kind) {
  case BuiltinType::Float:      return TPCII::OpType::FP32;
  case BuiltinType::BFloat16:   return TPCII::OpType::BF16;
  case BuiltinType::Float8_152: return TPCII::OpType::FP8_152;
  case BuiltinType::Float8_143: return TPCII::OpType::FP8_143;
  case BuiltinType::Char_S:     return TPCII::OpType::INT8;
  case BuiltinType::Short:      return TPCII::OpType::INT16;
  case BuiltinType::Int:        return TPCII::OpType::INT32;
  case BuiltinType::UChar:      return TPCII::OpType::UINT8;
  case BuiltinType::UShort:     return TPCII::OpType::UINT16;
  case BuiltinType::UInt:       return TPCII::OpType::UINT32;
  case BuiltinType::Half:       return TPCII::OpType::FP16;
  case BuiltinType::Bool:       return TPCII::OpType::BOOL;
  default:
    llvm_unreachable("Unexpected type");
  }
}


/// Checks if an instruction with the gived predicate and polarity always
/// executes.
static bool isUnconditional(Value *Predicate, Value *Polarity) {
  // Polarity is always constant.
  auto CPol = cast<ConstantInt>(Polarity);
  if (auto CPr = dyn_cast<ConstantInt>(Predicate))
    return (!CPol->getLimitedValue() && CPr->getLimitedValue()) ||
    (CPol->getLimitedValue() && !CPr->getLimitedValue());
  return false;
}


static llvm::Type *getIRType(CodeGenFunction *CGF, QualType T, unsigned &Multiplicity) {
  Multiplicity = 0;
  if (auto *STy = T.getCanonicalType()->getAs<RecordType>()) {
    // Assume that the number of elements in the structure is same as long vector
    // multiplicity.
    QualType ElementTy;
    llvm::Type *ElTy = nullptr;
    unsigned ElementSize = 0;
    for (const Decl *D : STy->getDecl()->fields()) {
      const auto *FD = cast<FieldDecl>(D);
      assert(FD->getType()->isIntegerType() || FD->getType()->isVectorType());
      if (ElementTy.isNull()) {
        ElementTy = FD->getType();
        ElTy = CGF->ConvertType(ElementTy);
        ElementSize = ElTy->getPrimitiveSizeInBits();
      } else {
        llvm::Type *ItemTy = CGF->ConvertType(FD->getType());
        assert(ItemTy->getPrimitiveSizeInBits() == ElementSize);
      }
      ++Multiplicity;
    }
    assert(Multiplicity == 2 || Multiplicity == 4);
    if (auto VTy = dyn_cast<llvm::FixedVectorType>(ElTy))
      return llvm::FixedVectorType::get(VTy->getElementType(),
                                   Multiplicity * VTy->getNumElements());
    return llvm::FixedVectorType::get(ElTy, Multiplicity);
  }
  return CGF->ConvertType(T.getCanonicalType());
}


static unsigned getSwitchForDestination(llvm::TPCII::OpType Ty) {
  switch (Ty) {
  case TPCII::OpType::FP32: return TPCII::SW_TO_FP32;
  case TPCII::OpType::BF16: return TPCII::SW_TO_BF16;
  case TPCII::OpType::FP16: return TPCII::SW_TO_FP16;
  case TPCII::OpType::INT32: return TPCII::SW_TO_INT32;
  case TPCII::OpType::UINT32: return TPCII::SW_TO_UINT32;
  case TPCII::OpType::INT16: return TPCII::SW_TO_INT16;
  case TPCII::OpType::UINT16: return TPCII::SW_TO_UINT16;
  case TPCII::OpType::INT8: return TPCII::SW_TO_INT8;
  case TPCII::OpType::UINT8: return TPCII::SW_TO_UINT8;
  case TPCII::OpType::FP8_143: return TPCII::SW_TO_FP8_143;
  case TPCII::OpType::FP8_152: return TPCII::SW_TO_FP8_152;
  default:
    llvm_unreachable("Unknown target type in CONVERT");
  }
}


static llvm::Value *emitPredicate(CodeGenFunction *CGF, const Expr *Pred) {
  if (Pred->getType()->isVectorType()) {
    unsigned NumElements = Pred->getType()->getAs<clang::VectorType>()->getNumElements();
    (void)NumElements;
    assert(NumElements == 32 || NumElements == 16 || NumElements == 8);
    assert(Pred->getType()->getAs<clang::VectorType>()->getElementType()->isUnsignedIntegerType());
    assert(Pred->getType()->getAs<clang::VectorType>()->getElementType()->isCharType());
    llvm::Value *V = CGF->EmitScalarExpr(Pred);
    assert(cast<llvm::FixedVectorType>(V->getType())->getElementType()->getIntegerBitWidth() == 1);
    if (cast<llvm::FixedVectorType>(V->getType())->getElementCount().getValue() == 256)
      return V;
    static llvm::Type *VectorPredicateType =
      llvm::FixedVectorType::get(llvm::Type::getInt1Ty(CGF->getLLVMContext()), 256);
    return CGF->Builder.CreateBitCast(V, VectorPredicateType);
  }

  return CGF->EvaluateExprAsBool(Pred);
}


static Value *emitOperand(CodeGenFunction *CGF, const Expr *E) {
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);

  if (Multiplicity) {
    LValue IncomeLV = CGF->EmitAggExprToLValue(E);
    Value *Ptr = IncomeLV.getPointer(*CGF);
    Ptr = CGF->Builder.CreateBitOrPointerCast(Ptr, llvm::PointerType::get(ResultTy, 0));
    return CGF->Builder.CreateAlignedLoad(Ptr, CharUnits::fromQuantity(256));
  }

  return CGF->EmitScalarExpr(E);
}


static unsigned translateGen1RoundingMode(unsigned Switches) {
  unsigned RM = Switches & TPCII::SW_GROUP_RM;
  switch (RM) {
  case TPCII::SW_RHNE:
    RM = TPCII::SW_G1_RHNE;
    break;
  case TPCII::SW_RD:
    RM = TPCII::SW_G1_RD;
    break;
  case TPCII::SW_RU:
    RM = TPCII::SW_G1_RU;
    break;
  case TPCII::SW_SR:
    RM = TPCII::SW_G1_SR;
    break;
  case TPCII::SW_RZ:
    RM = TPCII::SW_G1_RZ;
    break;
  case TPCII::SW_CSR:
    break;
  default:
    llvm_unreachable("Unsupported rounding mode");
  }
  Switches &= ~TPCII::SW_GROUP_RM;
  return Switches | RM;
}

static Value *prepareResult(CodeGenFunction *CGF, ReturnValueSlot ReturnValue,
                            Value *Result, unsigned Multiplicity,
                            llvm::Type *FEResultTy) {
  if (Multiplicity == 0)
    return Result;
  else if (Multiplicity == 2)
    Result = getStructFieldFromDoubleRegister(*CGF, FEResultTy, Result);
  else if (Multiplicity == 4)
    Result = getStructFieldFromQuadRegister(*CGF, FEResultTy, Result);
  else
    llvm_unreachable("Unexpected result multiplicity");

  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;

}

//------------------------------------------------------------------------------
// Builtin call emitters.
//------------------------------------------------------------------------------

static Value *emit_INT_CONVERT_TO(CodeGenFunction *CGF, unsigned BuiltinID,
                                  const CallExpr *E,
                                  ReturnValueSlot ReturnValue,
                                  llvm::Triple::ArchType Arch, bool IsUnsigned) {
  const unsigned ArgOpNum = 0;
  const unsigned ShiftOpNum = 1;
  const unsigned OptionsOpNum = 2;
  const unsigned AllowedSwitches = TPCII::SW_LINEAR;

  const Expr *Src = E->getArg(ArgOpNum);
  QualType SrcElementType = Src->getType();
  if (SrcElementType->isRecordType())
    SrcElementType = SrcElementType->getAs<RecordType>()
                         ->getDecl()
                         ->field_begin()
                         ->getType();
  if (SrcElementType->isVectorType())
    SrcElementType =
        SrcElementType->getAs<clang::VectorType>()->getElementType();
  unsigned SrcMultiplicity;
  llvm::Type *SrcTy = getIRType(CGF, Src->getType(), SrcMultiplicity);

  QualType DestElementType = E->getType();
  if (DestElementType->isRecordType())
    DestElementType = DestElementType->getAs<RecordType>()
                          ->getDecl()
                          ->field_begin()
                          ->getType();
  if (DestElementType->isVectorType())
    DestElementType =
        DestElementType->getAs<clang::VectorType>()->getElementType();
  unsigned DestMultiplicity;
  llvm::Type *DestTy = getIRType(CGF, E->getType(), DestMultiplicity);
  llvm::Type *FEDestTy =
      DestMultiplicity ? CGF->ConvertType(E->getType()) : DestTy;

  auto SrcVectTy = cast<FixedVectorType>(SrcTy);
  auto DestVectTy = cast<FixedVectorType>(DestTy);
  assert(SrcVectTy->getNumElements() == DestVectTy->getNumElements());

  llvm::Type *SrcElTy = SrcVectTy->getElementType();
  llvm::Type *DestElTy = DestVectTy->getElementType();

  // Determine switches. We use them when the convertion cannot be represented
  // by regular IR nodes.
  Value *Shift = CGF->EmitScalarExpr(E->getArg(ShiftOpNum));

  // Get specified switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(OptionsOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R);
  (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  const unsigned Options = SwitchVal;

  // Check if the switchset contains only allowed switches.
  assert((SwitchVal & ~AllowedSwitches) == 0);

  // Add target type specification to the switchset.
  llvm::TPCII::OpType TargetDT = getOptypeValue(E->getType());
  SwitchVal |= getSwitchForDestination(TargetDT);

  Value *SrcVal = emitOperand(CGF, Src);
  Value *Result = nullptr;

  // 'convert_to_*' may be mapped to llvm IR node only if size of elements are
  // equal, otherwise native conversion would produce swizzled order, while
  // the regular IR nodes expect linear one.
  // Also the conversion must not produce overflow, as the regular nodes in such
  // case produce undefined behavior. So, only conversions to floats of the same
  // length and default rounding are allowed.
  if (Options == 0) {
    if (SrcElTy->isIntegerTy() && DestElTy->isFloatingPointTy() &&
        SrcElTy->getPrimitiveSizeInBits() ==
            DestElTy->getPrimitiveSizeInBits()) {
      if (SrcElementType->isUnsignedIntegerType())
        Result = CGF->Builder.CreateUIToFP(SrcVal, DestTy);
      else
        Result = CGF->Builder.CreateSIToFP(SrcVal, DestTy);
    }
  }

  // If we cannot use LLVM IR node, call conversion intrinsic.
  if (!Result) {
    auto *BitTy = llvm::IntegerType::get(CGF->getLLVMContext(), 1);
    unsigned IID = (SwitchVal & TPCII::SW_LINEAR)? 
                         Intrinsic::tpc_convert_int_linear
                       : Intrinsic::tpc_convert_int;
    if (IsUnsigned) {
     IID = (SwitchVal & TPCII::SW_LINEAR)
                         ? Intrinsic::tpc_convert_uint_linear
                         : Intrinsic::tpc_convert_uint;
    }
    SwitchVal &= ~TPCII::SW_LINEAR;
    Function *Callee =
        CGF->CGM.getIntrinsic(IID, {DestTy, SrcTy, Shift->getType(), BitTy});
    SmallVector<llvm::Value *, 6> Args;
    Args.push_back(SrcVal);
    Args.push_back(Shift);
    Args.push_back(llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));
    Args.push_back(UndefValue::get(DestTy));
    Args.push_back(llvm::ConstantInt::get(BitTy, 1));
    Args.push_back(llvm::ConstantInt::get(BitTy, 0));

    Result = CGF->Builder.CreateCall(Callee, Args);
    assert(Result);
  }

  return prepareResult(CGF, ReturnValue, Result, DestMultiplicity, FEDestTy);
}



static Value *emit_CONVERT_TO(CodeGenFunction *CGF, unsigned BuiltinID,
                              const CallExpr *E, ReturnValueSlot ReturnValue,
                              llvm::Triple::ArchType Arch) {
  const unsigned ArgOpNum = 0;
  const unsigned OptionsOpNum = 1;
  const unsigned AllowedSwitches = TPCII::SW_GROUP_RM | TPCII::SW_LINEAR;

  const Expr *Src = E->getArg(ArgOpNum);
  QualType SrcElementType = Src->getType();
  if (SrcElementType->isRecordType())
    SrcElementType = SrcElementType->getAs<RecordType>()->getDecl()->field_begin()->getType();
  if (SrcElementType->isVectorType())
    SrcElementType = SrcElementType->getAs<clang::VectorType>()->getElementType();
  unsigned SrcMultiplicity;
  llvm::Type *SrcTy = getIRType(CGF, Src->getType(), SrcMultiplicity);

  QualType DestElementType = E->getType();
  if (DestElementType->isRecordType())
    DestElementType = DestElementType->getAs<RecordType>()->getDecl()->field_begin()->getType();
  if (DestElementType->isVectorType())
    DestElementType = DestElementType->getAs<clang::VectorType>()->getElementType();
  unsigned DestMultiplicity;
  llvm::Type *DestTy = getIRType(CGF, E->getType(), DestMultiplicity);
  llvm::Type *FEDestTy = DestMultiplicity ? CGF->ConvertType(E->getType()) : DestTy;

  auto SrcVectTy = cast<FixedVectorType>(SrcTy);
  auto DestVectTy = cast<FixedVectorType>(DestTy);
  assert(SrcVectTy->getNumElements() == DestVectTy->getNumElements());

  llvm::Type *SrcElTy = SrcVectTy->getElementType();
  llvm::Type *DestElTy = DestVectTy->getElementType();

  // Determine switches. We use them when the convertion cannot be represented
  // by regular IR nodes.

  // Get specified switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(OptionsOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  const unsigned Options = SwitchVal;

  // Check if the switchset contains only allowed switches.
  assert((SwitchVal & ~AllowedSwitches) == 0);

  // Add target type specification to the switchset.
  llvm::TPCII::OpType TargetDT = getOptypeValue(E->getType());
  SwitchVal |= getSwitchForDestination(TargetDT);

  Value *SrcVal = emitOperand(CGF, Src);
  Value *Result = nullptr;

  // 'convert_to_*' may be mapped to llvm IR node only if size of elements are
  // equal, otherwise native conversion would produce swizzled order, while
  // the regular IR nodes expect linear one.
  // Also the conversion must not produce overflow, as the regular nodes in such
  // case produce undefined behavior. So, only conversions to floats of the same
  // length and default rounding are allowed.
  if (Options == 0) {
    if (SrcElTy->isIntegerTy() && DestElTy->isFloatingPointTy() &&
        SrcElTy->getPrimitiveSizeInBits() == DestElTy->getPrimitiveSizeInBits()) {
      if (SrcElementType->isUnsignedIntegerType())
        Result = CGF->Builder.CreateUIToFP(SrcVal, DestTy);
      else
        Result = CGF->Builder.CreateSIToFP(SrcVal, DestTy);
    }
  }

  // If we cannot use LLVM IR node, call conversion intrinsic.
  if (!Result) {
    auto *BitTy = llvm::IntegerType::get(CGF->getLLVMContext(), 1);
    unsigned IID = (SwitchVal & TPCII::SW_LINEAR) ? Intrinsic::tpc_convert_linear
                                                  : Intrinsic::tpc_convert;
    SwitchVal &= ~TPCII::SW_LINEAR;
    Function *Callee = CGF->CGM.getIntrinsic(IID, { DestTy, SrcTy, BitTy });
    SmallVector<llvm::Value *, 6> Args;
    Args.push_back(SrcVal);
    Args.push_back(llvm::ConstantInt::get(CGF->Int8Ty,
                                          getOptypeValue(E->getArg(0)->getType())));
    Args.push_back(llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));
    Args.push_back(UndefValue::get(DestTy));
    Args.push_back(llvm::ConstantInt::get(BitTy, 1));
    Args.push_back(llvm::ConstantInt::get(BitTy, 0));

    Result = CGF->Builder.CreateCall(Callee, Args);
    assert(Result);
  }

  return prepareResult(CGF, ReturnValue, Result, DestMultiplicity, FEDestTy);
}


// __global void *gen_addr(int5 inx, const int8_t tensor, int switches, __global void *income, bool predicate, bool polarity);
//
static Value *emit_GEN_ADDR(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned SwitchesOpNum = 2;
  const unsigned IncomeOpNum = 3;
  const unsigned PredicateOpNum = 4;
  const unsigned PolarityOpNum = 5;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  Value *Index = CGF->EmitScalarExpr(E->getArg(IndexOpNum));
  Value *Tensor = CGF->EmitScalarExpr(E->getArg(TensorOpNum));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(SwitchesOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_gen_addr);
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Index, Tensor, Switches, Income, Predicate, Polarity});
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


// int5 prmt_indx(int5 ndx, int prmt_type, int switchs, int5 income, bool predicate, bool polarity);
//
static Value *emit_PRMT_INDX(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  const unsigned IndexOpNum = 0;
  const unsigned PTypeOpNum = 1;
  const unsigned SwitchesOpNum = 2;
  const unsigned IncomeOpNum = 3;
  const unsigned PredicateOpNum = 4;
  const unsigned PolarityOpNum = 5;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  Value *Index = CGF->EmitScalarExpr(E->getArg(IndexOpNum));
  Value *PType = CGF->EmitScalarExpr(E->getArg(PTypeOpNum));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(SwitchesOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_prmt_indx);
  Value *Result = CGF->Builder.CreateCall(Callee,
      { Index, PType, Switches, Income, Predicate, Polarity });
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


static Value *emit_SET_INDX(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  const unsigned SwitchesOpNum = 3;

  Function * Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_set_indx);

  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (SwitchVal && !CGF->CGM.getCodeGenOpts().LongIRF)
    report_fatal_error("set_indx with high switch relevants only if -long-irf specified");

  Value *Val = CGF->EmitScalarExpr(E->getArg(0));
  Value *Income = CGF->EmitScalarExpr(E->getArg(1));
  Value *Mask = CGF->EmitScalarExpr(E->getArg(2));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Pred = CGF->EvaluateExprAsBool(E->getArg(4));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(5));

  return CGF->Builder.CreateCall(Callee, { Income, Mask, Val, Switches, Pred, Polarity });
}


static Value* emit_LD_TNSR(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch,
                           unsigned Switch, unsigned Mask,
                           unsigned IID, bool IsPartial) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned OffsetOpNum = 2;
  const unsigned SizeOpNum = 3;
  const unsigned SwitchesOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (Mask || Switch) {
    SwitchVal &= ~Mask;
    SwitchVal |= Switch;
  }
  if (IsPartial)
    SwitchVal |= TPCII::SW_PARTIAL;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(IndexOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(TensorOpNum)));

  if (IsPartial) {
    Value *Size = CGF->EmitScalarExpr(E->getArg(OffsetOpNum));
    Value *Offset = CGF->EmitScalarExpr(E->getArg(SizeOpNum));
    Size = CGF->Builder.CreateZExt(Size, CGF->Int32Ty);
    Offset = CGF->Builder.CreateZExt(Offset, CGF->Int32Ty);
    Offset = CGF->Builder.CreateShl(Offset, ConstantInt::get(CGF->Int32Ty, 8));
    Value *OffSize = CGF->Builder.CreateOr(Offset, Size);
    Args.push_back(OffSize);
  } else {
    assert(E->getNumArgs() == 6);
  }

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  // If PARTIAL is specified, income argument must never be replaced with Undef,
  // as in this case the instruction updates income value.
  if (!IsPartial && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Args.push_back(Switches);
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);
  Function * Callee = CGF->CGM.getIntrinsic(IID, {ResultTy,
                                                  Predicate->getType()});

  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


static Value *emit_LD_TNSR_DIRECT(CodeGenFunction *CGF, unsigned BuiltinID,
                                  const CallExpr *E, ReturnValueSlot ReturnValue,
                                  llvm::Triple::ArchType Arch,
                                  unsigned Switch, unsigned Mask,
                                  unsigned IID, bool IsPartial) {
  const unsigned NumArgs = E->getNumArgs();

  const unsigned SizeOpNum      = IsPartial ? 2 : 0;
  const unsigned OffsetOpNum    = IsPartial ? 3 : 0;
  const unsigned SwitchesOpNum  = IsPartial ? 4 : 2;
  const unsigned IncomeOpNum    = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum  = NumArgs - 1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R);
  (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (Mask || Switch) {
    SwitchVal &= ~Mask;
    SwitchVal |= Switch;
  }
  SwitchVal |= TPCII::SW_DIRECT;
  if (IsPartial)
    SwitchVal |= TPCII::SW_PARTIAL;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(0))); // Src1
  Args.push_back(CGF->EmitScalarExpr(E->getArg(1))); // Src2

  if (IsPartial) {
    Value *Size   = CGF->EmitScalarExpr(E->getArg(OffsetOpNum));
    Value *Offset = CGF->EmitScalarExpr(E->getArg(SizeOpNum));
    Size   = CGF->Builder.CreateZExt(Size, CGF->Int32Ty);
    Offset = CGF->Builder.CreateZExt(Offset, CGF->Int32Ty);
    Offset = CGF->Builder.CreateShl(Offset, ConstantInt::get(CGF->Int32Ty, 8));
    Value *OffSize = CGF->Builder.CreateOr(Offset, Size);
    Args.push_back(OffSize);
  }

  Value *Switches  = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity  = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;

  // If PARTIAL is specified, income argument must never be replaced with Undef,
  // as in this case the instruction updates income value.
  if (!IsPartial && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Args.push_back(Switches);
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID, {ResultTy, Predicate->getType()});

  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


// void v_f32_st_tnsr (int5 ndx, const int8_t tensor, float64 value, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_r (int5 ndx, int8_t tensor, float64 value, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_rmw (int5 ndx, int8_t tensor, float64 value, int rmw, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_partial (int5 ndx, int8_t tensor, float64 value, int offsize, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_partial_rmw (int5 ndx, int8_t tensor, float64 value, int rmw, int offsize, int switches, bool predicate, bool polarity);
//
static Value *emit_ST_TNSR(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned ValueOpNum = 2;
  const unsigned RMWOpNum = 3;
  const unsigned SwitchesOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_PARTIAL | TPCII::SW_RMW_SEL;
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIv_f32_st_tnsr:
  case TPC::BIv_bf16_st_tnsr:
  case TPC::BIv_f16_st_tnsr:
  case TPC::BIv_f8_st_tnsr:
  case TPC::BIv_h8_st_tnsr:
  case TPC::BIv_i32_st_tnsr:
  case TPC::BIv_u32_st_tnsr:
  case TPC::BIv_i16_st_tnsr:
  case TPC::BIv_u16_st_tnsr:
  case TPC::BIv_i8_st_tnsr:
  case TPC::BIv_u8_st_tnsr:
  case TPC::BIv_i1_st_tnsr:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_st_tnsr;
    break;
  case TPC::BIv_f32_st_tnsr_rmw:
  case TPC::BIv_bf16_st_tnsr_rmw:
  case TPC::BIv_f16_st_tnsr_rmw:
  case TPC::BIv_i32_st_tnsr_rmw:
  case TPC::BIv_u32_st_tnsr_rmw:
  case TPC::BIv_i16_st_tnsr_rmw:
  case TPC::BIv_u16_st_tnsr_rmw:
  case TPC::BIv_i8_st_tnsr_rmw:
  case TPC::BIv_u8_st_tnsr_rmw:
  case TPC::BIv_h8_st_tnsr_rmw:
    RequiredSwitches = TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_rmw;
    break;
  case TPC::BIv_f32_st_tnsr_partial:
  case TPC::BIv_bf16_st_tnsr_partial:
  case TPC::BIv_f16_st_tnsr_partial:
  case TPC::BIv_f8_st_tnsr_partial:
  case TPC::BIv_h8_st_tnsr_partial:
  case TPC::BIv_i32_st_tnsr_partial:
  case TPC::BIv_u32_st_tnsr_partial:
  case TPC::BIv_i16_st_tnsr_partial:
  case TPC::BIv_u16_st_tnsr_partial:
  case TPC::BIv_i8_st_tnsr_partial:
  case TPC::BIv_u8_st_tnsr_partial:
  case TPC::BIv_i1_st_tnsr_partial:
    RequiredSwitches = TPCII::SW_PARTIAL;
    IID = Intrinsic::tpc_st_tnsr_partial;
    break;
  case TPC::BIv_f32_st_tnsr_partial_rmw:
  case TPC::BIv_bf16_st_tnsr_partial_rmw:
  case TPC::BIv_f16_st_tnsr_partial_rmw:
  case TPC::BIv_h8_st_tnsr_partial_rmw:
  case TPC::BIv_i32_st_tnsr_partial_rmw:
  case TPC::BIv_u32_st_tnsr_partial_rmw:
  case TPC::BIv_i16_st_tnsr_partial_rmw:
  case TPC::BIv_u16_st_tnsr_partial_rmw:
  case TPC::BIv_i8_st_tnsr_partial_rmw:
  case TPC::BIv_u8_st_tnsr_partial_rmw:
    RequiredSwitches = TPCII::SW_PARTIAL | TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_partial_rmw;
    break;
  default:
    llvm_unreachable("Unhandled ST_TNSR intrinsic");
  }
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(IndexOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(TensorOpNum)));
  Value *Val = CGF->EmitScalarExpr(E->getArg(ValueOpNum));
  Args.push_back(Val);

  if (SwitchVal & TPCII::SW_RMW_SEL)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(RMWOpNum)));
  if (SwitchVal & TPCII::SW_PARTIAL) {
    Value *Size = CGF->EmitScalarExpr(E->getArg(Args.size()));
    Value *Offset = CGF->EmitScalarExpr(E->getArg(Args.size()+1));
    Size = CGF->Builder.CreateZExt(Size, CGF->Int32Ty);
    Offset = CGF->Builder.CreateZExt(Offset, CGF->Int32Ty);
    Offset = CGF->Builder.CreateShl(Offset, ConstantInt::get(CGF->Int32Ty, 8));
    Value *OffSize = CGF->Builder.CreateOr(Offset, Size);
    Args.push_back(OffSize);
  }
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Args.push_back(Switches);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID, Val->getType());
  return CGF->Builder.CreateCall(Callee, Args);
}

static Value *emit_ST_TNSR_DIRECT(CodeGenFunction *CGF, unsigned BuiltinID,
                                  const CallExpr *E,
                                  llvm::Triple::ArchType Arch, unsigned IID,
                                  bool isPartial, bool isRmw) {

  unsigned NumArgs = E->getNumArgs();

  const unsigned ValueOpNum     = 2;
  const unsigned RMWOpNum       = isRmw ? (isPartial ? 4 : 3) : 0;
  const unsigned SwitchesOpNum  = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum  = NumArgs - 1;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R);
  (void)R;

  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal |= TPCII::SW_DIRECT;
  if (isPartial) SwitchVal |= TPCII::SW_PARTIAL;
  if (isRmw)     SwitchVal |= TPCII::SW_RMW_SEL;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(0))); // Src1
  Args.push_back(CGF->EmitScalarExpr(E->getArg(1))); // Src2
  Value *Val = CGF->EmitScalarExpr(E->getArg(ValueOpNum));
  Args.push_back(Val);

  if (isRmw) Args.push_back(CGF->EmitScalarExpr(E->getArg(RMWOpNum)));
  if (isPartial) {
    Value *Size   = CGF->EmitScalarExpr(E->getArg(Args.size()));
    Value *Offset = CGF->EmitScalarExpr(E->getArg(Args.size() + 1));
    Size = CGF->Builder.CreateZExt(Size, CGF->Int32Ty);
    Offset = CGF->Builder.CreateZExt(Offset, CGF->Int32Ty);
    Offset = CGF->Builder.CreateShl(Offset, ConstantInt::get(CGF->Int32Ty, 8));
    Value *OffSize = CGF->Builder.CreateOr(Offset, Size);
    Args.push_back(OffSize);
  }

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Args.push_back(Switches);

  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Predicate);

  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID, Val->getType());
  return CGF->Builder.CreateCall(Callee, Args);
}

// void v_f32_st_tnsr_low (int5 ndx, const int8_t tensor, float64 value, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_low_r (int5 ndx, int8_t tensor, float64 value, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_low_rmw (int5 ndx, int8_t tensor, float64 value, int rmw, int switches, bool predicate, bool polarity);
//
static Value *emit_ST_TNSR_LOW(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned ValueOpNum = 2;
  const unsigned RMWOpNum = 3;
  const unsigned SwitchesOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_RMW_SEL;
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIv_f32_st_tnsr_low:
  case TPC::BIv_bf16_st_tnsr_low:
  case TPC::BIv_f16_st_tnsr_low:
  case TPC::BIv_f8_st_tnsr_low:
  case TPC::BIv_h8_st_tnsr_low:
  case TPC::BIv_i32_st_tnsr_low:
  case TPC::BIv_u32_st_tnsr_low:
  case TPC::BIv_i16_st_tnsr_low:
  case TPC::BIv_u16_st_tnsr_low:
  case TPC::BIv_i8_st_tnsr_low:
  case TPC::BIv_u8_st_tnsr_low:
  case TPC::BIv_i1_st_tnsr_low:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_st_tnsr_low;
    break;
  case TPC::BIv_f32_st_tnsr_low_rmw:
  case TPC::BIv_bf16_st_tnsr_low_rmw:
  case TPC::BIv_f16_st_tnsr_low_rmw:
  case TPC::BIv_h8_st_tnsr_low_rmw:
  case TPC::BIv_i32_st_tnsr_low_rmw:
  case TPC::BIv_u32_st_tnsr_low_rmw:
  case TPC::BIv_i16_st_tnsr_low_rmw:
  case TPC::BIv_u16_st_tnsr_low_rmw:
  case TPC::BIv_i8_st_tnsr_low_rmw:
  case TPC::BIv_u8_st_tnsr_low_rmw:
    RequiredSwitches = TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_low_rmw;
    break;
  default:
    llvm_unreachable("Unhandled ST_TNSR_LOW intrinsic");
  }
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(IndexOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(TensorOpNum)));
  Value *Val = CGF->EmitScalarExpr(E->getArg(ValueOpNum));
  Args.push_back(Val);

  if (SwitchVal & TPCII::SW_RMW_SEL)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(RMWOpNum)));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Args.push_back(Switches);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID, Val->getType());
  return CGF->Builder.CreateCall(Callee, Args);
}


// void v_f32_st_tnsr_high (int5 ndx, const int8_t tensor, float64 value, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_high_r (int5 ndx, int8_t tensor, float64 value, int switches, bool predicate, bool polarity);
// void v_f32_st_tnsr_high_rmw (int5 ndx, int8_t tensor, float64 value, int rmw, int switches, bool predicate, bool polarity);
//
static Value *emit_ST_TNSR_HIGH(CodeGenFunction *CGF, unsigned BuiltinID,
                                const CallExpr *E, ReturnValueSlot ReturnValue,
                                llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned ValueOpNum = 2;
  const unsigned RMWOpNum = 3;
  const unsigned SwitchesOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_RMW_SEL;
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIv_f32_st_tnsr_high:
  case TPC::BIv_bf16_st_tnsr_high:
  case TPC::BIv_f16_st_tnsr_high:
  case TPC::BIv_f8_st_tnsr_high:
  case TPC::BIv_h8_st_tnsr_high:
  case TPC::BIv_i32_st_tnsr_high:
  case TPC::BIv_u32_st_tnsr_high:
  case TPC::BIv_i16_st_tnsr_high:
  case TPC::BIv_u16_st_tnsr_high:
  case TPC::BIv_i8_st_tnsr_high:
  case TPC::BIv_u8_st_tnsr_high:
  case TPC::BIv_i1_st_tnsr_high:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_st_tnsr_high;
    break;
  case TPC::BIv_f32_st_tnsr_high_rmw:
  case TPC::BIv_bf16_st_tnsr_high_rmw:
  case TPC::BIv_f16_st_tnsr_high_rmw:
  case TPC::BIv_h8_st_tnsr_high_rmw:
  case TPC::BIv_i32_st_tnsr_high_rmw:
  case TPC::BIv_u32_st_tnsr_high_rmw:
  case TPC::BIv_i16_st_tnsr_high_rmw:
  case TPC::BIv_u16_st_tnsr_high_rmw:
  case TPC::BIv_i8_st_tnsr_high_rmw:
  case TPC::BIv_u8_st_tnsr_high_rmw:
    RequiredSwitches = TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_high_rmw;
    break;
  default:
    llvm_unreachable("Unhandled ST_TNSR_HIGH intrinsic");
  }
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(IndexOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(TensorOpNum)));
  Value *Val = CGF->EmitScalarExpr(E->getArg(ValueOpNum));
  Args.push_back(Val);

  if (SwitchVal & TPCII::SW_RMW_SEL)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(RMWOpNum)));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Args.push_back(Switches);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID, Val->getType());
  return CGF->Builder.CreateCall(Callee, Args);
}


static Value *emit_ST_TNSR_S(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned ValueOrSqzOpNum = 2;
  const unsigned RMWOpNum = 3;
  const unsigned SwitchesOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R =
      E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;

  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_HW_REG | TPCII::SW_RMW_SEL;
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIs_f32_st_tnsr_s:
  case TPC::BIs_bf16_st_tnsr_s:
  case TPC::BIs_f16_st_tnsr_s:
  case TPC::BIs_i32_st_tnsr_s:
  case TPC::BIs_u32_st_tnsr_s:
  case TPC::BIs_i16_st_tnsr_s:
  case TPC::BIs_u16_st_tnsr_s:
  case TPC::BIs_i8_st_tnsr_s:
  case TPC::BIs_u8_st_tnsr_s:
  case TPC::BIs_f8_st_tnsr_s:
  case TPC::BIs_h8_st_tnsr_s:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_st_tnsr_s;
    break;
  case TPC::BIs_f32_st_tnsr_s_rmw:
  case TPC::BIs_bf16_st_tnsr_s_rmw:
  case TPC::BIs_f16_st_tnsr_s_rmw:
  case TPC::BIs_h8_st_tnsr_s_rmw:
  case TPC::BIs_i32_st_tnsr_s_rmw:
  case TPC::BIs_u32_st_tnsr_s_rmw:
  case TPC::BIs_i16_st_tnsr_s_rmw:
  case TPC::BIs_u16_st_tnsr_s_rmw:
  case TPC::BIs_i8_st_tnsr_s_rmw:
  case TPC::BIs_u8_st_tnsr_s_rmw:
    RequiredSwitches = TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_s_rmw;
    break;
  case TPC::BIst_tnsr_s_hwr:
    RequiredSwitches = TPCII::SW_HW_REG;
    IID = Intrinsic::tpc_st_tnsr_s_hwr;
    break;
  case TPC::BIst_tnsr_s_hwr_rmw:
    RequiredSwitches = TPCII::SW_HW_REG | TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_s_hwr_rmw;
    break;
  default:
    llvm_unreachable("Unhandled ST_TNSR_S intrinsic");
  }

  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(IndexOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(TensorOpNum)));
  Value *Val = CGF->EmitScalarExpr(E->getArg(ValueOrSqzOpNum));
  Args.push_back(Val);

  if (SwitchVal & TPCII::SW_RMW_SEL)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(RMWOpNum)));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Args.push_back(Switches);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Args.push_back(Predicate);
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Polarity);

  Function *Callee =
      IID == Intrinsic::tpc_st_tnsr_s || IID == Intrinsic::tpc_st_tnsr_s_rmw ?
        CGF->CGM.getIntrinsic(IID, Val->getType()) :
        CGF->CGM.getIntrinsic(IID);

  return CGF->Builder.CreateCall(Callee, Args);
}

static Value *emit_reset_sqz_cntr(CodeGenFunction *CGF, unsigned BuildinID, const CallExpr *E,
                                  llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned SqzCntrIdx = 0;
  const unsigned SqzCntrVal = 1;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;
  unsigned IID = Intrinsic::tpc_reset_sqz_cntr;

  const TargetInfo &TI = CGF->getContext().getTargetInfo();
  const auto &TO = CGF->CGM.getCodeGenOpts();
  if (TI.hasFeature("gaudi2")) {
    if (SqzCntrIdx < 0 || SqzCntrIdx > 7) {
      report_fatal_error("Incorrect sqz_cntr index: acceptable values are [0; 7]");
    }
  } else if (TI.hasFeature("doron1")) {
    if (SqzCntrIdx < 0 || SqzCntrIdx > 15) {
      report_fatal_error("Incorrect sqz_cntr index: acceptable values are [0; 15]");
    }
  }

  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(SqzCntrIdx)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(SqzCntrVal)));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Args.push_back(Predicate);
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID);
  return CGF->Builder.CreateCall(Callee, Args);
}

static Value *emit_ST_TNSR_SQZ(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned IndexOpNum = 0;
  const unsigned TensorOpNum = 1;
  const unsigned SqueezeOpNum = 2;
  const unsigned ValueOpNum = 3;
  const unsigned RMWOpNum = 4;
  const unsigned SwitchesOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;

  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_RMW_SEL;
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIv_f32_st_tnsr_sqz:
  case TPC::BIv_i32_st_tnsr_sqz:
  case TPC::BIv_u32_st_tnsr_sqz:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_st_tnsr_sqz;
    break;
  case TPC::BIv_f32_st_tnsr_sqz_rmw:
  case TPC::BIv_i32_st_tnsr_sqz_rmw:
  case TPC::BIv_u32_st_tnsr_sqz_rmw:
    RequiredSwitches = TPCII::SW_RMW_SEL;
    IID = Intrinsic::tpc_st_tnsr_sqz_rmw;
    break;
  default:
    llvm_unreachable("Unhandled ST_TNSR_SQZ intrinsic");
  }

  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(IndexOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(TensorOpNum)));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(SqueezeOpNum)));
  Value *Val = CGF->EmitScalarExpr(E->getArg(ValueOpNum));
  Args.push_back(Val);

  if (SwitchVal & TPCII::SW_RMW_SEL)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(RMWOpNum)));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Args.push_back(Switches);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Args.push_back(Predicate);
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID, Val->getType());
  return CGF->Builder.CreateCall(Callee, Args);
}

// float64 v_f32_fclass_b(float64 a, int switches, float64 income, bool predicate, bool polarity);
// float64 v_f32_fclass_limit_b(float64 a, float64 b, float64 c, int switches, float64 income, bool predicate, bool polarity);
//
static Value *emit_FCLASS(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned SrcBOpNum = 1;
  const unsigned SrcCOpNum = 2;
  const unsigned SwitchesOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_LIMIT;
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIs_f32_fclass:
  case TPC::BIs_bf16_fclass:
  case TPC::BIs_f16_fclass:
  case TPC::BIs_f8_fclass:
  case TPC::BIs_h8_fclass:
  case TPC::BIv_f32_fclass_b:
  case TPC::BIv_bf16_fclass_b:
  case TPC::BIv_f16_fclass_b:
  case TPC::BIv_f8_fclass_b:
  case TPC::BIv_h8_fclass_b:
  case TPC::BIv_f32_fclass_vb:
  case TPC::BIv_bf16_fclass_vb:
  case TPC::BIv_f16_fclass_vb:
  case TPC::BIv_f8_fclass_vb:
  case TPC::BIv_h8_fclass_vb:
    assert(NumArgs == 5);
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_fclass;
    break;
  case TPC::BIv_f32_fclass_limit_b:
  case TPC::BIv_f32_fclass_limit_vb:
  case TPC::BIv_bf16_fclass_limit_b:
  case TPC::BIv_bf16_fclass_limit_vb:
  case TPC::BIv_f16_fclass_limit_b:
  case TPC::BIv_f16_fclass_limit_vb:
  case TPC::BIv_f8_fclass_limit_b:
  case TPC::BIv_f8_fclass_limit_vb:
  case TPC::BIv_h8_fclass_limit_b:
  case TPC::BIv_h8_fclass_limit_vb:
    assert(NumArgs == 7);
    RequiredSwitches = TPCII::SW_LIMIT;
    IID = Intrinsic::tpc_fclass_limit;
    break;
  default:
    llvm_unreachable("Unhandled FCLASS intrinsic");
  }
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  const Expr *SrcArg = E->getArg(SrcOpNum);
  SmallVector<llvm::Value *, 8> Args;
  Value *Src = CGF->EmitScalarExpr(SrcArg);
  Args.push_back(Src);
  if (SwitchVal & TPCII::SW_LIMIT) {
    Args.push_back(CGF->EmitScalarExpr(E->getArg(SrcBOpNum)));
    Args.push_back(CGF->EmitScalarExpr(E->getArg(SrcCOpNum)));
  }

  auto DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(SrcArg->getType()));
  Args.push_back(DT);
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Args.push_back(Switches);
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(IID,
                                           { ResultTy,
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


// uchar256 v_i32_popcnt_b(int64 a, int switches, uchar256 income, bool predicate, bool polarity);
//
static Value *emit_POPCNT(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned SwitchesOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;
  assert(NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Operands.
  const Expr *SrcArg = E->getArg(SrcOpNum);
  Value *Src = CGF->EmitScalarExpr(SrcArg);
  auto DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(SrcArg->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_popcnt,
                                           { ResultTy,
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, {Src, DT, Switches, Income, Predicate, Polarity});
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


// uchar256 v_i32_find_first_b (int64 a, int switches, uchar256 income, bool predicate, bool polarity);
//
static Value *emit_FIND_FIRST(CodeGenFunction *CGF, unsigned BuiltinID,
                              const CallExpr *E, ReturnValueSlot ReturnValue,
                              llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned SwitchesOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;
  assert(NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Operands.
  const Expr *SrcArg = E->getArg(SrcOpNum);
  Value *Src = CGF->EmitScalarExpr(SrcArg);
  auto DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(SrcArg->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_find_first,
                                           { ResultTy,
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, { Src, DT, Switches, Income, Predicate, Polarity });
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


// float s_f32_nearbyint(float a, int switches, float income, bool predicate, bool polarity);
//
static Value *emit_NEARBYINT(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SwOpNum = NumArgs-4;
  const unsigned IncomeOpNum = NumArgs-3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches.
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_TO_TYPE | TPCII::SW_CNVRT;
  const TargetInfo &TI = CGF->getContext().getTargetInfo();
  switch (BuiltinID) {
  case TPC::BIs_f32_nearbyint:
  case TPC::BIs_bf16_nearbyint:
  case TPC::BIs_f16_nearbyint:
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_TO_INT32;
    else
      RequiredSwitches = 0;
    break;
  case TPC::BIs_f8_nearbyint:
  case TPC::BIs_h8_nearbyint:
      RequiredSwitches = 0;
      break;
  case TPC::BIv_f32_nearbyint_b:
  case TPC::BIv_f32_nearbyint_vb:
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_TO_INT32;
    else
      RequiredSwitches = 0;
    break;
  case TPC::BIv_bf16_nearbyint_b:
  case TPC::BIv_bf16_nearbyint_vb:
  case TPC::BIv_f16_nearbyint_b:
  case TPC::BIv_f16_nearbyint_vb:
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_TO_INT16;
    else
      RequiredSwitches = 0;
    break;
  case TPC::BIv_f8_nearbyint_b:
  case TPC::BIv_f8_nearbyint_vb:
  case TPC::BIv_h8_nearbyint_b:
  case TPC::BIv_h8_nearbyint_vb:
    RequiredSwitches = 0;
    break;
  case TPC::BIv_f32_nearbyint_cnvrt_b:
  case TPC::BIv_f32_nearbyint_cnvrt_vb:
    RequiredSwitches = (TPCII::SW_CNVRT | TPCII::SW_TO_INT32);
    break;
  case TPC::BIv_bf16_nearbyint_cnvrt_b:
  case TPC::BIv_bf16_nearbyint_cnvrt_vb:
  case TPC::BIv_f16_nearbyint_cnvrt_b:
  case TPC::BIv_f16_nearbyint_cnvrt_vb:
    RequiredSwitches = (TPCII::SW_CNVRT | TPCII::SW_TO_INT16);
    break;
  case TPC::BIv_f8_nearbyint_cnvrt_b:
  case TPC::BIv_f8_nearbyint_cnvrt_vb:
  case TPC::BIv_h8_nearbyint_cnvrt_b:
  case TPC::BIv_h8_nearbyint_cnvrt_vb:
    RequiredSwitches = (TPCII::SW_CNVRT | TPCII::SW_TO_INT8);
    break;
  default:
    llvm_unreachable("Unhandled NEARBYINT intrinsic");
  }
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;
  if (TI.hasFeature("goya"))
    SwitchVal = translateGen1RoundingMode(SwitchVal);

  // Operands.
  Value *Src = CGF->EmitScalarExpr(/* a */ E->getArg(0));
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(0)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_nearbyint,
                                           { ResultTy,
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src, DT, Switches, Income, Predicate, Polarity});
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// int64 v_f32_extract_exp_vb(float64 a, int switches, int64 income, bool64 predicate, bool polarity);
//
static Value *emit_EXTRACT_EXP(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned SwitchesOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;
  assert(NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Operands.
  const Expr *SrcArg = E->getArg(SrcOpNum);
  Value *Src = CGF->EmitScalarExpr(SrcArg);
  auto DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(SrcArg->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_extract_exp,
                                           { ResultTy,
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, { Src, DT, Switches, Income, Predicate, Polarity });
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


static Value *emit_BREV(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned SwitchesOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredicateOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;
  assert(NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Operands.
  const Expr *SrcArg = E->getArg(SrcOpNum);
  Value *Src = CGF->EmitScalarExpr(SrcArg);
  auto DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(SrcArg->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_brev,
                                           { ResultTy,
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, { Src, DT, Switches, Income, Predicate, Polarity });
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}

// float64 v_f32_mov_dual_group_vb(float64 a, const uint32_t b, const int src_dg, const int dest_dg, int switches, float64 income, bool64 predicate, bool polarity);
static Value *emit_MOV_DUAL_GROUP(CodeGenFunction *CGF, unsigned BuiltinID, const CallExpr *E, ReturnValueSlot ReturnValue, llvm::Triple::ArchType Arch)
{
  Value *Src  = CGF->EmitScalarExpr(E->getArg(0));
  Value *WrEn = CGF->EmitScalarExpr(E->getArg(1));

  Expr::EvalResult ResVal;
  // SRC_DUAL_GROUP
  bool Res = E->getArg(2)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned src_dg = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  // DEST_DUAL_GROUP
  Res = E->getArg(3)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned dst_dg = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  // WR_LOWER_GROUP, WR_UPPER_GROUP
  Res = E->getArg(4)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned SwitchVal = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert((SwitchVal & 0x0F00) == 0);
  unsigned wr_lower_upper_group = SwitchVal >> 8;
  unsigned ctrl_val = src_dg | (dst_dg << 2) | wr_lower_upper_group;  // src_dual_group | (dst_dual_group << 2) | (write_lower_group << 4) | (write_upper_group << 5).

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal & 0xF0FF); // clean up the WR_LOWER_GROUP & WR_UPPER_GROUP.
  Value *Income = CGF->EmitScalarExpr(E->getArg(5));
  Value *Pred = emitPredicate(CGF, E->getArg(6));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(7));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_dual_group, {Income->getType(), Pred->getType() });
  return CGF->Builder.CreateCall(Callee, { Src, WrEn, llvm::ConstantInt::get(CGF->Int32Ty, ctrl_val), Switches, Income, Pred, Polarity });
}

static Value *emit_MOV_DG(CodeGenFunction *CGF, unsigned IID, const CallExpr *E, ReturnValueSlot ReturnValue, llvm::Triple::ArchType Arch)
{
  Value *Src1     = CGF->EmitScalarExpr(E->getArg(0));
  Value *WrEn     = CGF->EmitScalarExpr(E->getArg(1));
  Value *Src2     = CGF->EmitScalarExpr(E->getArg(2));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(3));
  Value *Income   = CGF->EmitScalarExpr(E->getArg(4));
  Value *Pred     = emitPredicate(CGF, E->getArg(5));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(6));

  Function *Callee = CGF->CGM.getIntrinsic(IID, {Income->getType(), Pred->getType()});
  return CGF->Builder.CreateCall(Callee, {Src1, WrEn, Src2, Switches, Income, Pred, Polarity});
}

// float64 v_f32_mov_dual_group_all_vb(float64 a, const uint32_t b, const int sdg0, const int sdg1, const int sdg2, const int sdg3, int switches, float64 income,bool64  predicate, bool polarity);
static Value *emit_MOV_DUAL_GROUP_ALL(CodeGenFunction *CGF, unsigned BuiltinID, const CallExpr *E, ReturnValueSlot ReturnValue, llvm::Triple::ArchType Arch)
{
  Value *Src  = CGF->EmitScalarExpr(E->getArg(0));
  Value *WrEn = CGF->EmitScalarExpr(E->getArg(1));

  Expr::EvalResult ResVal;
  // SRC_DUAL_GROUP[0]
  bool Res = E->getArg(2)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned sdg0 = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  // SRC_DUAL_GROUP[1]
  Res = E->getArg(3)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned sdg1 = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  // SRC_DUAL_GROUP[2]
  Res = E->getArg(4)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned sdg2 = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  // SRC_DUAL_GROUP[3]
  Res = E->getArg(5)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned sdg3 = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  // WR_LOWER_GROUP[], WR_UPPER_GROUP[]
  Res = E->getArg(6)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res; assert(Res);
  unsigned Sw = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert((Sw & 0x0FF00) == 0);
  unsigned SwitchVal = Sw;
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Income = CGF->EmitScalarExpr(E->getArg(7));
  Value *Pred = emitPredicate(CGF, E->getArg(8));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(9));

  unsigned ctrl_val = sdg0 | (sdg1 << 2) | (sdg2 << 4) | (sdg3 << 6);
  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_dual_group_all, { Income->getType(), Pred->getType() });
  return CGF->Builder.CreateCall(Callee, { Src, WrEn, llvm::ConstantInt::get(CGF->Int32Ty, ctrl_val), Switches, Income, Pred, Polarity });
}

  // half128   v_f16_mov_dual_group_unpack_vb (half128   a, const int sdg0,
// const int sdg1, const int sdg2, const int sdg3, int switches, half128
// income, bool128 predicate, bool polarity);
static Value *emit_MOV_DUAL_GROUP_UNPACK(CodeGenFunction *CGF,
                                         const CallExpr *E) {
  Value *Src = CGF->EmitScalarExpr(E->getArg(0));
  Value *WrEn = CGF->EmitScalarExpr(E->getArg(1));

  unsigned SwitchVal = TPCII::SW_MDG_TYPE_UNPACK;
  Expr::EvalResult ResVal;
  // SRC_DUAL_GROUP[0]
  bool Res = E->getArg(2)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res;
  assert(Res);
  unsigned Sw = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert(Sw < 4);
  SwitchVal |= (Sw << TPCII::SW_SDG0_SHIFT);
  // SRC_DUAL_GROUP[1]
  Res = E->getArg(3)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res;
  assert(Res);
  Sw = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert(Sw < 4);
  SwitchVal |= (Sw << TPCII::SW_SDG1_SHIFT);
  // SRC_DUAL_GROUP[2]
  Res = E->getArg(4)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res;
  assert(Res);
  Sw = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert(Sw < 4);
  SwitchVal |= (Sw << TPCII::SW_SDG2_SHIFT);
  // SRC_DUAL_GROUP[3]
  Res = E->getArg(5)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res;
  assert(Res);
  Sw = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert(Sw < 4);
  SwitchVal |= (Sw << TPCII::SW_SDG3_SHIFT);
  // WR_LOWER_GROUP[], WR_UPPER_GROUP[]
  Res = E->getArg(6)->EvaluateAsRValue(ResVal, CGF->getContext());
  (void)Res;
  assert(Res);
  Sw = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  assert((Sw & 0x0FF00) == 0);
  SwitchVal |= Sw;
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);

  Value *Income = CGF->EmitScalarExpr(E->getArg(7));
  Value *Pred = nullptr;
  if (E->getArg(7)->getType()->isVectorType()) {
    Pred = emitPredicate(CGF, E->getArg(8));;
  } else {
    Pred = CGF->EvaluateExprAsBool(E->getArg(8));
  }
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(9));

  Function *Callee = CGF->CGM.getIntrinsic(
      Intrinsic::tpc_mov_dual_group_unpack, {Income->getType(), Pred->getType()});
  return CGF->Builder.CreateCall(
      Callee, {Src, WrEn, Switches, Income, Pred, Polarity});
}

// float64 v_f32_mov_dual_group_pack_vb (float64 a, int switches, float64 income,
//                                       bool64 predicate, bool polarity);
static Value *emit_MOV_DUAL_GROUP_PACK(CodeGenFunction *CGF, unsigned BuiltinID,
                                       const CallExpr *E, ReturnValueSlot ReturnValue,
                                       llvm::Triple::ArchType Arch) {
  Value *Src = CGF->EmitScalarExpr(E->getArg(0));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(1));
  Value *Income = CGF->EmitScalarExpr(E->getArg(2));
  Value *Pred = emitPredicate(CGF, E->getArg(3));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(4));
  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_dual_group_pack,
                                           { Income->getType(),
                                             Pred->getType() });
  return CGF->Builder.CreateCall(Callee, { Src, Switches, Income, Pred, Polarity });
}


// uint32_t_pair_t u32_udiv_step(uint32_t a, uint32_t step,  int switches, uint32_t_pair_t income, bool predicate, bool polarity);
//
static Value *emit_UDIV_STEP(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  if (!CGF->getContext().getTargetInfo().hasFeature("greco") &&
      !E->getArg(1)->isConstantInitializer(CGF->getContext(), false))
    report_fatal_error("The step in UDIV_STEP or UDIV_4STEP must be a "
                       "constant on Gaudi, GaudiB, Goya architectures.");

  Value* Src  = CGF->EmitScalarExpr(E->getArg(0));
  Value* Step = CGF->EmitScalarExpr(E->getArg(1));
  Value* Sw   = CGF->EmitScalarExpr(E->getArg(2));
  Value* DT =  llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(0)->getType()));
  Value *Income = emitOperand(CGF, E->getArg(3));
  Value *Pred = emitOperand(CGF, E->getArg(4));
  Value *Polarity = emitOperand(CGF, E->getArg(5));

  SmallVector<llvm::Value *, 7> Args;
  Args.push_back(Src);
  Args.push_back(Step);
  Args.push_back(DT);
  Args.push_back(Sw);
  Args.push_back(Income);
  Args.push_back(Pred);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_udiv_step,
                                           { Income->getType(), Src->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);

  if (Multiplicity == 0)
    return Result;
  Result = getStructFieldFromDoubleScalarRegister(*CGF, FEResultTy, Result);
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


static Value *emit_UDIV(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  bool IsBoth = false;
  unsigned DivModeMask = TPCII::SW_GROUP_DIV_MODE;
  switch (BuiltinID) {
  case TPC::BIu32_udiv_both:
  case TPC::BIu16_udiv_both:
  case TPC::BIu8_udiv_both:
    IsBoth = true;
    break;
  }

  Expr::EvalResult ResVal;
  bool R = E->getArg(2)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (IsBoth) {
    SwitchVal &= ~DivModeMask;
    SwitchVal |= TPCII::SW_DIV_MODE_BOTH;
  }
  Value *SrcA = CGF->EmitScalarExpr(E->getArg(0));
  Value *SrcB = CGF->EmitScalarExpr(E->getArg(1));
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty,
                                     getOptypeValue(E->getArg(0)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(4));
  Value *Polarity = emitPredicate(CGF, E->getArg(5));

  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(3));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_udiv,
                                           { ResultTy,
                                             SrcA->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {SrcA, SrcB, DT, Switches, Income, Predicate, Polarity});
  assert(Result);

  if (Multiplicity == 0)
    return Result;
  assert(Multiplicity == 2);
  Result = getStructFieldFromDoubleScalarRegister(*CGF, FEResultTy, Result);
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;

}

static Value *emit_MOV_GROUP(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  Value *Src = CGF->EmitScalarExpr(E->getArg(0));
  Value *Imm = CGF->EmitScalarExpr(E->getArg(1));
  Value *Sw = CGF->EmitScalarExpr(E->getArg(2));
  Value *Income = CGF->EmitScalarExpr(E->getArg(3));
  Value *Pred = emitPredicate(CGF, E->getArg(4));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(5));
  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_group,
                                          { CGF->ConvertType(E->getType()),
                                            CGF->ConvertType(E->getArg(0)->getType()),
                                            Pred->getType() });
  return CGF->Builder.CreateCall(Callee, {Src, Imm, Sw, Income, Pred, Polarity});
}

static Value *emit_EVENT(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  Value *Src  = CGF->EmitScalarExpr(E->getArg(0));
  Value *Sw   = CGF->EmitScalarExpr(E->getArg(1));
  Value *Pred =  emitPredicate(CGF, E->getArg(2));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(3));
  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_event);
  return CGF->Builder.CreateCall(Callee, {Src, Sw, Pred, Polarity});
}

// float128 v_f32_sel2_less_f32_vb(float64 a, float64 b, float64 c, float64 d, int switches, float128 income, bool64 predicate, bool polarity);
//
static Value *emit_SEL(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch, unsigned IID) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Adjust FE operands.
  const Expr *ASrcA = E->getArg(0);
  const Expr *ASrcB = E->getArg(1);
  const Expr *ASrcC = E->getArg(2);
  const Expr *ASrcD = E->getArg(3);

  if (auto *Cast = dyn_cast<ImplicitCastExpr>(ASrcB))
    if (Cast->getCastKind() == CastKind::CK_VectorSplat)
      ASrcB = Cast->getSubExpr();
  if (ASrcB->getType()->isVectorType())
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(ASrcD))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        ASrcD = Cast->getSubExpr();

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Operands.
  Value *SrcA = CGF->EmitScalarExpr(ASrcA);
  Value *SrcB = CGF->EmitScalarExpr(ASrcB);
  Value *SrcC = CGF->EmitScalarExpr(ASrcC);
  Value *SrcD = CGF->EmitScalarExpr(ASrcD);
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(ASrcA->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(IID,
                                           { ResultTy,
                                             SrcA->getType(),
                                             SrcB->getType(),
                                             SrcC->getType(),
                                             SrcD->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {SrcA, SrcB, SrcC, SrcD, DT, Switches, Income, Predicate, Polarity});
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// float s_f32_ld_l (uint32_t addr, int switches, float income, bool predicate, bool polarity);
//
static Value *emit_LD_L(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned AddrOpNum = 0;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  assert(NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  Value *Addr = CGF->EmitScalarExpr(E->getArg(AddrOpNum));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_ld_l, { ResultTy });

  // If we are reading semaphore value from MMIO memory then mark the call
  // of ld_l intrinsic with 'hasSideEffects' in order to not optimize out
  // the call at Early CSE.
  bool isGetSemaphore = false;
  ConstantInt *AddrCI = dyn_cast<ConstantInt>(Addr);
  if (AddrCI) {
    if (SwitchVal == TPCII::SW_MMIO) {
      unsigned AddrI = AddrCI->getZExtValue();
      unsigned tpc_semaphore_addr = 0x808;
      const TargetInfo &TI = CGF->getContext().getTargetInfo();
      if (TI.hasFeature("goya")) {
        tpc_semaphore_addr = 0x808;
      } else if (TI.hasFeature("gaudi") || TI.hasFeature("gaudib")) {
        tpc_semaphore_addr = 0x908;
      } else if (TI.hasFeature("greco")) {
        tpc_semaphore_addr = 0xDB4U;
      } else if (TI.hasFeature("gaudi2")) {
        tpc_semaphore_addr = 0xDB4U;
      } else if (TI.hasFeature("doron1")) {
        tpc_semaphore_addr = 0xDB4U;
      }
      if (AddrI == tpc_semaphore_addr) {
        isGetSemaphore = true;
      }
    }
  }
  if (isGetSemaphore) {
    Callee->setSpeculatable();
    Callee->removeAttribute(AttributeList::FunctionIndex, Attribute::ReadOnly);
  }

  return CGF->Builder.CreateCall(Callee,
      {Addr, Switches, Income, Predicate, Polarity});
}


// float s_f32_ld_g (uint32_t addr, int switches, float income, bool predicate, bool polarity);
// int5 i_i32_ld_g(uint32_t addr, int dimmask, int switches, int5 income, bool predicate, bool polarity);
//
  static Value *emit_LD_G(CodeGenFunction * CGF, unsigned IntrinsicID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch, bool check_exclusive_read_write = false) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned AddrOpNum = 0;
  const unsigned DimMaskOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  bool doron1 = CGF->getContext().getTargetInfo().hasFeature("doron1");
  bool bv64   = doron1 && (IntrinsicID == TPC::BIs_i32_x2_ld_g || IntrinsicID == TPC::BIs_u32_x2_ld_g);
  bv64 ? assert(Multiplicity == 2) : assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (doron1 && check_exclusive_read_write && (SwitchVal & TPCII::SW_EXC)) {
      SwitchVal |= TPCII::SW_L0CS;
  }

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  SmallVector<llvm::Value *, 6> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(AddrOpNum)));
  if (IntrinsicID == TPC::BIi_i32_ld_g)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(Switches);

  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (IntrinsicID != TPC::BIi_i32_ld_g && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee;
  if (IntrinsicID == TPC::BIi_i32_ld_g)
    Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_ld_g_int5);
  else
    Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_ld_g, {ResultTy, Predicate->getType()});

  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);
  if (bv64) {
    assert(!ReturnValue.isNull());
    Result = getStructFieldFromDoubleScalarRegister(*CGF, CGF->ConvertType(E->getType()), Result);
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  }

  return Result;
}


static Value *emit_LD_G_P(CodeGenFunction *CGF, unsigned IntrinsicID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned AddrOpNum = 0;
  const unsigned SizeOpNum = 1;
  const unsigned OffsetOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  const unsigned SwitchMask = TPCII::SW_PARTIAL_SRCB | TPCII::SW_L0CS;
  SwitchVal &= SwitchMask;
  SwitchVal |= TPCII::SW_PARTIAL_SRCB;

  SmallVector<llvm::Value *, 6> Args;
  Args.push_back(CGF->EmitScalarExpr(E->getArg(AddrOpNum)));

  Value *Size = CGF->EmitScalarExpr(E->getArg(SizeOpNum));
  Value *Offset = CGF->EmitScalarExpr(E->getArg(OffsetOpNum));
  Size = CGF->Builder.CreateZExt(Size, CGF->Int32Ty);
  Offset = CGF->Builder.CreateZExt(Offset, CGF->Int32Ty);
  Offset = CGF->Builder.CreateShl(Offset, ConstantInt::get(CGF->Int32Ty, 8));
  Value *SizeOff = CGF->Builder.CreateOr(Size, Offset);
  Args.push_back(SizeOff);

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  Args.push_back(Switches);
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee =
      CGF->CGM.getIntrinsic(Intrinsic::tpc_ld_g_partial,
                            {ResultTy, Predicate->getType()});

  return CGF->Builder.CreateCall(Callee, Args);
}


static Value *emit_LD_G_P_INC(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned AddrOpNum = 0;
  const unsigned SizeOpNum = 1;
  const unsigned OffsetOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  const auto *PtrTy = cast<clang::PointerType>(E->getArg(AddrOpNum)->getType());
  const auto *PointeeTy = cast<clang::PointerType>(PtrTy->getPointeeType());
  Value *AddrPtr = CGF->EmitScalarExpr(E->getArg(AddrOpNum));
  MaybeAlign MAlign = AddrPtr->getPointerAlignment(CGF->CGM.getDataLayout());
  unsigned AlignValue = 1;
  if (MAlign) {
    llvm::Align A = *MAlign;
    AlignValue = A.value();
  }

  SmallVector<llvm::Value *, 6> Args;

  Address Addr0 = CGF->EmitLoadOfPointer(
    Address(AddrPtr, CharUnits::fromQuantity(AlignValue)),
    cast<clang::PointerType>(E->getArg(0)->getType()));
  Args.push_back(Addr0.getPointer());

  // Read value.
  Value *Income = CGF->EmitScalarExpr(E->getArg(IncomeOpNum));
  unsigned ValueSize = Income->getType()->getScalarSizeInBits();

  // Determine increment value.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  const unsigned SwitchMask = TPCII::SW_PARTIAL_SRCB | TPCII::SW_L0CS |
      TPCII::SW_INC_VAL;
  SwitchVal &= SwitchMask;
  unsigned IncVal;
  if ((SwitchVal & TPCII::SW_INC_VAL) == TPCII::SW_INC_0) {
    // SW_INC switch is not specified. Evaluate increment from the type size.
    switch (ValueSize) {
    case 1:
    case 8:
      SwitchVal |= TPCII::SW_INC_1;
      break;
    case 16:
      SwitchVal |= TPCII::SW_INC_2;
      break;
    case 32:
      SwitchVal |= TPCII::SW_INC_4;
      break;
    case 64:
      SwitchVal |= TPCII::SW_INC_8;
      break;
    default:
      llvm_unreachable("Invalid item size");
    }
    IncVal = ValueSize == 1 ? 1 : ValueSize / CHAR_BIT;
  } else {
    switch (SwitchVal & TPCII::SW_INC_VAL) {
    case TPCII::SW_INC_1:
      IncVal = 1;
      break;
    case TPCII::SW_INC_2:
      IncVal = 2;
      break;
    case TPCII::SW_INC_4:
      IncVal = 4;
      break;
    case TPCII::SW_INC_8:
      IncVal = 8;
      break;
    }
  }
  Value *IncValue = ConstantInt::get(CGF->Int32Ty, IncVal);
  Args.push_back(IncValue);

  Value *Size = CGF->EmitScalarExpr(E->getArg(SizeOpNum));
  Value *Offset = CGF->EmitScalarExpr(E->getArg(OffsetOpNum));
  Size = CGF->Builder.CreateZExt(Size, CGF->Int32Ty);
  Offset = CGF->Builder.CreateZExt(Offset, CGF->Int32Ty);
  Offset = CGF->Builder.CreateShl(Offset, ConstantInt::get(CGF->Int32Ty, 8));
  Value *SizeOff = CGF->Builder.CreateOr(Size, Offset);
  Args.push_back(SizeOff);

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Pred = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Args.push_back(Switches);
  Args.push_back(Income);
  Args.push_back(Pred);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(
    Intrinsic::tpc_ld_g_partial_inc, { Income->getType(),
                                       CGF->ConvertType(QualType(PointeeTy, 0)),
                                       Pred->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, Args);

  Address VarPtr(AddrPtr, CharUnits::fromQuantity(cast<AllocaInst>(AddrPtr)->getAlignment()));
  Value *PtrUpd = CGF->Builder.CreateExtractValue(Result, { 1 });
  CGF->EmitStoreOfScalar(PtrUpd, CGF->MakeAddrLValue(VarPtr, QualType(PtrTy, 0)));

  return CGF->Builder.CreateExtractValue(Result, { 0 });
}


// float s_f32_ld_g_inc(__global float **addr, int switches, float income, bool predicate, bool polarity);
//
static Value *emit_LD_G_INC(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned AddrOpNum = 0;
  const unsigned DimMaskOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  const auto *PtrTy = cast<clang::PointerType>(E->getArg(AddrOpNum)->getType());
  const auto *PointeeTy = cast<clang::PointerType>(PtrTy->getPointeeType());
  Value *AddrPtr = CGF->EmitScalarExpr(E->getArg(AddrOpNum));
  MaybeAlign MAlign = AddrPtr->getPointerAlignment(CGF->CGM.getDataLayout());
  unsigned AlignValue = 1;
  if (MAlign) {
    llvm::Align A = *MAlign;
    AlignValue = A.value();
  }
  Address Addr0 = CGF->EmitLoadOfPointer(
    Address(AddrPtr, CharUnits::fromQuantity(AlignValue)),
    cast<clang::PointerType>(E->getArg(AddrOpNum)->getType()));
  Value *DimMask = nullptr;
  if (BuiltinID == TPC::BIi_i32_ld_g_inc)
    DimMask = CGF->EmitScalarExpr(E->getArg(DimMaskOpNum));

  // Read value.
  Value *Income = emitOperand(CGF, E->getArg(IncomeOpNum));

  unsigned ValueSize;
  bool bv64 = BuiltinID == TPC::BIs_i32_x2_ld_g_inc ||
              BuiltinID == TPC::BIs_u32_x2_ld_g_inc;
  if (bv64) {
    ValueSize = 64;
  } else {
    ValueSize = Income->getType()->getScalarSizeInBits();
  }

  // Determine increment value.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  unsigned IncVal;
  if ((SwitchVal & TPCII::SW_INC_VAL) == TPCII::SW_INC_0) {
    // SW_INC switch is not specified. Evaluate increment from the type size.
    switch (ValueSize) {
    case 1:
    case 8:
      SwitchVal |= TPCII::SW_INC_1;
      break;
    case 16:
      SwitchVal |= TPCII::SW_INC_2;
      break;
    case 32:
      SwitchVal |= TPCII::SW_INC_4;
      break;
    case 64:
      SwitchVal |= TPCII::SW_INC_8;
      break;
    default:
      llvm_unreachable("Invalid item size");
    }
    IncVal = ValueSize == 1 ? 1 : ValueSize / CHAR_BIT;
  } else {
    switch (SwitchVal & TPCII::SW_INC_VAL) {
    case TPCII::SW_INC_1:
      IncVal = 1;
      break;
    case TPCII::SW_INC_2:
      IncVal = 2;
      break;
    case TPCII::SW_INC_4:
      IncVal = 4;
      break;
    case TPCII::SW_INC_8:
      IncVal = 8;
      break;
    }
  }

  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *IncValue = ConstantInt::get(CGF->Int32Ty, IncVal);
  Value *Pred = CGF->EvaluateExprAsBool(E->getArg(PredOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));

  Function *Callee = BuiltinID != TPC::BIi_i32_ld_g_inc ?
      CGF->CGM.getIntrinsic(Intrinsic::tpc_ld_g_inc,
                            { Income->getType(),
                              CGF->ConvertType(QualType(PointeeTy, 0)) }) :
      CGF->CGM.getIntrinsic(Intrinsic::tpc_ld_g_int5_inc);
  Value *Result = BuiltinID != TPC::BIi_i32_ld_g_inc ?
      CGF->Builder.CreateCall(Callee, { Addr0.getPointer(), IncValue, Switches, Income, Pred, Polarity }):
      CGF->Builder.CreateCall(Callee, { Addr0.getPointer(), IncValue, DimMask, Switches, Income, Pred, Polarity });

  CharUnits Alignment;
  if (isa<AllocaInst>(AddrPtr))
    Alignment = CharUnits::fromQuantity(cast<AllocaInst>(AddrPtr)->getAlignment());
  else
    Alignment = CharUnits::fromQuantity(4);
  Address VarPtr(AddrPtr, Alignment);
  Value *PtrUpd = CGF->Builder.CreateExtractValue(Result, { 1 });
  CGF->EmitStoreOfScalar(PtrUpd, CGF->MakeAddrLValue(VarPtr, QualType(PtrTy, 0)));

  Result = CGF->Builder.CreateExtractValue(Result, {0});
  if (bv64) {
    assert(!ReturnValue.isNull());
    Result = getStructFieldFromDoubleScalarRegister(*CGF, CGF->ConvertType(E->getType()), Result);
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  } else {
    return Result;
  }
}


// float64 v_f32_lookup_c0(uint64 a, int fid, int switches, float64 income, bool predicate, bool polarity);
//
static Value *emit_LOOKUP(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  assert(NumArgs == 6);
  const unsigned SrcOpNum = 0;
  const unsigned FuncIdOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches and intrinsic.
  unsigned IID;
  switch (BuiltinID) {
  case TPC::BIv_f32_lookup:
  case TPC::BIv_bf16_lookup:
  case TPC::BIv_f16_lookup:
  case TPC::BIv_i32_lookup:
  case TPC::BIv_u32_lookup:
  case TPC::BIv_i16_lookup:
  case TPC::BIv_u16_lookup:
  case TPC::BIv_i8_lookup:
    IID = Intrinsic::tpc_lookup;
    break;
  case TPC::BIv_f32_lookup_c0:
  case TPC::BIv_i32_lookup_c0:
  case TPC::BIv_u32_lookup_c0:
  case TPC::BIv_i16_lookup_c0:
  case TPC::BIv_u16_lookup_c0:
  case TPC::BIv_i8_lookup_c0:
    IID = Intrinsic::tpc_lookup_c0;
    break;
  case TPC::BIv_f32_lookup_c1c2:
  case TPC::BIv_i16_lookup_c1c2:
  case TPC::BIv_u16_lookup_c1c2:
  case TPC::BIv_i8_lookup_c1c2:
    IID = Intrinsic::tpc_lookup_c1c2;
    break;
  case TPC::BIv_f32_lookup_1c:
  case TPC::BIv_i32_lookup_1c:
  case TPC::BIv_u32_lookup_1c:
  case TPC::BIv_i16_lookup_1c:
  case TPC::BIv_u16_lookup_1c:
  case TPC::BIv_bf16_lookup_1c:
  case TPC::BIv_f16_lookup_1c:
    IID = Intrinsic::tpc_lookup_1c;
    break;
  case TPC::BIv_f32_lookup_2c:
  case TPC::BIv_i32_lookup_2c:
  case TPC::BIv_u32_lookup_2c:
  case TPC::BIv_i16_lookup_2c:
  case TPC::BIv_u16_lookup_2c:
  case TPC::BIv_bf16_lookup_2c:
  case TPC::BIv_f16_lookup_2c:
    IID = Intrinsic::tpc_lookup_2c;
    break;
  default:
    llvm_unreachable("Unhandled MOV intrinsic");
  }
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Operands.
  Value *Src = CGF->EmitScalarExpr(E->getArg(SrcOpNum));
  Value *FuncId    = CGF->EmitScalarExpr(E->getArg(FuncIdOpNum));
  Value *SwitchSet = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = CGF->EvaluateExprAsBool(E->getArg(PredOpNum));
  Value *Polarity  = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));

  // Unless LOOKUP_DT == BV32 lookup is always updating.
  bool Update = false;
  const TargetInfo &TI = CGF->getContext().getTargetInfo();
  if (TI.hasFeature("goya"))
    Update = (SwitchVal & TPCII::SW_LOOKUP_G1) != TPCII::SW_BV32;
  else
    Update = (SwitchVal & TPCII::SW_LOOKUP_G2) != TPCII::SW_BV32;
  Value *Income;
  if (!Update && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(IID, { ResultTy, Src->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src, FuncId, SwitchSet, Income, Predicate, Polarity});
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// int64 v_convert_f32_to_i32_b(float64 src, int switches, int64 income, bool predicate, bool polarity);
// short128 v_convert_f32_to_i16_b(float64 src, const int lane, int switches, short128 income, bool predicate, bool polarity);
//
static Value *emit_CONVERT(CodeGenFunction *CGF, unsigned IntrinsicID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned LaneSelNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  bool HasLaneSel = NumArgs == 6;

  const TargetInfo &TI = CGF->getContext().getTargetInfo();

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches.
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_TO_TYPE | TPCII::SW_X2_CONVERT
      | TPCII::SW_X4_CONVERT | TPCII::SW_NUM_LANES_SRCB_G5;
  bool Updates = 0;
  TPCII::OpType DT = TPCII::OpType::Invalid;
  switch (IntrinsicID) {
  case TPC::BIs_convert_f32_to_bf16:
  case TPC::BIs_convert_f32_to_f16:
  case TPC::BIs_convert_f32_to_i32:
  case TPC::BIs_convert_f32_to_i16:
  case TPC::BIs_convert_f32_to_i8:
  case TPC::BIs_convert_bf16_to_f32:
  case TPC::BIs_convert_bf16_to_f16:
  case TPC::BIs_convert_bf16_to_i16:
  case TPC::BIs_convert_bf16_to_i8:
  case TPC::BIs_convert_f16_to_f32:
  case TPC::BIs_convert_f16_to_bf16:
  case TPC::BIs_convert_f16_to_i16:
  case TPC::BIs_convert_f16_to_i8:
  case TPC::BIs_convert_i32_to_f32:
  case TPC::BIs_convert_i32_to_bf16:
  case TPC::BIs_convert_i32_to_f16:
  case TPC::BIs_convert_i32_to_u32:
  case TPC::BIs_convert_i32_to_u8:
  case TPC::BIs_convert_i16_to_f32:
  case TPC::BIs_convert_i16_to_bf16:
  case TPC::BIs_convert_i16_to_f16:
  case TPC::BIs_convert_i16_to_i32:
  case TPC::BIs_convert_i16_to_u32:
  case TPC::BIs_convert_i16_to_u16:
  case TPC::BIs_convert_i16_to_u8:
  case TPC::BIs_convert_u16_to_bf16:
  case TPC::BIs_convert_u16_to_f16:
  case TPC::BIs_convert_i8_to_f32:
  case TPC::BIs_convert_i8_to_bf16:
  case TPC::BIs_convert_i8_to_f16:
  case TPC::BIs_convert_i8_to_i32:
  case TPC::BIs_convert_i8_to_u32:
  case TPC::BIs_convert_i8_to_i16:
  case TPC::BIs_convert_i8_to_u16:
  case TPC::BIs_convert_i8_to_u8:
  case TPC::BIs_convert_u8_to_f32:
  case TPC::BIs_convert_u8_to_bf16:
  case TPC::BIs_convert_u8_to_i32:
  case TPC::BIs_convert_u8_to_u32:
  case TPC::BIs_convert_u8_to_i16:
  case TPC::BIs_convert_u8_to_u16:
  case TPC::BIs_convert_f32_to_u32:
  case TPC::BIs_convert_f32_to_u16:
  case TPC::BIs_convert_f32_to_u8:
  case TPC::BIs_convert_f32_to_f8:
  case TPC::BIs_convert_f32_to_h8:
  case TPC::BIs_convert_bf16_to_i32:
  case TPC::BIs_convert_bf16_to_u32:
  case TPC::BIs_convert_bf16_to_u16:
  case TPC::BIs_convert_bf16_to_u8:
  case TPC::BIs_convert_bf16_to_f8:
  case TPC::BIs_convert_bf16_to_h8:
  case TPC::BIs_convert_f16_to_i32:
  case TPC::BIs_convert_f16_to_u32:
  case TPC::BIs_convert_f16_to_u16:
  case TPC::BIs_convert_f16_to_u8:
  case TPC::BIs_convert_f16_to_f8:
  case TPC::BIs_convert_f16_to_h8:
  case TPC::BIs_convert_f8_to_f32:
  case TPC::BIs_convert_f8_to_bf16:
  case TPC::BIs_convert_f8_to_f16:
  case TPC::BIs_convert_f8_to_i32:
  case TPC::BIs_convert_f8_to_u32:
  case TPC::BIs_convert_f8_to_i16:
  case TPC::BIs_convert_f8_to_u16:
  case TPC::BIs_convert_f8_to_i8:
  case TPC::BIs_convert_f8_to_u8:
  case TPC::BIs_convert_f8_to_h8:
  case TPC::BIs_convert_h8_to_f32:
  case TPC::BIs_convert_h8_to_bf16:
  case TPC::BIs_convert_h8_to_f16:
  case TPC::BIs_convert_h8_to_i32:
  case TPC::BIs_convert_h8_to_u32:
  case TPC::BIs_convert_h8_to_i16:
  case TPC::BIs_convert_h8_to_u16:
  case TPC::BIs_convert_h8_to_i8:
  case TPC::BIs_convert_h8_to_u8:
  case TPC::BIs_convert_h8_to_f8:
  case TPC::BIs_convert_i32_to_i16:
  case TPC::BIs_convert_i32_to_u16:
  case TPC::BIs_convert_i32_to_i8:
  case TPC::BIs_convert_i32_to_f8:
  case TPC::BIs_convert_i32_to_h8:
  case TPC::BIs_convert_u32_to_f32:
  case TPC::BIs_convert_u32_to_bf16:
  case TPC::BIs_convert_u32_to_f16:
  case TPC::BIs_convert_u32_to_i32:
  case TPC::BIs_convert_u32_to_i16:
  case TPC::BIs_convert_u32_to_u16:
  case TPC::BIs_convert_u32_to_i8:
  case TPC::BIs_convert_u32_to_u8:
  case TPC::BIs_convert_u32_to_f8:
  case TPC::BIs_convert_u32_to_h8:
  case TPC::BIs_convert_i16_to_i8:
  case TPC::BIs_convert_i16_to_f8:
  case TPC::BIs_convert_i16_to_h8:
  case TPC::BIs_convert_u16_to_i32:
  case TPC::BIs_convert_u16_to_u32:
  case TPC::BIs_convert_u16_to_i16:
  case TPC::BIs_convert_u16_to_i8:
  case TPC::BIs_convert_u16_to_u8:
  case TPC::BIs_convert_u16_to_f32:
  case TPC::BIs_convert_u16_to_f8:
  case TPC::BIs_convert_u16_to_h8:
  case TPC::BIs_convert_i8_to_f8:
  case TPC::BIs_convert_i8_to_h8:
  case TPC::BIs_convert_u8_to_i8:
  case TPC::BIs_convert_u8_to_f8:
  case TPC::BIs_convert_u8_to_h8:
    // Scalar conversion are always replacing.
    RequiredSwitches = 0;
    break;
  case TPC::BIs_convert_i4_to_i8:
    DT = TPCII::OpType::INT4;
    RequiredSwitches = 0;
    break;
  case TPC::BIs_convert_u4_to_u8:
    DT = TPCII::OpType::UINT4;
    RequiredSwitches = 0;
    break;
  case TPC::BIv_convert_f32_to_i32_b:
  case TPC::BIv_convert_f32_to_i32_vb:
  case TPC::BIv_convert_bf16_to_i16_b:
  case TPC::BIv_convert_bf16_to_i16_vb:
  case TPC::BIv_convert_bf16_to_f16_b:
  case TPC::BIv_convert_bf16_to_f16_vb:
  case TPC::BIv_convert_f16_to_bf16_b:
  case TPC::BIv_convert_f16_to_bf16_vb:
  case TPC::BIv_convert_f16_to_i16_b:
  case TPC::BIv_convert_f16_to_i16_vb:
  case TPC::BIv_convert_i32_to_f32_b:
  case TPC::BIv_convert_i32_to_f32_vb:
  case TPC::BIv_convert_i32_to_u32_b:
  case TPC::BIv_convert_i32_to_u32_vb:
  case TPC::BIv_convert_i16_to_u16_b:
  case TPC::BIv_convert_i16_to_u16_vb:
  case TPC::BIv_convert_i16_to_bf16_b:
  case TPC::BIv_convert_i16_to_bf16_vb:
  case TPC::BIv_convert_i16_to_f16_b:
  case TPC::BIv_convert_i16_to_f16_vb:
  case TPC::BIv_convert_u16_to_bf16_b:
  case TPC::BIv_convert_u16_to_bf16_vb:
  case TPC::BIv_convert_u16_to_f16_b:
  case TPC::BIv_convert_u16_to_f16_vb:
  case TPC::BIv_convert_i8_to_u8_b:
  case TPC::BIv_convert_i8_to_u8_vb:
  case TPC::BIv_convert_f32_to_u32_b:
  case TPC::BIv_convert_f32_to_u32_vb:
  case TPC::BIv_convert_bf16_to_u16_b:
  case TPC::BIv_convert_bf16_to_u16_vb:
  case TPC::BIv_convert_f16_to_u16_b:
  case TPC::BIv_convert_f16_to_u16_vb:
  case TPC::BIv_convert_u32_to_f32_b:
  case TPC::BIv_convert_u32_to_f32_vb:
  case TPC::BIv_convert_u32_to_i32_b:
  case TPC::BIv_convert_u32_to_i32_vb:
  case TPC::BIv_convert_u16_to_i16_b:
  case TPC::BIv_convert_u16_to_i16_vb:
  case TPC::BIv_convert_u8_to_i8_b:
  case TPC::BIv_convert_u8_to_i8_vb:
  case TPC::BIv_convert_f8_to_i8_b:
  case TPC::BIv_convert_f8_to_i8_vb:
  case TPC::BIv_convert_h8_to_i8_b:
  case TPC::BIv_convert_h8_to_i8_vb:
  case TPC::BIv_convert_f8_to_u8_b:
  case TPC::BIv_convert_f8_to_u8_vb:
  case TPC::BIv_convert_h8_to_u8_b:
  case TPC::BIv_convert_h8_to_u8_vb:
  case TPC::BIv_convert_f8_to_h8_b:
  case TPC::BIv_convert_f8_to_h8_vb:
  case TPC::BIv_convert_h8_to_f8_b:
  case TPC::BIv_convert_h8_to_f8_vb:
  case TPC::BIv_convert_i8_to_f8_b:
  case TPC::BIv_convert_i8_to_f8_vb:
  case TPC::BIv_convert_i8_to_h8_b:
  case TPC::BIv_convert_i8_to_h8_vb:
  case TPC::BIv_convert_u8_to_f8_b:
  case TPC::BIv_convert_u8_to_f8_vb:
  case TPC::BIv_convert_u8_to_h8_b:
  case TPC::BIv_convert_u8_to_h8_vb:
    // Sizes of target and source types are equal.
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    else
      RequiredSwitches = 0;
    break;
  case TPC::BIv_convert_f32_to_i16_all_b:
  case TPC::BIv_convert_f32_to_i16_all_vb:
  case TPC::BIv_convert_f32_to_i8_all_b:
  case TPC::BIv_convert_f32_to_i8_all_vb:
  case TPC::BIv_convert_f32_to_f16_all_b:
  case TPC::BIv_convert_f32_to_f16_all_vb:
  case TPC::BIv_convert_f32_to_bf16_all_b:
  case TPC::BIv_convert_f32_to_bf16_all_vb:
  case TPC::BIv_convert_bf16_to_f32_all_b:
  case TPC::BIv_convert_bf16_to_f32_all_vb:
  case TPC::BIv_convert_bf16_to_i8_all_b:
  case TPC::BIv_convert_bf16_to_i8_all_vb:
  case TPC::BIv_convert_f16_to_f32_all_b:
  case TPC::BIv_convert_f16_to_f32_all_vb:
  case TPC::BIv_convert_f16_to_i8_all_b:
  case TPC::BIv_convert_f16_to_i8_all_vb:
  case TPC::BIv_convert_i32_to_bf16_all_b:
  case TPC::BIv_convert_i32_to_bf16_all_vb:
  case TPC::BIv_convert_i32_to_f16_all_b:
  case TPC::BIv_convert_i32_to_f16_all_vb:
  case TPC::BIv_convert_i16_to_f32_all_b:
  case TPC::BIv_convert_i16_to_f32_all_vb:
  case TPC::BIv_convert_i16_to_i32_all_b:
  case TPC::BIv_convert_i16_to_i32_all_vb:
  case TPC::BIv_convert_i16_to_u32_all_b:
  case TPC::BIv_convert_i16_to_u32_all_vb:
  case TPC::BIv_convert_i16_to_u8_all_b:
  case TPC::BIv_convert_i16_to_u8_all_vb:
  case TPC::BIv_convert_i8_to_f32_all_b:
  case TPC::BIv_convert_i8_to_f32_all_vb:
  case TPC::BIv_convert_i8_to_i32_all_b:
  case TPC::BIv_convert_i8_to_i32_all_vb:
  case TPC::BIv_convert_i8_to_u32_all_b:
  case TPC::BIv_convert_i8_to_u32_all_vb:
  case TPC::BIv_convert_i8_to_i16_all_b:
  case TPC::BIv_convert_i8_to_i16_all_vb:
  case TPC::BIv_convert_i8_to_u16_all_b:
  case TPC::BIv_convert_i8_to_u16_all_vb:
  case TPC::BIv_convert_i8_to_bf16_all_b:
  case TPC::BIv_convert_i8_to_bf16_all_vb:
  case TPC::BIv_convert_i8_to_f16_all_b:
  case TPC::BIv_convert_i8_to_f16_all_vb:
  case TPC::BIv_convert_u8_to_f32_all_b:
  case TPC::BIv_convert_u8_to_f32_all_vb:
  case TPC::BIv_convert_u8_to_bf16_all_b:
  case TPC::BIv_convert_u8_to_bf16_all_vb:
  case TPC::BIv_convert_u8_to_i32_all_b:
  case TPC::BIv_convert_u8_to_i32_all_vb:
  case TPC::BIv_convert_u8_to_i16_all_b:
  case TPC::BIv_convert_u8_to_i16_all_vb:
  case TPC::BIv_convert_u8_to_u32_all_b:
  case TPC::BIv_convert_u8_to_u32_all_vb:
  case TPC::BIv_convert_u8_to_u16_all_b:
  case TPC::BIv_convert_u8_to_u16_all_vb:
  case TPC::BIv_convert_u8_to_f16_all_b:
  case TPC::BIv_convert_u8_to_f16_all_vb:
  case TPC::BIv_convert_f32_to_u16_all_b:
  case TPC::BIv_convert_f32_to_u16_all_vb:
  case TPC::BIv_convert_f32_to_u8_all_b:
  case TPC::BIv_convert_f32_to_u8_all_vb:
  case TPC::BIv_convert_bf16_to_i32_all_b:
  case TPC::BIv_convert_bf16_to_i32_all_vb:
  case TPC::BIv_convert_bf16_to_u32_all_b:
  case TPC::BIv_convert_bf16_to_u32_all_vb:
  case TPC::BIv_convert_bf16_to_u8_all_b:
  case TPC::BIv_convert_bf16_to_u8_all_vb:
  case TPC::BIv_convert_f16_to_u32_all_b:
  case TPC::BIv_convert_f16_to_u32_all_vb:
  case TPC::BIv_convert_f16_to_i32_all_b:
  case TPC::BIv_convert_f16_to_i32_all_vb:
  case TPC::BIv_convert_f16_to_u8_all_b:
  case TPC::BIv_convert_f16_to_u8_all_vb:
  case TPC::BIv_convert_i32_to_i16_all_b:
  case TPC::BIv_convert_i32_to_i16_all_vb:
  case TPC::BIv_convert_i32_to_u16_all_b:
  case TPC::BIv_convert_i32_to_u16_all_vb:
  case TPC::BIv_convert_i32_to_i8_all_b:
  case TPC::BIv_convert_i32_to_i8_all_vb:
  case TPC::BIv_convert_i32_to_u8_all_b:
  case TPC::BIv_convert_i32_to_u8_all_vb:
  case TPC::BIv_convert_u32_to_bf16_all_b:
  case TPC::BIv_convert_u32_to_bf16_all_vb:
  case TPC::BIv_convert_u32_to_f16_all_b:
  case TPC::BIv_convert_u32_to_f16_all_vb:
  case TPC::BIv_convert_u32_to_i16_all_b:
  case TPC::BIv_convert_u32_to_i16_all_vb:
  case TPC::BIv_convert_u32_to_u16_all_b:
  case TPC::BIv_convert_u32_to_u16_all_vb:
  case TPC::BIv_convert_u32_to_i8_all_b:
  case TPC::BIv_convert_u32_to_i8_all_vb:
  case TPC::BIv_convert_u32_to_u8_all_b:
  case TPC::BIv_convert_u32_to_u8_all_vb:
  case TPC::BIv_convert_i16_to_i8_all_b:
  case TPC::BIv_convert_i16_to_i8_all_vb:
  case TPC::BIv_convert_u16_to_f32_all_b:
  case TPC::BIv_convert_u16_to_f32_all_vb:
  case TPC::BIv_convert_u16_to_i32_all_b:
  case TPC::BIv_convert_u16_to_i32_all_vb:
  case TPC::BIv_convert_u16_to_u32_all_b:
  case TPC::BIv_convert_u16_to_u32_all_vb:
  case TPC::BIv_convert_u16_to_i8_all_b:
  case TPC::BIv_convert_u16_to_i8_all_vb:
  case TPC::BIv_convert_u16_to_u8_all_b:
  case TPC::BIv_convert_u16_to_u8_all_vb:
  case TPC::BIv_convert_f32_to_f8_all_b:
  case TPC::BIv_convert_f32_to_f8_all_vb:
  case TPC::BIv_convert_f32_to_h8_all_b:
  case TPC::BIv_convert_f32_to_h8_all_vb:
  case TPC::BIv_convert_bf16_to_f8_all_b:
  case TPC::BIv_convert_bf16_to_f8_all_vb:
  case TPC::BIv_convert_bf16_to_h8_all_b:
  case TPC::BIv_convert_bf16_to_h8_all_vb:
  case TPC::BIv_convert_f16_to_f8_all_b:
  case TPC::BIv_convert_f16_to_f8_all_vb:
  case TPC::BIv_convert_f16_to_h8_all_b:
  case TPC::BIv_convert_f16_to_h8_all_vb:
  case TPC::BIv_convert_f8_to_f32_all_b:
  case TPC::BIv_convert_f8_to_f32_all_vb:
  case TPC::BIv_convert_h8_to_f32_all_b:
  case TPC::BIv_convert_h8_to_f32_all_vb:
  case TPC::BIv_convert_f8_to_bf16_all_b:
  case TPC::BIv_convert_f8_to_bf16_all_vb:
  case TPC::BIv_convert_h8_to_bf16_all_b:
  case TPC::BIv_convert_h8_to_bf16_all_vb:
  case TPC::BIv_convert_f8_to_f16_all_b:
  case TPC::BIv_convert_f8_to_f16_all_vb:
  case TPC::BIv_convert_h8_to_f16_all_b:
  case TPC::BIv_convert_h8_to_f16_all_vb:
  case TPC::BIv_convert_f8_to_i32_all_b:
  case TPC::BIv_convert_f8_to_i32_all_vb:
  case TPC::BIv_convert_h8_to_i32_all_b:
  case TPC::BIv_convert_h8_to_i32_all_vb:
  case TPC::BIv_convert_f8_to_u32_all_b:
  case TPC::BIv_convert_f8_to_u32_all_vb:
  case TPC::BIv_convert_h8_to_u32_all_b:
  case TPC::BIv_convert_h8_to_u32_all_vb:
  case TPC::BIv_convert_f8_to_i16_all_b:
  case TPC::BIv_convert_f8_to_i16_all_vb:
  case TPC::BIv_convert_h8_to_i16_all_b:
  case TPC::BIv_convert_h8_to_i16_all_vb:
  case TPC::BIv_convert_f8_to_u16_all_b:
  case TPC::BIv_convert_f8_to_u16_all_vb:
  case TPC::BIv_convert_h8_to_u16_all_b:
  case TPC::BIv_convert_h8_to_u16_all_vb:
  case TPC::BIv_convert_i32_to_f8_all_b:
  case TPC::BIv_convert_i32_to_f8_all_vb:
  case TPC::BIv_convert_i32_to_h8_all_b:
  case TPC::BIv_convert_i32_to_h8_all_vb:
  case TPC::BIv_convert_u32_to_f8_all_b:
  case TPC::BIv_convert_u32_to_f8_all_vb:
  case TPC::BIv_convert_u32_to_h8_all_b:
  case TPC::BIv_convert_u32_to_h8_all_vb:
  case TPC::BIv_convert_i16_to_f8_all_b:
  case TPC::BIv_convert_i16_to_f8_all_vb:
  case TPC::BIv_convert_i16_to_h8_all_b:
  case TPC::BIv_convert_i16_to_h8_all_vb:
  case TPC::BIv_convert_u16_to_f8_all_b:
  case TPC::BIv_convert_u16_to_f8_all_vb:
  case TPC::BIv_convert_u16_to_h8_all_b:
  case TPC::BIv_convert_u16_to_h8_all_vb:
    // Sizes of target and source types are equal.
    RequiredSwitches = TPCII::SW_ALL_LANES;
    break;
  case TPC::BIv_convert_i4_to_i8_all_b:
  case TPC::BIv_convert_i4_to_i8_all_vb:
    RequiredSwitches = TPCII::SW_ALL_LANES;
    DT = TPCII::OpType::INT4;
    break;
  case TPC::BIv_convert_u4_to_u8_all_b:
  case TPC::BIv_convert_u4_to_u8_all_vb:
    RequiredSwitches = TPCII::SW_ALL_LANES;
    DT = TPCII::OpType::UINT4;
    break;
  case TPC::BIv_convert_bf16_to_f32_b:
  case TPC::BIv_convert_bf16_to_f32_vb:
  case TPC::BIv_convert_f16_to_f32_b:
  case TPC::BIv_convert_f16_to_f32_vb:
    // Upconverts use only one lane.
    if (TI.hasFeature("gaudib") || TI.hasFeature("greco") ||
        TI.hasFeature("gaudi2") || TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    else
      RequiredSwitches = 0;
    break;
  case TPC::BIv_convert_i16_to_f32_b:
  case TPC::BIv_convert_i16_to_f32_vb:
  case TPC::BIv_convert_i16_to_i32_b:
  case TPC::BIv_convert_i16_to_i32_vb:
  case TPC::BIv_convert_i16_to_u32_b:
  case TPC::BIv_convert_i16_to_u32_vb:
  case TPC::BIv_convert_i8_to_f32_b:
  case TPC::BIv_convert_i8_to_f32_vb:
  case TPC::BIv_convert_i8_to_i32_b:
  case TPC::BIv_convert_i8_to_i32_vb:
  case TPC::BIv_convert_i8_to_u32_b:
  case TPC::BIv_convert_i8_to_u32_vb:
  case TPC::BIv_convert_i8_to_i16_b:
  case TPC::BIv_convert_i8_to_i16_vb:
  case TPC::BIv_convert_i8_to_u16_b:
  case TPC::BIv_convert_i8_to_u16_vb:
  case TPC::BIv_convert_i8_to_bf16_b:
  case TPC::BIv_convert_i8_to_bf16_vb:
  case TPC::BIv_convert_i8_to_f16_b:
  case TPC::BIv_convert_i8_to_f16_vb:
  case TPC::BIv_convert_u8_to_f32_b:
  case TPC::BIv_convert_u8_to_f32_vb:
  case TPC::BIv_convert_u8_to_bf16_b:
  case TPC::BIv_convert_u8_to_bf16_vb:
  case TPC::BIv_convert_u8_to_i32_b:
  case TPC::BIv_convert_u8_to_i32_vb:
  case TPC::BIv_convert_u8_to_i16_b:
  case TPC::BIv_convert_u8_to_i16_vb:
  case TPC::BIv_convert_u8_to_u32_b:
  case TPC::BIv_convert_u8_to_u32_vb:
  case TPC::BIv_convert_u8_to_u16_b:
  case TPC::BIv_convert_u8_to_u16_vb:
  case TPC::BIv_convert_u8_to_f16_b:
  case TPC::BIv_convert_u8_to_f16_vb:
  case TPC::BIv_convert_u16_to_i32_b:
  case TPC::BIv_convert_u16_to_i32_vb:
  case TPC::BIv_convert_u16_to_u32_b:
  case TPC::BIv_convert_u16_to_u32_vb:
  case TPC::BIv_convert_u16_to_f32_b:
  case TPC::BIv_convert_u16_to_f32_vb:
  case TPC::BIv_convert_bf16_to_i32_b:
  case TPC::BIv_convert_bf16_to_i32_vb:
  case TPC::BIv_convert_bf16_to_u32_b:
  case TPC::BIv_convert_bf16_to_u32_vb:
  case TPC::BIv_convert_f16_to_i32_b:
  case TPC::BIv_convert_f16_to_i32_vb:
  case TPC::BIv_convert_f16_to_u32_b:
  case TPC::BIv_convert_f16_to_u32_vb:
  case TPC::BIv_convert_f8_to_f32_b:
  case TPC::BIv_convert_f8_to_f32_vb:
  case TPC::BIv_convert_h8_to_f32_b:
  case TPC::BIv_convert_h8_to_f32_vb:
  case TPC::BIv_convert_f8_to_bf16_b:
  case TPC::BIv_convert_f8_to_bf16_vb:
  case TPC::BIv_convert_h8_to_bf16_b:
  case TPC::BIv_convert_h8_to_bf16_vb:
  case TPC::BIv_convert_f8_to_f16_b:
  case TPC::BIv_convert_f8_to_f16_vb:
  case TPC::BIv_convert_h8_to_f16_b:
  case TPC::BIv_convert_h8_to_f16_vb:
  case TPC::BIv_convert_f8_to_i32_b:
  case TPC::BIv_convert_f8_to_i32_vb:
  case TPC::BIv_convert_h8_to_i32_b:
  case TPC::BIv_convert_h8_to_i32_vb:
  case TPC::BIv_convert_f8_to_u32_b:
  case TPC::BIv_convert_f8_to_u32_vb:
  case TPC::BIv_convert_h8_to_u32_b:
  case TPC::BIv_convert_h8_to_u32_vb:
  case TPC::BIv_convert_f8_to_i16_b:
  case TPC::BIv_convert_f8_to_i16_vb:
  case TPC::BIv_convert_h8_to_i16_b:
  case TPC::BIv_convert_h8_to_i16_vb:
  case TPC::BIv_convert_f8_to_u16_b:
  case TPC::BIv_convert_f8_to_u16_vb:
  case TPC::BIv_convert_h8_to_u16_b:
  case TPC::BIv_convert_h8_to_u16_vb:
    // Upconverts use only one lane.
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    else
      RequiredSwitches = 0;
    break;
  case TPC::BIv_convert_i4_to_i8_b:
  case TPC::BIv_convert_i4_to_i8_vb:
    DT = TPCII::OpType::INT4;
    RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    break;
  case TPC::BIv_convert_u4_to_u8_b:
  case TPC::BIv_convert_u4_to_u8_vb:
    DT = TPCII::OpType::UINT4;
    RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    break;
  case TPC::BIv_convert_f32_to_bf16_b:
  case TPC::BIv_convert_f32_to_bf16_vb:
  case TPC::BIv_convert_f32_to_f16_b:
  case TPC::BIv_convert_f32_to_f16_vb:
    // Downconverts require lane specification.
    if (TI.hasFeature("gaudib") || TI.hasFeature("greco") ||
        TI.hasFeature("gaudi2") || TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    else
      RequiredSwitches = 0;
    assert(HasLaneSel);
    Updates = true;
    break;
  case TPC::BIv_convert_f32_to_i16_b:
  case TPC::BIv_convert_f32_to_i16_vb:
  case TPC::BIv_convert_f32_to_i8_b:
  case TPC::BIv_convert_f32_to_i8_vb:
  case TPC::BIv_convert_bf16_to_i8_b:
  case TPC::BIv_convert_bf16_to_i8_vb:
  case TPC::BIv_convert_f16_to_i8_b:
  case TPC::BIv_convert_f16_to_i8_vb:
  case TPC::BIv_convert_i32_to_bf16_b:
  case TPC::BIv_convert_i32_to_bf16_vb:
  case TPC::BIv_convert_i32_to_f16_b:
  case TPC::BIv_convert_i32_to_f16_vb:
  case TPC::BIv_convert_i32_to_u8_b:
  case TPC::BIv_convert_i32_to_u8_vb:
  case TPC::BIv_convert_i16_to_u8_b:
  case TPC::BIv_convert_i16_to_u8_vb:
  case TPC::BIv_convert_f32_to_u16_b:
  case TPC::BIv_convert_f32_to_u16_vb:
  case TPC::BIv_convert_f32_to_u8_b:
  case TPC::BIv_convert_f32_to_u8_vb:
  case TPC::BIv_convert_bf16_to_u8_b:
  case TPC::BIv_convert_bf16_to_u8_vb:
  case TPC::BIv_convert_f16_to_u8_b:
  case TPC::BIv_convert_f16_to_u8_vb:
  case TPC::BIv_convert_i32_to_i16_b:
  case TPC::BIv_convert_i32_to_i16_vb:
  case TPC::BIv_convert_i32_to_u16_b:
  case TPC::BIv_convert_i32_to_u16_vb:
  case TPC::BIv_convert_i32_to_i8_b:
  case TPC::BIv_convert_i32_to_i8_vb:
  case TPC::BIv_convert_u32_to_bf16_b:
  case TPC::BIv_convert_u32_to_bf16_vb:
  case TPC::BIv_convert_u32_to_f16_b:
  case TPC::BIv_convert_u32_to_f16_vb:
  case TPC::BIv_convert_u32_to_i16_b:
  case TPC::BIv_convert_u32_to_i16_vb:
  case TPC::BIv_convert_u32_to_u16_b:
  case TPC::BIv_convert_u32_to_u16_vb:
  case TPC::BIv_convert_u32_to_i8_b:
  case TPC::BIv_convert_u32_to_i8_vb:
  case TPC::BIv_convert_u32_to_u8_b:
  case TPC::BIv_convert_u32_to_u8_vb:
  case TPC::BIv_convert_i16_to_i8_b:
  case TPC::BIv_convert_i16_to_i8_vb:
  case TPC::BIv_convert_u16_to_i8_b:
  case TPC::BIv_convert_u16_to_i8_vb:
  case TPC::BIv_convert_u16_to_u8_b:
  case TPC::BIv_convert_u16_to_u8_vb:
  case TPC::BIv_convert_f32_to_f8_b:
  case TPC::BIv_convert_f32_to_f8_vb:
  case TPC::BIv_convert_f32_to_h8_b:
  case TPC::BIv_convert_f32_to_h8_vb:
  case TPC::BIv_convert_bf16_to_f8_b:
  case TPC::BIv_convert_bf16_to_f8_vb:
  case TPC::BIv_convert_bf16_to_h8_b:
  case TPC::BIv_convert_bf16_to_h8_vb:
  case TPC::BIv_convert_f16_to_f8_b:
  case TPC::BIv_convert_f16_to_f8_vb:
  case TPC::BIv_convert_f16_to_h8_b:
  case TPC::BIv_convert_f16_to_h8_vb:
  case TPC::BIv_convert_i32_to_f8_b:
  case TPC::BIv_convert_i32_to_f8_vb:
  case TPC::BIv_convert_i32_to_h8_b:
  case TPC::BIv_convert_i32_to_h8_vb:
  case TPC::BIv_convert_u32_to_f8_b:
  case TPC::BIv_convert_u32_to_f8_vb:
  case TPC::BIv_convert_u32_to_h8_b:
  case TPC::BIv_convert_u32_to_h8_vb:
  case TPC::BIv_convert_i16_to_f8_b:
  case TPC::BIv_convert_i16_to_f8_vb:
  case TPC::BIv_convert_i16_to_h8_b:
  case TPC::BIv_convert_i16_to_h8_vb:
  case TPC::BIv_convert_u16_to_f8_b:
  case TPC::BIv_convert_u16_to_f8_vb:
  case TPC::BIv_convert_u16_to_h8_b:
  case TPC::BIv_convert_u16_to_h8_vb:
    // Downconverts require lane specification.
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    else
      RequiredSwitches = 0;
    assert(HasLaneSel);
    Updates = true;
    break;
  case TPC::BIv_convert_f32_to_bf16_single_b:
  case TPC::BIv_convert_f32_to_bf16_single_vb:
  case TPC::BIv_convert_f32_to_f16_single_b:
  case TPC::BIv_convert_f32_to_f16_single_vb:
    RequiredSwitches = TPCII::SW_SINGLE_LANE_SRCB;
    Updates = true;
    break;
  case TPC::BIv_convert_i32_to_f32_x4_b:
  case TPC::BIv_convert_i32_to_f32_x4_vb:
  case TPC::BIv_convert_u32_to_f32_x4_b:
  case TPC::BIv_convert_u32_to_f32_x4_vb:
    RequiredSwitches = llvm::TPCII::SW_X4_CONVERT;
    break;
  case TPC::BIv_convert_i32_to_f32_x2_b:
  case TPC::BIv_convert_i32_to_f32_x2_vb:
  case TPC::BIv_convert_u32_to_f32_x2_b:
  case TPC::BIv_convert_u32_to_f32_x2_vb:
    RequiredSwitches = llvm::TPCII::SW_X2_CONVERT;
    break;
  default:
    llvm_unreachable("Unhandled CONVERT intrinsic");
  }
  // Target type.
  llvm::TPCII::OpType TargetDT = getOptypeValue(E->getType());
  RequiredSwitches |= getSwitchForDestination(TargetDT);
  // LaneSel.
  if (HasLaneSel) {
    Expr::EvalResult LSResVal;
    bool R = E->getArg(LaneSelNum)->EvaluateAsRValue(LSResVal, CGF->getContext());
    assert(R); (void)R;
    unsigned LaneSelVal = (unsigned)(LSResVal.Val.getInt().getLimitedValue());
    RequiredSwitches |= LaneSelVal; // TODO: Error?
  }
  // Calculate the final switch set.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;
  if (TI.hasFeature("goya"))
    SwitchVal = translateGen1RoundingMode(SwitchVal);

  // Operands.
  SmallVector<llvm::Value *, 6> Args;
  Value *Src = emitOperand(CGF, E->getArg(0));
  Args.push_back(Src);
  if (DT == TPCII::OpType::Invalid)
    DT = getOptypeValue(E->getArg(0)->getType());
  Args.push_back(llvm::ConstantInt::get(CGF->Int8Ty, DT));
  Args.push_back(llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));

  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (!Updates && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_convert,
                                           { ResultTy,
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}

// int32 s_convert_i64_to_i32
static Value *emit_CONVERT_INT64(CodeGenFunction *CGF, unsigned IntrinsicID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  const unsigned IncomeOpNum = 2;
  const unsigned PredOpNum = 3;
  const unsigned PolarityOpNum = 4;

  // Result type.
  unsigned Multiplicity = 0;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);
  bool Updates = 0;
  assert(IntrinsicID == TPC::BIs_convert_i64_to_i32); 

  // Operands.
  SmallVector<llvm::Value *, 5> Args;
  Value *Src1 = emitOperand(CGF, E->getArg(0));
  Args.push_back(Src1);
  Value *Src2 = emitOperand(CGF, E->getArg(1));
  Args.push_back(Src2);
  Value *Switches = CGF->EmitScalarExpr(E->getArg(2));
  Args.push_back(Switches);
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (!Updates && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);
 
  Function *Callee = CGF->CGM.getIntrinsic(
      Intrinsic::tpc_convert_int64,
                                  {ResultTy, Src1->getType(), Src2->getType(),
                                   Predicate->getType()});
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);

  return Result; //Multiplicity == 0
}

static Value *emit_PREFETCH(CodeGenFunction *CGF, unsigned IntrinsicID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  Value *Addr = CGF->EmitScalarExpr(E->getArg(0));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(1));
  Value *Pred = CGF->EvaluateExprAsBool(E->getArg(2));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(3));
  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_prefetch);
  return CGF->Builder.CreateCall(Callee, { Addr, Switches, Pred, Polarity });
}


// float64 v_f32_ld_l_v_s_vb(uint32_t a, int switches, float64 income, bool256 predicate, bool polarity);
//
static Value *emit_LD_L_V_Generic(CodeGenFunction *CGF, unsigned IntrinsicID,
                                  const CallExpr *E, ReturnValueSlot ReturnValue,
                                  llvm::Triple::ArchType Arch) {
  assert(E->getNumArgs() == 5);
  llvm::Type *ResultTy = CGF->ConvertType(E->getType());

  Value *Addr = CGF->EmitScalarExpr(E->getArg(0));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(1));
  Value *Income = CGF->EmitScalarExpr(E->getArg(2));
  Value *Pred = emitPredicate(CGF, E->getArg(3));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(4));

  Function *Callee = CGF->CGM.getIntrinsic(IntrinsicID, { ResultTy, Pred->getType() });
  return CGF->Builder.CreateCall(Callee, { Addr, Switches, Income, Pred, Polarity });
}


static Value *emit_LD_L_V(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  return emit_LD_L_V_Generic(CGF, Intrinsic::tpc_ld_l_v, E, ReturnValue, Arch);
}

static Value *emit_LD_L_V_LOW(CodeGenFunction *CGF, unsigned BuiltinID,
                              const CallExpr *E, ReturnValueSlot ReturnValue,
                              llvm::Triple::ArchType Arch) {
  return emit_LD_L_V_Generic(CGF, Intrinsic::tpc_ld_l_v_low, E, ReturnValue, Arch);
}

static Value *emit_LD_L_V_HIGH(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  return emit_LD_L_V_Generic(CGF, Intrinsic::tpc_ld_l_v_high, E, ReturnValue, Arch);
}


// void s_f32_st_l (uint32_t addr, float value, int switches, bool predicate, bool polarity);
//
static Value *emit_ST_L(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  Value *Addr = CGF->EmitScalarExpr(E->getArg(0));
  Value *Val = CGF->EmitScalarExpr(E->getArg(1));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(2));
  Value *Pred = CGF->EvaluateExprAsBool(E->getArg(3));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(4));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_st_l, { Val->getType() });
  return CGF->Builder.CreateCall(Callee, { Addr, Val, Switches, Pred, Polarity });
}


static Value *emit_ST_G(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch, bool check_exclusive_read_write = false) {
  Value *Addr = CGF->EmitScalarExpr(E->getArg(0));
  Value *Val;
  bool bv64 = BuiltinID == TPC::BIs_i32_x2_st_g || BuiltinID == TPC::BIs_u32_x2_st_g;
  if (bv64) {
    Val = emitOperand(CGF, E->getArg(1));
  } else {
    Val = CGF->EmitScalarExpr(E->getArg(1));
  }

  unsigned SwOpNum = 2;
  Value *Switches;
  bool doron1 = CGF->getContext().getTargetInfo().hasFeature("doron1");
  if (doron1 && check_exclusive_read_write) {
    Expr::EvalResult ResVal;
    bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
    assert(R);
    (void)R;
    unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
    if (SwitchVal & TPCII::SW_EXC) {
      SwitchVal |= TPCII::SW_L0CS;
    }
    Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  } else {
    Switches = CGF->EmitScalarExpr(E->getArg(SwOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_st_g, { Val->getType() });
  Value *Pred = CGF->EvaluateExprAsBool(E->getArg(3));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(4));

  Value *Result = CGF->Builder.CreateCall(Callee, { Addr, Val, Switches, Pred, Polarity });
  return Result;
}


// void s_f32_st_g_inc(__global void **addr, float value, int switches, bool predicate, bool polarity)
static Value *emit_ST_G_INC(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  const auto *PtrTy = cast<clang::PointerType>(E->getArg(0)->getType());
  const auto *PointeeTy = cast<clang::PointerType>(PtrTy->getPointeeType());
  Value *AddrPtr = CGF->EmitScalarExpr(E->getArg(0));
  MaybeAlign MAlign = AddrPtr->getPointerAlignment(CGF->CGM.getDataLayout());
  unsigned AlignValue = 1;
  if (MAlign) {
    llvm::Align A = *MAlign;
    AlignValue = A.value();
  }
  Address Addr0 = CGF->EmitLoadOfPointer(
    Address(AddrPtr, CharUnits::fromQuantity(AlignValue)),
     cast<clang::PointerType>(E->getArg(0)->getType()));

  // Stored value.
  Value *Val;
  unsigned ValueSize;
  bool bv64 = BuiltinID == TPC::BIs_i32_x2_st_g_inc ||
              BuiltinID == TPC::BIs_u32_x2_st_g_inc;
  if (bv64) {
    Val = emitOperand(CGF, E->getArg(1));
    ValueSize = 8;
  } else {
    Val = CGF->EmitScalarExpr(E->getArg(1));
    ValueSize = Val->getType()->getScalarSizeInBits() / CHAR_BIT;
  }

  // Determine increment value.
  Value *Switches = CGF->EmitScalarExpr(E->getArg(2));
  Expr::EvalResult ResVal;
  bool R = E->getArg(2)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  unsigned IncVal;
  if ((SwitchVal & TPCII::SW_INC_VAL) == TPCII::SW_INC_0) {
    // SW_INC switch is not specified. Evaluate increment from the type size.
    switch (ValueSize) {
    case 1:
      SwitchVal |= TPCII::SW_INC_1;
      break;
    case 2:
      SwitchVal |= TPCII::SW_INC_2;
      break;
    case 4:
      SwitchVal |= TPCII::SW_INC_4;
      break;
    case 8:
      SwitchVal |= TPCII::SW_INC_8;
      break;
    default:
      llvm_unreachable("Invalid item size");
    }
    IncVal = ValueSize;
  } else {
    switch (SwitchVal & TPCII::SW_INC_VAL) {
    case TPCII::SW_INC_1:
      IncVal = 1;
      break;
    case TPCII::SW_INC_2:
      IncVal = 2;
      break;
    case TPCII::SW_INC_4:
      IncVal = 4;
      break;
    case TPCII::SW_INC_8:
      IncVal = 8;
      break;
    }
  }

  Value *IncValue = ConstantInt::get(CGF->Int32Ty, IncVal);
  Value *Pred = CGF->EvaluateExprAsBool(E->getArg(3));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(4));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_st_g_inc,
      { CGF->ConvertType(QualType(PointeeTy, 0)), Val->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, { Addr0.getPointer(), Val, IncValue, Switches, Pred, Polarity });

  Address VarPtr(AddrPtr, CharUnits::fromQuantity(cast<AllocaInst>(AddrPtr)->getAlignment()));
  CGF->EmitStoreOfScalar(Result, CGF->MakeAddrLValue(VarPtr, QualType(PtrTy, 0)));

  return UndefValue::get(CGF->VoidTy);
}


// void f32_st_l_v_s_v_b(uint32_t addr, float64 value, int sw, bool predicate, bool polarity);
//
static Value *emit_ST_L_V_Generic(CodeGenFunction *CGF, unsigned IntrinsicID,
                                  const CallExpr *E) {
  assert(E->getNumArgs() == 5);

  Value *Addr = CGF->EmitScalarExpr(E->getArg(0));
  Value *Src = CGF->EmitScalarExpr(E->getArg(1));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(2));
  Value *Pred = emitPredicate(CGF, E->getArg(3));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(4));

  Function *Callee = CGF->CGM.getIntrinsic(IntrinsicID, { Src->getType(), Pred->getType() });
  return CGF->Builder.CreateCall(Callee, { Addr, Src, Switches, Pred, Polarity });
}

static Value *emit_ST_L_V(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  return emit_ST_L_V_Generic(CGF, Intrinsic::tpc_st_l_v, E);
}

static Value *emit_ST_L_V_LOW(CodeGenFunction *CGF, unsigned BuiltinID,
                              const CallExpr *E, ReturnValueSlot ReturnValue,
                              llvm::Triple::ArchType Arch) {
  return emit_ST_L_V_Generic(CGF, Intrinsic::tpc_st_l_v_low, E);
}

static Value *emit_ST_L_V_HIGH(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  return emit_ST_L_V_Generic(CGF, Intrinsic::tpc_st_l_v_high, E);
}


// float s_f32_mac (float a, float b, float accumulator, int switches, bool predicate, bool polarity);
// float64 v_f32_mac_vb(float64 a, float64 b, float64 accumulator, int switches, bool64 predicate, bool polarity);
// int128 v_i16_mac_vb (short128 a, short128 b, int128 accumulator, int switches, bool128 predicate, bool polarity);
// int256 v_i8_mac_vb (char256 a, char256 b, int256 accumulator, int switches, bool256 predicate, bool polarity);
// short256 v_i8_mac_acc16_vb(char256 a, char256 b, short256 accumulator, int switches, bool256 predicate, bool polarity);
// float128 v_bf16_mac_acc32_vb(bfloat128 a, bfloat128 b, float128 accumulator, int switches, bool128 predicate, bool polarity);
// int128 v_u16_mac_acc32_vb(ushort128 a, ushort128 b, int128 accumulator, int switches, bool128 predicate, bool polarity);
// int256 v_i8_mac_zp_vb(char256 a, char256 b, char256 zp, int256 accumulator, int switches, bool256 predicate, bool polarity);
// short256 v_i8_mac_zp_acc16_vb(char256 a, char256 b, char256 zp, short256 accumulator, int switches, bool256 predicate, bool polarity);
// int256 v_u8_mac_zp_acc32_vb(uchar256 a, uchar256 b, uchar256 zp, int256 accumulator, int switches, bool256 predicate, bool polarity);
// int256 v_i8_mac_x2_vb(char256 a, char256 b, char256 c, char256 d, int256 accumulator, int switches, bool256 predicate, bool polarity);
// short256 v_i8_mac_x2_acc16_vb(char256 a, char256 b, char256 c, char256 d, short256 accumulator, int switches, bool256 predicate, bool polarity);
// int256 v_u8_mac_x2_acc32_vb(uchar256 a, uchar256 b, uchar256 c, uchar256 d, int256 accumulator, int switches, bool256 predicate, bool polarity);
// int256 v_i8_mac_x2_zp_vb(char256 a, char256 b, char256 c, char256 d, char256 zp, int256 accumulator, int switches, bool256 predicate, bool polarity);
// short256 v_i8_mac_x2_zp_acc16_vb(char256 a, char256 b, char256 c, char256 d, char256 zp, short256 accumulator, int switches, bool256 predicate, bool polarity);
// int256 v_u8_mac_x2_zp_acc32_vb(uchar256 a, uchar256 b, uchar256 c, uchar256 d, uchar256 zp, int256 accumulator, int switches, bool256 predicate, bool polarity);
//
static Value *emit_MAC(CodeGenFunction *CGF, unsigned BuiltinID, const CallExpr *E,
                       ReturnValueSlot ReturnValue, llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned AccOpNum = NumArgs-4;
  const unsigned SwOpNum = NumArgs-3;
  const unsigned PredOpNum =  NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  const unsigned NumInputs = NumArgs - 4;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches. Some intrinsics like 's_bf16_mac_acc32' require setting
  // specific switches, which user does not specify in invocation.
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_ACC_FP32 | TPCII::SW_ACC_I16 |
      TPCII::SW_ACC_I32 | TPCII::SW_ZP | TPCII::SW_X2_ARITHMETIC;
  unsigned IntrinsicID;
  switch (BuiltinID) {
  case TPC::BIs_f32_mac:
  case TPC::BIs_bf16_mac:
  case TPC::BIs_f16_mac:
  case TPC::BIs_i16_mac:
  case TPC::BIs_u16_mac:
  case TPC::BIs_i8_mac:
  case TPC::BIs_u8_mac:
  case TPC::BIv_f32_mac_b:
  case TPC::BIv_f32_mac_vb:
  case TPC::BIv_bf16_mac_b:
  case TPC::BIv_bf16_mac_vb:
  case TPC::BIv_f16_mac_b:
  case TPC::BIv_f16_mac_vb:
  case TPC::BIv_i16_mac_b:
  case TPC::BIv_i16_mac_vb:
  case TPC::BIv_u16_mac_b:
  case TPC::BIv_u16_mac_vb:
  case TPC::BIv_i8_mac_b:
  case TPC::BIv_i8_mac_vb:
  case TPC::BIv_u8_mac_b:
  case TPC::BIv_u8_mac_vb:
    RequiredSwitches = 0;
    IntrinsicID = Intrinsic::tpc_mac;
    break;
  case TPC::BIs_bf16_mac_acc32:
  case TPC::BIs_f16_mac_acc32:
  case TPC::BIs_f8_mac_acc32:
  case TPC::BIs_h8_mac_acc32:
  case TPC::BIv_bf16_mac_acc32_b:
  case TPC::BIv_bf16_mac_acc32_vb:
  case TPC::BIv_f16_mac_acc32_b:
  case TPC::BIv_f16_mac_acc32_vb:
  case TPC::BIv_f8_mac_acc32_b:
  case TPC::BIv_f8_mac_acc32_vb:
  case TPC::BIv_h8_mac_acc32_b:
  case TPC::BIv_h8_mac_acc32_vb:
    RequiredSwitches = TPCII::SW_ACC_FP32;
    IntrinsicID = Intrinsic::tpc_mac;
    break;
  case TPC::BIs_i8_mac_acc16:
  case TPC::BIs_u8_mac_acc16:
  case TPC::BIv_i8_mac_acc16_b:
  case TPC::BIv_i8_mac_acc16_vb:
  case TPC::BIv_u8_mac_acc16_b:
  case TPC::BIv_u8_mac_acc16_vb:
    RequiredSwitches = TPCII::SW_ACC_I16;
    IntrinsicID = Intrinsic::tpc_mac;
    break;
  case TPC::BIs_u16_mac_acc32:
  case TPC::BIs_u8_mac_acc32:
  case TPC::BIv_u16_mac_acc32_b:
  case TPC::BIv_u16_mac_acc32_vb:
  case TPC::BIv_u8_mac_acc32_b:
  case TPC::BIv_u8_mac_acc32_vb:
    RequiredSwitches = TPCII::SW_ACC_I32;
    IntrinsicID = Intrinsic::tpc_mac;
    break;
  case TPC::BIv_i8_mac_zp_b:
  case TPC::BIv_i8_mac_zp_vb:
  case TPC::BIv_u8_mac_zp_b:
  case TPC::BIv_u8_mac_zp_vb:
    RequiredSwitches = TPCII::SW_ZP;
    IntrinsicID = Intrinsic::tpc_mac_zp;
    break;
  case TPC::BIv_i8_mac_zp_acc16_b:
  case TPC::BIv_i8_mac_zp_acc16_vb:
  case TPC::BIv_u8_mac_zp_acc16_b:
  case TPC::BIv_u8_mac_zp_acc16_vb:
    RequiredSwitches = TPCII::SW_ZP | TPCII::SW_ACC_I16;
    IntrinsicID = Intrinsic::tpc_mac_zp;
    break;
  case TPC::BIv_u8_mac_zp_acc32_b:
  case TPC::BIv_u8_mac_zp_acc32_vb:
    RequiredSwitches = TPCII::SW_ZP | TPCII::SW_ACC_I32;
    IntrinsicID = Intrinsic::tpc_mac_zp;
    break;
  case TPC::BIv_i8_mac_x2_b:
  case TPC::BIv_i8_mac_x2_vb:
  case TPC::BIv_u8_mac_x2_b:
  case TPC::BIv_u8_mac_x2_vb:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC;
    IntrinsicID = Intrinsic::tpc_mac_x2;
    break;
  case TPC::BIv_f32_mac_x2_vb:
  case TPC::BIv_f32_mac_x2_b:
  case TPC::BIv_f32_mac_x2_svv_vb:
  case TPC::BIv_f32_mac_x2_svv_b:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC;
    IntrinsicID = Intrinsic::tpc_mac_x2_f32;
    break;
  case TPC::BIv_i8_mac_x2_acc16_b:
  case TPC::BIv_i8_mac_x2_acc16_vb:
  case TPC::BIv_u8_mac_x2_acc16_b:
  case TPC::BIv_u8_mac_x2_acc16_vb:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC | TPCII::SW_ACC_I16;
    IntrinsicID = Intrinsic::tpc_mac_x2;
    break;
  case TPC::BIv_u8_mac_x2_acc32_b:
  case TPC::BIv_u8_mac_x2_acc32_vb:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC | TPCII::SW_ACC_I32;
    IntrinsicID = Intrinsic::tpc_mac_x2;
    break;
  case TPC::BIv_i8_mac_x2_zp_b:
  case TPC::BIv_i8_mac_x2_zp_vb:
  case TPC::BIv_u8_mac_x2_zp_b:
  case TPC::BIv_u8_mac_x2_zp_vb:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC | TPCII::SW_ZP;
    IntrinsicID = Intrinsic::tpc_mac_x2_zp;
    break;
  case TPC::BIv_i8_mac_x2_zp_acc16_b:
  case TPC::BIv_i8_mac_x2_zp_acc16_vb:
  case TPC::BIv_u8_mac_x2_zp_acc16_b:
  case TPC::BIv_u8_mac_x2_zp_acc16_vb:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC | TPCII::SW_ZP | TPCII::SW_ACC_I16;
    IntrinsicID = Intrinsic::tpc_mac_x2_zp;
    break;
  case TPC::BIv_u8_mac_x2_zp_acc32_b:
  case TPC::BIv_u8_mac_x2_zp_acc32_vb:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC | TPCII::SW_ZP | TPCII::SW_ACC_I32;
    IntrinsicID = Intrinsic::tpc_mac_x2_zp;
    break;
  default:
    llvm_unreachable("Unhandled MAC intrinsic");
  }
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Operands.
  SmallVector<llvm::Value *, 9> Args;
  for (unsigned ArgNo = 0; ArgNo < NumInputs; ArgNo++)
    Args.push_back(emitOperand(CGF, E->getArg(ArgNo)));

  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(0)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Acc = emitOperand(CGF, E->getArg(AccOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));

  Args.push_back(DT);
  Args.push_back(Switches);
  Args.push_back(Acc);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function *Callee = nullptr;
  switch (IntrinsicID) {
  case Intrinsic::tpc_mac_x2:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID, { ResultTy,
                                                  Args[0]->getType(),
                                                  Args[1]->getType(),
                                                  Args[3]->getType(),
                                                  Predicate->getType() });
    break;
  case Intrinsic::tpc_mac_x2_f32:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID, { ResultTy,
                                                  Args[0]->getType(),
                                                  Args[1]->getType(),
                                                  Args[2]->getType(),
                                                  Predicate->getType() });
    break;
  default:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID, { ResultTy,
                                                  Args[0]->getType(),
                                                  Predicate->getType() });
    break;
  }

  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// float s_f32_mul(float a, float b, int switches, float income, bool predicate, bool polarity);
// int5 i_i32_mul(int5 a, int5 b, int dimMask, int5 income, bool predicate, bool polarity);
// float64 v_f32_mul_vb (float64 a, float64 b, int switches, float64 income, bool64 predicate, bool polarity);
// int128 v_i32_mul_vb(int64 a, int64 b, int switches, int128 income, bool128 predicate, bool polarity);
// float128 v_bf16_mul_acc32_vb(bfloat128 a, bfloat128 b, int switches, float128 income, bool128 predicate, bool polarity);
// int64 v_i32_mul_acc32_vb(int64 a, int64 b, int switches, int64 income, bool64 predicate, bool polarity);
//
static Value *emit_MUL(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs - 1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches. Some intrinsics like 's_bf16_mul_acc32' require setting
  // specific switches, which user does not specify in invocation.
  unsigned RequiredSwitches;
  unsigned IntrinsicID;
  unsigned NumInputs;
  const unsigned SwitchMask = TPCII::SW_GROUP_RND32 |
      TPCII::SW_ACC_FP32 | TPCII::SW_X2_ARITHMETIC;
  switch (BuiltinID) {
  case TPC::BIv_i32_mul_b:
  case TPC::BIv_i32_mul_vb:
  case TPC::BIv_u32_mul_b:
  case TPC::BIv_u32_mul_vb:
  case TPC::BIs_f32_mul:
  case TPC::BIs_bf16_mul:
  case TPC::BIs_f16_mul:
  case TPC::BIv_f32_mul_b:
  case TPC::BIv_f32_mul_vb:
  case TPC::BIv_bf16_mul_b:
  case TPC::BIv_bf16_mul_vb:
  case TPC::BIv_f16_mul_b:
  case TPC::BIv_f16_mul_vb:
  case TPC::BIs_i32_mul:
  case TPC::BIs_u32_mul:
  case TPC::BIs_i16_mul:
  case TPC::BIs_u16_mul:
  case TPC::BIs_i8_mul:
  case TPC::BIs_u8_mul:
  case TPC::BIv_i16_mul_b:
  case TPC::BIv_i16_mul_vb:
  case TPC::BIv_u16_mul_b:
  case TPC::BIv_u16_mul_vb:
  case TPC::BIv_i8_mul_b:
  case TPC::BIv_i8_mul_vb:
  case TPC::BIv_u8_mul_b:
  case TPC::BIv_u8_mul_vb:
    NumInputs = 2;
    RequiredSwitches = 0;
    IntrinsicID = Intrinsic::tpc_mul;
    break;
  case TPC::BIi_i32_mul:
    NumInputs = 2;
    RequiredSwitches = 0;
    IntrinsicID = Intrinsic::tpc_mul_mask;
    break;
  case TPC::BIs_bf16_mul_acc32:
  case TPC::BIv_bf16_mul_acc32_vb:
  case TPC::BIv_bf16_mul_acc32_b:
  case TPC::BIs_f16_mul_acc32:
  case TPC::BIv_f16_mul_acc32_vb:
  case TPC::BIv_f16_mul_acc32_b:

  case TPC::BIs_f8_mul_acc32:
  case TPC::BIv_f8_mul_acc32_vb:
  case TPC::BIv_f8_mul_acc32_b:
  case TPC::BIs_h8_mul_acc32:
  case TPC::BIv_h8_mul_acc32_vb:
  case TPC::BIv_h8_mul_acc32_b:

    NumInputs = 2;
    RequiredSwitches = TPCII::SW_ACC_FP32;
    IntrinsicID = Intrinsic::tpc_mul;
    break;
  case TPC::BIv_i32_mul_round_vb:
  case TPC::BIv_i32_mul_round_b:
  case TPC::BIv_u32_mul_round_vb:
  case TPC::BIv_u32_mul_round_b: {
    const TargetInfo &TI = CGF->getContext().getTargetInfo();
    if (TI.hasFeature("greco") || TI.hasFeature("gaudi2") ||
        TI.hasFeature("doron1"))
      RequiredSwitches = TPCII::SW_RND32_DNR32;
    else
      RequiredSwitches = TPCII::SW_DOUBLE_AND_ROUND32;
    NumInputs = 2;
    IntrinsicID = Intrinsic::tpc_mul;
    break;
  }
  case TPC::BIv_f32_mul_x2_vb:
  case TPC::BIv_f32_mul_x2_b:
  case TPC::BIv_f32_mul_x2_svv_vb:
  case TPC::BIv_f32_mul_x2_svv_b:
    NumInputs = 3;
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC;
    IntrinsicID = Intrinsic::tpc_mul_x2_f32;
    break;
  default:
    llvm_unreachable("Unhandled MUL intrinsic");
  }

  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (RequiredSwitches) {
    SwitchVal &= ~SwitchMask;
    SwitchVal |= RequiredSwitches;
  }

  // Prepare arguments.
  SmallVector<llvm::Value *, 8> Args;
  for (unsigned ArgNo = 0; ArgNo < NumInputs; ++ArgNo)
    Args.push_back(emitOperand(CGF, E->getArg(ArgNo)));
  if (IntrinsicID == Intrinsic::tpc_mul_mask)
    Args.push_back(/* DimMask */ CGF->EmitScalarExpr(E->getArg(2)));
  Args.push_back( /* DT */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(0)->getType())));
  Args.push_back(/* Switches */ llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));

  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity) &&
      IntrinsicID != Intrinsic::tpc_mul_mask) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  // Call intrinsic.
  Function *Callee;
  switch (IntrinsicID) {
  case Intrinsic::tpc_mul:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Args[0]->getType(),
                                     Args[1]->getType(),
                                     Predicate->getType() });
    break;
  case Intrinsic::tpc_mul_mask:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { Args[0]->getType(),
                                     Args[1]->getType() });
    break;
  case Intrinsic::tpc_mul_x2_f32:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Args[0]->getType(),
                                     Args[1]->getType(),
                                     Args[2]->getType(),
                                     Predicate->getType() });
    break;
  default:
    llvm_unreachable("Unhandled IntrinsicID for mul instruction");
  }
  Value *Result = CGF->Builder.CreateCall(Callee, Args);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


static Value *emit_MADD(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SwOpNum = NumArgs-4;
  const unsigned IncomeOpNum = NumArgs-3;
  const unsigned PredOpNum =  NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches. Some intrinsics like 'v_bf16_madd_acc32_vb' require setting
  // specific switches, which user does not specify in invocation.
  unsigned RequiredSwitches;
  unsigned SwitchMask = TPCII::SW_ACC_I16 | TPCII::SW_ACC_I32 |
      TPCII::SW_X2_ARITHMETIC | TPCII::SW_ZP;
  switch (BuiltinID) {
  case TPC::BIv_f32_madd_b:
  case TPC::BIv_f32_madd_vb:
  case TPC::BIv_bf16_madd_b:
  case TPC::BIv_bf16_madd_vb:
  case TPC::BIv_f16_madd_b:
  case TPC::BIv_f16_madd_vb:
  case TPC::BIv_i16_madd_b:
  case TPC::BIv_i16_madd_vb:
  case TPC::BIv_u16_madd_b:
  case TPC::BIv_u16_madd_vb:
  case TPC::BIv_i8_madd_b:
  case TPC::BIv_i8_madd_vb:
  case TPC::BIv_u8_madd_b:
  case TPC::BIv_u8_madd_vb:
    RequiredSwitches = 0;
    break;
  case TPC::BIv_bf16_madd_acc32_b:
  case TPC::BIv_bf16_madd_acc32_vb:
  case TPC::BIv_f16_madd_acc32_b:
  case TPC::BIv_f16_madd_acc32_vb:
  case TPC::BIv_f8_madd_acc32_b:
  case TPC::BIv_f8_madd_acc32_vb:
  case TPC::BIv_h8_madd_acc32_b:
  case TPC::BIv_h8_madd_acc32_vb:
    RequiredSwitches = TPCII::SW_ACC_FP32;
    break;
  case TPC::BIv_i8_madd_acc16_b:
  case TPC::BIv_i8_madd_acc16_vb:
  case TPC::BIv_u8_madd_acc16_b:
  case TPC::BIv_u8_madd_acc16_vb:
    RequiredSwitches = TPCII::SW_ACC_I16;
    break;
  case TPC::BIv_u8_madd_acc32_b:
  case TPC::BIv_u8_madd_acc32_vb:
  case TPC::BIv_u16_madd_acc32_b:
  case TPC::BIv_u16_madd_acc32_vb:
    RequiredSwitches = TPCII::SW_ACC_I32;
    break;
  case TPC::BIv_i8_madd_zp_vb:
  case TPC::BIv_i8_madd_zp_b:
  case TPC::BIv_u8_madd_zp_vb:
  case TPC::BIv_u8_madd_zp_b:
    RequiredSwitches = TPCII::SW_ZP;
    break;
  case TPC::BIv_i8_madd_zp_acc16_vb:
  case TPC::BIv_i8_madd_zp_acc16_b:
  case TPC::BIv_u8_madd_zp_acc16_vb:
  case TPC::BIv_u8_madd_zp_acc16_b:
    RequiredSwitches = TPCII::SW_ACC_I16 | TPCII::SW_ZP;
    break;
  case TPC::BIv_u8_madd_zp_acc32_vb:
  case TPC::BIv_u8_madd_zp_acc32_b:
    RequiredSwitches = TPCII::SW_ACC_I32 | TPCII::SW_ZP;
    break;
  case TPC::BIv_f32_madd_x2_vb:
  case TPC::BIv_f32_madd_x2_b:
  case TPC::BIv_f32_madd_x2_svvv_vb:
  case TPC::BIv_f32_madd_x2_svvv_b:
  case TPC::BIv_f32_madd_x2_vvsv_vb:
  case TPC::BIv_f32_madd_x2_vvsv_b:
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC;
    break;
  default:
    llvm_unreachable("Unhandled MADD intrinsic");
  }
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // Prepare arguments.
  SmallVector<llvm::Value *, 8> Args;
  //Args.push_back(CGF->EmitScalarExpr(X0));
  //Args.push_back(CGF->EmitScalarExpr(X1));
  for (unsigned ArgNo = 0; ArgNo < SwOpNum; ArgNo++){
    Args.push_back(emitOperand(CGF, E->getArg(ArgNo)));
  }

  Args.push_back( /* DT */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(0)->getType())));
  Args.push_back(/* Switches */ llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));

  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  unsigned IntrinsicID;
  if (RequiredSwitches & TPCII::SW_ZP)
    IntrinsicID = Intrinsic::tpc_madd_zp;
  else if (RequiredSwitches & TPCII::SW_X2_ARITHMETIC)
    IntrinsicID = Intrinsic::tpc_madd_x2;
  else
    IntrinsicID = Intrinsic::tpc_madd;
  Function *Callee;
      if (RequiredSwitches & TPCII::SW_X2_ARITHMETIC)
        Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                       { ResultTy,
                                         Args[0]->getType(), Args[1]->getType(),
                                         Args[2]->getType(), Args[3]->getType(),
                                         Predicate->getType() });
      else
        Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                       { ResultTy,
                                         Args[0]->getType(),
                                         Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// int8_t s_convert_i32_to_i8 (int32_t value, int32_t shift, int switches, int8_t income, bool predicate, bool polarity);
// short128 v_convert_i32_to_i16_single_b (int64 value, int64 shift, const int lane, int switches, short128 income, bool predicate, bool polarity);
// short128 v_convert_i32_to_i16_all_b (int128 value, short128 shift, int switches, short128 income, bool predicate, bool polarity);
//
static Value *emit_CONVERT_INT(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned ShiftOpNum = 1;
  const unsigned LaneOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  const TargetInfo &TI = CGF->getContext().getTargetInfo();

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Lane number if present.
  unsigned Lane = ~0U;
  if (E->getNumArgs() == 7) {
    Expr::EvalResult ResVal;
    bool Status = E->getArg(LaneOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
    if (!Status)
      report_fatal_error("Lane must be a constant integer", false);
    Lane = (unsigned)(ResVal.Val.getInt().getLimitedValue());
  }

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_GROUP_TO | TPCII::SW_NUM_LANES | TPCII::SW_LANE_SEL;
  unsigned IID;
  unsigned TotalLanes = 0;
  switch (BuiltinID) {
  case TPC::BIv_convert_int32_to_i16_b:
  case TPC::BIv_convert_int32_to_i16_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_16;
    TotalLanes = 2;
    break;
  case TPC::BIv_convert_int32_to_i16_single_b:
  case TPC::BIv_convert_int32_to_i16_single_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_16 | TPCII::SW_SINGLE_LANE;
    TotalLanes = 2;
    break;
  case TPC::BIs_convert_int32_to_i16:
  case TPC::BIv_convert_int32_to_i16_all_b:
  case TPC::BIv_convert_int32_to_i16_all_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_16;
    break;
  case TPC::BIv_convert_int32_to_i8_b:
  case TPC::BIv_convert_int32_to_i8_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_8;
    TotalLanes = 4;
    break;
  case TPC::BIv_convert_int32_to_i8_single_b:
  case TPC::BIv_convert_int32_to_i8_single_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_8 | TPCII::SW_SINGLE_LANE;
    TotalLanes = 4;
    break;
  case TPC::BIs_convert_int32_to_i8:
  case TPC::BIv_convert_int32_to_i8_all_b:
  case TPC::BIv_convert_int32_to_i8_all_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_8;
    break;
  case TPC::BIv_convert_uint32_to_u16_b:
  case TPC::BIv_convert_uint32_to_u16_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_16;
    TotalLanes = 2;
    break;
  case TPC::BIv_convert_uint32_to_u16_single_b:
  case TPC::BIv_convert_uint32_to_u16_single_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_16 | TPCII::SW_SINGLE_LANE;
    TotalLanes = 2;
    break;
  case TPC::BIs_convert_uint32_to_u16:
  case TPC::BIv_convert_uint32_to_u16_all_b:
  case TPC::BIv_convert_uint32_to_u16_all_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_16;
    break;
  case TPC::BIv_convert_uint32_to_u8_b:
  case TPC::BIv_convert_uint32_to_u8_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_8;
    TotalLanes = 4;
    break;
  case TPC::BIv_convert_uint32_to_u8_single_b:
  case TPC::BIv_convert_uint32_to_u8_single_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_8 | TPCII::SW_SINGLE_LANE;
    TotalLanes = 4;
    break;
  case TPC::BIs_convert_uint32_to_u8:
  case TPC::BIv_convert_uint32_to_u8_all_b:
  case TPC::BIv_convert_uint32_to_u8_all_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_8;
    break;
  case TPC::BIv_convert_int16_to_i8_b:
  case TPC::BIv_convert_int16_to_i8_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_8;
    TotalLanes = 2;
    break;
  case TPC::BIv_convert_int16_to_i8_single_b:
  case TPC::BIv_convert_int16_to_i8_single_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_8 | TPCII::SW_SINGLE_LANE;
    TotalLanes = 2;
    break;
  case TPC::BIs_convert_int16_to_i8:
  case TPC::BIv_convert_int16_to_i8_all_b:
  case TPC::BIv_convert_int16_to_i8_all_vb:
    IID = Intrinsic::tpc_convert_int;
    RequiredSwitches = TPCII::SW_TO_8;
    break;
  case TPC::BIv_convert_uint16_to_u8_b:
  case TPC::BIv_convert_uint16_to_u8_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_8;
    TotalLanes = 2;
    break;
  case TPC::BIv_convert_uint16_to_u8_single_b:
  case TPC::BIv_convert_uint16_to_u8_single_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_8 | TPCII::SW_SINGLE_LANE;
    TotalLanes = 2;
    break;
  case TPC::BIs_convert_uint16_to_u8:
  case TPC::BIv_convert_uint16_to_u8_all_b:
  case TPC::BIv_convert_uint16_to_u8_all_vb:
    IID = Intrinsic::tpc_convert_uint;
    RequiredSwitches = TPCII::SW_TO_8;
    break;
  case TPC::BIs_convert_int8_to_i4:
  case TPC::BIv_convert_int8_to_i4_all_b:
  case TPC::BIv_convert_int8_to_i4_all_vb:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_convert_int;
    break;
  case TPC::BIs_convert_uint8_to_u4:
  case TPC::BIv_convert_uint8_to_u4_all_b:
  case TPC::BIv_convert_uint8_to_u4_all_vb:
    RequiredSwitches = 0;
    IID = Intrinsic::tpc_convert_uint;
    break;
  default:
    llvm_unreachable("Unhandled CONVERT_INT");
  }
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;
  if (TotalLanes) {
    assert(Lane != ~0U);
    assert(Lane < TotalLanes);
    // We rely on the fact that lane as number and lane as switch are the same value.
    static_assert(TPCII::SW_LANE_3 == 3, "Unexpected lane encoding");
    SwitchVal |= Lane;
  }
  if (TI.hasFeature("goya"))
    SwitchVal = translateGen1RoundingMode(SwitchVal);

  // Arguments.
  Value *Src = emitOperand(CGF, E->getArg(SrcOpNum));
  Value *Shift = CGF->EmitScalarExpr(E->getArg(ShiftOpNum));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (TotalLanes == 0 && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(IID,
      { ResultTy, Src->getType(), Shift->getType(), Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src, Shift, Switches, Income, Predicate, Polarity});
  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());
  return Result;
}


// int8_t s_i8_min(int8_t a, int8_t b, int sw, int8_t income, bool predicate, bool polarity);
// int5 i_i32_max(int5 a, int5 b, int dimMask, int sw, int5 income, bool predicate, bool polarity);
// int64 v_i32_and_vb(int64 a, int64 b, int sw, int64 income, bool256 predicate, bool polarity);
//
static Value* emit_BinOp(CodeGenFunction* CGF, unsigned BuiltinID, const CallExpr* E,
                         unsigned IntrinsicID, unsigned IntrinsicMaskID) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned Src1OpNum = 0;
  const unsigned Src2OpNum = 1;
  const unsigned DimMaskOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  const bool WithMask = E->getNumArgs() == 7;
  const bool IRFOp = ResultTy->isVectorTy() &&
      cast<FixedVectorType>(ResultTy)->getNumElements() == 5;

  // Arguments of the operation.
  const Expr *X0 = E->getArg(Src1OpNum);
  const Expr *X1 = E->getArg(Src2OpNum);

  // If some of the operands is a vector splat, move it to the first place, if
  // the call produces int5. This corresponds to IRF operations. Otherwise move
  // it to the second place, such order is natural for VRF operations.
  if (IRFOp) {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X1))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        std::swap(X0, X1);
  } else {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X0))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        std::swap(X0, X1);
  }

  // If the first operand (for int5 type) or the second one (for other vector
  // types) is a vector splat, replace it with scalar argument.
  if (IRFOp) {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X0))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        X0 = Cast->getSubExpr();
  } else {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X1))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        X1 = Cast->getSubExpr();
  }

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  SmallVector<llvm::Value *, 8> Args;

  Value *Src1 = CGF->EmitScalarExpr(X0);
  Value *Src2 = CGF->EmitScalarExpr(X1);
  Args.push_back(Src1);
  Args.push_back(Src2);
  if (WithMask)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(/* DT */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(Src1OpNum)->getType())));
  Args.push_back(/* SW */ llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));

  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity) && !IRFOp) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function* Callee;
  if (WithMask) {
    Callee = CGF->CGM.getIntrinsic(IntrinsicMaskID,
                                   { Src1->getType(),
                                     Src2->getType() });

  } else {
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Src1->getType(),
                                     Src2->getType(),
                                     Predicate->getType() });
  }
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  return Result;
}


// int8_t s_i8_add(int8_t a, int8_t b, int sw, int8_t income, bool predicate, bool polarity);
// int5   i_i32_add(int5 a, int5 b, int dimMask, int sw, int5 income, bool predicate, bool polarity);
// float64 v_f32_add_vb(float64 a, float64 b, int sw, float64 income, bool256 predicate, bool polarity);
//
static Value *emit_ADD(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned DimMaskOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Data type.
  auto DT = llvm::ConstantInt::get(CGF->Int8Ty,
                                   getOptypeValue(E->getArg(1)->getType()));

  unsigned IntrinsicID;
  unsigned NumInputs;
  unsigned RequiredSwitches = 0;
  const unsigned SwitchMask = TPCII::SW_X2_ARITHMETIC;
  switch (BuiltinID) {
  case TPC::BIs_f32_add:
  case TPC::BIs_i32_add:
  case TPC::BIs_u32_add:
  case TPC::BIs_i16_add:
  case TPC::BIs_u16_add:
  case TPC::BIs_i8_add:
  case TPC::BIs_u8_add:
  case TPC::BIs_bf16_add:
  case TPC::BIs_f16_add:
  case TPC::BIs_f8_add:
  case TPC::BIs_h8_add:
  case TPC::BIv_f32_add_vb:
  case TPC::BIv_f32_add_b:
  case TPC::BIv_bf16_add_vb:
  case TPC::BIv_bf16_add_b:
  case TPC::BIv_f16_add_vb:
  case TPC::BIv_f16_add_b:
  case TPC::BIv_f8_add_vb:
  case TPC::BIv_f8_add_b:
  case TPC::BIv_h8_add_vb:
  case TPC::BIv_h8_add_b:
  case TPC::BIv_i32_add_vb:
  case TPC::BIv_i32_add_b:
  case TPC::BIv_u32_add_vb:
  case TPC::BIv_u32_add_b:
  case TPC::BIv_i16_add_vb:
  case TPC::BIv_i16_add_b:
  case TPC::BIv_u16_add_vb:
  case TPC::BIv_u16_add_b:
  case TPC::BIv_i8_add_vb:
  case TPC::BIv_i8_add_b:
  case TPC::BIv_u8_add_vb:
  case TPC::BIv_u8_add_b:
    IntrinsicID = Intrinsic::tpc_add;
    NumInputs = 2;
    break;
  case TPC::BIi_i32_add:
    IntrinsicID = Intrinsic::tpc_add_mask;
    NumInputs = 2;
    break;
  case TPC::BIv_f32_add_x2_vb:
  case TPC::BIv_f32_add_x2_b:
    IntrinsicID = Intrinsic::tpc_add_x2;
    NumInputs = 3;
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC;
    break;
  default:
    llvm_unreachable("Unhandled ADD intrinsic");
  }

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // If some of the operands is a vector splat, move it to the first place, if
  // the call produces int5. This corresponds to IRF operations. Otherwise move
  // it to the second place, such order is natural for VRF operations.
  const Expr *X0 = E->getArg(0);
  const Expr *X1 = E->getArg(1);
  if (IntrinsicID == Intrinsic::tpc_add_mask) {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X1))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        std::swap(X0, X1);
  } else {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X0))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        std::swap(X0, X1);
  }

  // If the first operand (for int5 type) or the second one (for other vector
  // types) is a vector splat, replace it with scalar argument.
  if (IntrinsicID == Intrinsic::tpc_add_mask) {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X0))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        X0 = Cast->getSubExpr();
  } else {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X1))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        X1 = Cast->getSubExpr();
  }

  SmallVector<llvm::Value *, 8> Args;
  for (unsigned ArgNo = 0; ArgNo < NumInputs; ++ArgNo)
    Args.push_back(emitOperand(CGF, E->getArg(ArgNo)));
  if (IntrinsicID == Intrinsic::tpc_add_mask)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(DT);
  Args.push_back(/* SW */ llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));

  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity) && IntrinsicID != Intrinsic::tpc_add_mask) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function* Callee = nullptr;
  switch (IntrinsicID) {
  case Intrinsic::tpc_add:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Args[0]->getType(),
                                     Args[1]->getType(),
                                     Predicate->getType() });
    break;
  case Intrinsic::tpc_add_mask:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { Args[0]->getType(),
                                     Args[1]->getType() });
    break;
  case Intrinsic::tpc_add_x2:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Args[1]->getType(),
                                     Args[2]->getType(),
                                     Predicate->getType()});
    break;
  default:
    llvm_unreachable("Unhandled ADD intrinsic");
  }

  Value *Result = CGF->Builder.CreateCall(Callee, Args);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}

static Value *emit_SUB(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned DimMaskOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Data type.
  auto DT = llvm::ConstantInt::get(CGF->Int8Ty,
                                   getOptypeValue(E->getArg(1)->getType()));

  unsigned IntrinsicID;
  unsigned NumInputs;
  unsigned RequiredSwitches = 0;
  // Add NO_BORROW_GEN and BORROW switches to the mask
  const unsigned SwitchMask = TPCII::SW_X2_ARITHMETIC;
  switch (BuiltinID) {
  case TPC::BIs_f32_sub:
  case TPC::BIs_i32_sub:
  case TPC::BIs_u32_sub:
  case TPC::BIs_i16_sub:
  case TPC::BIs_u16_sub:
  case TPC::BIs_i8_sub:
  case TPC::BIs_u8_sub:
  case TPC::BIs_bf16_sub:
  case TPC::BIs_f16_sub:
  case TPC::BIs_f8_sub:
  case TPC::BIs_h8_sub:

  case TPC::BIv_f32_sub_vb:
  case TPC::BIv_f32_sub_b:
  case TPC::BIv_bf16_sub_vb:
  case TPC::BIv_bf16_sub_b:
  case TPC::BIv_f16_sub_vb:
  case TPC::BIv_f16_sub_b:

  case TPC::BIv_f8_sub_vb:
  case TPC::BIv_f8_sub_b:
  case TPC::BIv_h8_sub_vb:
  case TPC::BIv_h8_sub_b:

  case TPC::BIv_i32_sub_vb:
  case TPC::BIv_i32_sub_b:
  case TPC::BIv_u32_sub_vb:
  case TPC::BIv_u32_sub_b:
  case TPC::BIv_i16_sub_vb:
  case TPC::BIv_i16_sub_b:
  case TPC::BIv_u16_sub_vb:
  case TPC::BIv_u16_sub_b:
  case TPC::BIv_i8_sub_vb:
  case TPC::BIv_i8_sub_b:
  case TPC::BIv_u8_sub_vb:
  case TPC::BIv_u8_sub_b:
    IntrinsicID = Intrinsic::tpc_sub;
    NumInputs = 2;
    break;
  case TPC::BIi_i32_sub:
    IntrinsicID = Intrinsic::tpc_sub_mask;
    NumInputs = 2;
    break;
  case TPC::BIv_f32_sub_x2_vb:
  case TPC::BIv_f32_sub_x2_b:
    IntrinsicID = Intrinsic::tpc_sub_x2;
    NumInputs = 3;
    RequiredSwitches = TPCII::SW_X2_ARITHMETIC;
    break;
  default:
    llvm_unreachable("Unhandled SUB intrinsic");
  }

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  // If the first operand (for int5 type) or the second one (for other vector
  // types) is a vector splat, replace it with scalar argument.
  const Expr *X0 = E->getArg(0);
  const Expr *X1 = E->getArg(1);
  if (IntrinsicID == Intrinsic::tpc_sub_mask) {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X0))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        X0 = Cast->getSubExpr();
  } else {
    if (auto *Cast = dyn_cast<ImplicitCastExpr>(X1))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        X1 = Cast->getSubExpr();
  }

  SmallVector<llvm::Value *, 8> Args;
  for (unsigned ArgNo = 0; ArgNo < NumInputs; ++ArgNo)
    Args.push_back(emitOperand(CGF, E->getArg(ArgNo)));
  if (IntrinsicID == Intrinsic::tpc_sub_mask)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(DT);
  Args.push_back(/* SW */ llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));

  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity) && IntrinsicID != Intrinsic::tpc_sub_mask) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function* Callee = nullptr;
  switch (IntrinsicID) {
  case Intrinsic::tpc_sub:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Args[0]->getType(),
                                     Args[1]->getType(),
                                     Predicate->getType() });
    break;
  case Intrinsic::tpc_sub_mask:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { Args[0]->getType(),
                                     Args[1]->getType() });
    break;
  case Intrinsic::tpc_sub_x2:
    Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                   { ResultTy,
                                     Args[1]->getType(),
                                     Args[2]->getType(),
                                     Predicate->getType()});
    break;
  default:
    llvm_unreachable("Unhandled SUB intrinsic");
  }
  Value *Result = CGF->Builder.CreateCall(Callee, Args);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}

static Value *emit_MAX(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  return emit_BinOp(CGF, BuiltinID, E, Intrinsic::tpc_max, Intrinsic::tpc_max_mask);
}

static Value *emit_MIN(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  return emit_BinOp(CGF, BuiltinID, E, Intrinsic::tpc_min, Intrinsic::tpc_min_mask);
}

static Value *emit_AND(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  return emit_BinOp(CGF, BuiltinID, E, Intrinsic::tpc_and, Intrinsic::tpc_and_mask);
}

static Value *emit_OR(CodeGenFunction *CGF, unsigned BuiltinID,
                      const CallExpr *E, ReturnValueSlot ReturnValue,
                      llvm::Triple::ArchType Arch) {
  return emit_BinOp(CGF, BuiltinID, E, Intrinsic::tpc_or, Intrinsic::tpc_or_mask);
}

static Value *emit_XOR(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  return emit_BinOp(CGF, BuiltinID, E, Intrinsic::tpc_xor, Intrinsic::tpc_xor_mask);
}


// bool64 v_f32_cmp_eq_vb (float64 a, float64 b, int switches, bool64 income, bool64 predicate, bool polarity);
//
static Value *emit_CMP(CodeGenFunction *CGF, unsigned BuiltinID, const CallExpr *E, unsigned IntrinsicID) {
  const unsigned NumArgs = E->getNumArgs();
  assert(NumArgs == 6);
  const unsigned Src1OpNum = 0;
  const unsigned Src2OpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  const Expr *X0 = E->getArg(Src1OpNum);
  const Expr *X1 = E->getArg(Src2OpNum);
  if (auto *Cast = dyn_cast<ImplicitCastExpr>(X0))
    if (Cast->getCastKind() == CastKind::CK_VectorSplat)
      std::swap(X0, X1);
  if (auto *Cast = dyn_cast<ImplicitCastExpr>(X1))
    if (Cast->getCastKind() == CastKind::CK_VectorSplat)
      X1 = Cast->getSubExpr();

  Value *Src1 = emitOperand(CGF, X0);
  Value *Src2 = emitOperand(CGF, X1);
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(Src1OpNum)->getType()));
  Value *SwitchSet = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(IntrinsicID,
                                           { ResultTy,
                                             Src1->getType(),
                                             Src2->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src1, Src2, DT, SwitchSet, Income, Predicate, Polarity});
  return Result;
}

static Value *emit_CMP_EQ(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  return emit_CMP(CGF, BuiltinID, E, Intrinsic::tpc_cmp_eq);
}

static Value *emit_CMP_NEQ(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  return emit_CMP(CGF, BuiltinID, E, Intrinsic::tpc_cmp_neq);
}

static Value *emit_CMP_LESS(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  return emit_CMP(CGF, BuiltinID, E, Intrinsic::tpc_cmp_less);
}

static Value *emit_CMP_LEQ(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  return emit_CMP(CGF, BuiltinID, E, Intrinsic::tpc_cmp_leq);
}

static Value *emit_CMP_GRT(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  return emit_CMP(CGF, BuiltinID, E, Intrinsic::tpc_cmp_grt);
}

static Value *emit_CMP_GEQ(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  return emit_CMP(CGF, BuiltinID, E, Intrinsic::tpc_cmp_geq);
}


// int32_t mov_irf_dim(int5 src, const int8_t dim, int switches, int32_t income, bool predicate, bool polarity)
// int32_t_pair_t long_irf_dim(int5 src, const int8_t dim, int switches, int32_t_pair_t income, bool predicate, bool polarity);
static Value *emit_MOV_IRF_DIM(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned DimOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  assert(NumArgs == 6);
  if (BuiltinID == TPC::BIlong_irf_dim && !CGF->CGM.getCodeGenOpts().LongIRF)
    report_fatal_error("long_irf_dim relevants only if -long-irf specified");

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  if (BuiltinID == TPC::BIlong_irf_dim)
    SwitchVal |= TPCII::SW_MOV_IRF_DIM_BOTH;

  Value *Src = CGF->EmitScalarExpr(E->getArg(SrcOpNum));
  Value *Dim = CGF->EmitScalarExpr(E->getArg(DimOpNum));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_irf_dim,
                                           {Income->getType()});
  Value *Result = CGF->Builder.CreateCall(Callee,
      { Src, Dim, Switches, Income, Predicate, Polarity });


  if (Multiplicity == 0)
    return Result;
  if (Multiplicity == 2)
    Result = getStructFieldFromDoubleScalarRegister(*CGF, FEResultTy, Result);
  else
    llvm_unreachable("Unhandled case");

  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());

  return Result;
}


// bool256 v_i1_mov_b (int32_t a, const int flavor, int switches, bool256 income, bool predicate, bool polarity);
// bool256 v_i1_mov_vb(int32_t a, const int flavor, int switches, bool256 income, bool256 predicate, bool polarity);
static Value *emit_MOV_FLAVOR(CodeGenFunction *CGF, unsigned BuiltinID,
                              const CallExpr *E, ReturnValueSlot ReturnValue,
                              llvm::Triple::ArchType Arch) {
  SmallVector<llvm::Value *, 8> Args;

  Args.push_back(CGF->EmitScalarExpr(E->getArg(0))); // src
  Args.push_back(CGF->EmitScalarExpr(E->getArg(1))); // flavor
  Args.push_back(CGF->EmitScalarExpr(E->getArg(2))); // switches
  Args.push_back(CGF->EmitScalarExpr(E->getArg(3))); // income
  llvm::Value *Predicate = emitPredicate(CGF, E->getArg(4));
  Args.push_back(Predicate);
  Args.push_back(CGF->EvaluateExprAsBool(E->getArg(5))); // polarity

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_flavor,
                                           { Predicate->getType() } );
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  return Result;
}


// int5 i_i32_mov(int5 src, int dimmask, int switches, int5 income, bool predicate, bool polarity);
static Value *emit_MOV_IRF(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  SmallVector<llvm::Value *, 8> Args;

  llvm::Value *Src = CGF->EmitScalarExpr(E->getArg(0));
  Args.push_back(Src); // src
  Args.push_back(CGF->EmitScalarExpr(E->getArg(1))); // dimmask
  Args.push_back(CGF->EmitScalarExpr(E->getArg(2))); // switches
  Args.push_back(CGF->EmitScalarExpr(E->getArg(3))); // income
  Args.push_back(emitPredicate(CGF, E->getArg(4)));  // predicate
  Args.push_back(CGF->EvaluateExprAsBool(E->getArg(5))); // polarity

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov_mask,
                                           { Src->getType() });
  return CGF->Builder.CreateCall(Callee, Args);
}


// bool s_i1_mov(bool a, int switches, uint8_t income, bool predicate, bool polarity);
// float64 v_f32_mov_vb (float64 a, int switches, float64 income, bool64  predicate, bool polarity);
static Value *emit_MOV(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches.
  unsigned RequiredSwitches;
  const unsigned SwitchMask = TPCII::SW_X2_MOV;
  switch (BuiltinID) {
  case TPC::BIs_f32_mov:
  case TPC::BIs_bf16_mov:
  case TPC::BIs_f16_mov:
  case TPC::BIs_f8_mov:
  case TPC::BIs_h8_mov:
  case TPC::BIs_i32_mov:
  case TPC::BIs_u32_mov:
  case TPC::BIs_i16_mov:
  case TPC::BIs_u16_mov:
  case TPC::BIs_i8_mov:
  case TPC::BIs_u8_mov:
  case TPC::BIs_i1_mov:
  case TPC::BIv_i1_mov_b:
  case TPC::BIv_i1_mov_vb:
  case TPC::BIv_i1_mov_i1_b:
  case TPC::BIv_i1_mov_i1_vb:
  case TPC::BIv_i1_mov_u32_b:
  case TPC::BIv_i1_mov_u32_vb:
  case TPC::BIv_u32_mov_i1_b:
  case TPC::BIv_u32_mov_i1_vb:
  case TPC::BIv_f32_mov_vb:
  case TPC::BIv_bf16_mov_vb:
  case TPC::BIv_f16_mov_vb:
  case TPC::BIv_f8_mov_vb:
  case TPC::BIv_h8_mov_vb:
  case TPC::BIv_i32_mov_vb:
  case TPC::BIv_u32_mov_vb:
  case TPC::BIv_i16_mov_vb:
  case TPC::BIv_u16_mov_vb:
  case TPC::BIv_i8_mov_vb:
  case TPC::BIv_u8_mov_vb:
  case TPC::BIv_f32_mov_b:
  case TPC::BIv_bf16_mov_b:
  case TPC::BIv_f16_mov_b:
  case TPC::BIv_f8_mov_b:
  case TPC::BIv_h8_mov_b:
  case TPC::BIv_i32_mov_b:
  case TPC::BIv_u32_mov_b:
  case TPC::BIv_i16_mov_b:
  case TPC::BIv_u16_mov_b:
  case TPC::BIv_i8_mov_b:
  case TPC::BIv_u8_mov_b:
    RequiredSwitches = 0;
    break;
  case TPC::BIv_f32_mov_x2_b:
  case TPC::BIv_f32_mov_x2_vb:
  case TPC::BIv_bf16_mov_x2_b:
  case TPC::BIv_bf16_mov_x2_vb:
  case TPC::BIv_f16_mov_x2_b:
  case TPC::BIv_f16_mov_x2_vb:
  case TPC::BIv_i32_mov_x2_b:
  case TPC::BIv_i32_mov_x2_vb:
  case TPC::BIv_u32_mov_x2_b:
  case TPC::BIv_u32_mov_x2_vb:
  case TPC::BIv_i16_mov_x2_b:
  case TPC::BIv_i16_mov_x2_vb:
  case TPC::BIv_u16_mov_x2_b:
  case TPC::BIv_u16_mov_x2_vb:
  case TPC::BIv_i8_mov_x2_b:
  case TPC::BIv_i8_mov_x2_vb:
  case TPC::BIv_u8_mov_x2_b:
  case TPC::BIv_u8_mov_x2_vb:
  //case TPC::BIv_f8_mov_x2_b:
  case TPC::BIv_f8_mov_x2_vb:
  //case TPC::BIv_h8_mov_x2_b:
  case TPC::BIv_h8_mov_x2_vb:
    RequiredSwitches = TPCII::SW_X2_MOV;
    break;
  default:
    llvm_unreachable("Unhandled MOV intrinsic");
  }
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;

  const Expr *SrcArg = E->getArg(SrcOpNum);
  if (auto *Cast = dyn_cast<ImplicitCastExpr>(SrcArg))
    if (Cast->getCastKind() == CastKind::CK_VectorSplat)
      SrcArg = Cast->getSubExpr();

  // Prepare arguments.
  Value *Src = emitOperand(CGF, SrcArg);
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(SrcOpNum)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_mov,
                                           { Income->getType(),
                                             Src->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src, DT, Switches, Income, Predicate, Polarity});
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// uint32_t_pair_t get_addr(__global void *addr, int switches, uint32_t_pair_t income, bool predicate, bool polarity);
static Value *emit_GET_ADDR(CodeGenFunction *CGF, unsigned BuiltinID,
                            const CallExpr *E, ReturnValueSlot ReturnValue,
                            llvm::Triple::ArchType Arch) {
  const unsigned SrcOpNum = 0;
  const unsigned SwOpNum = 1;
  const unsigned IncomeOpNum = 2;
  const unsigned PredOpNum = 3;
  const unsigned PolarityOpNum = 4;

  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 2 && "Only value 2 is available");
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  Value *Src = emitOperand(CGF, E->getArg(SrcOpNum));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(SwOpNum));
  Value *Predicate = CGF->EvaluateExprAsBool(E->getArg(PredOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  Value *Income = emitOperand(CGF, E->getArg(IncomeOpNum));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_get_addr);
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src, Switches, Income, Predicate, Polarity});
  assert(Result);
  Result = getStructFieldFromDoubleScalarRegister(*CGF, FEResultTy, Result);

  if (!ReturnValue.isNull())
    return CGF->Builder.CreateStore(Result, ReturnValue.getValue());

  return Result;
}


// void update_addr(__global void **ptr, uint32_t_pair_t addr, int switches, bool predicate, bool polarity);
static Value *emit_UPDATE_ADDR(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  const unsigned PtrOpNum = 0;
  const unsigned AddrOpNum = 1;
  const unsigned SwOpNum = 2;
  const unsigned PredOpNum = 3;
  const unsigned PolarityOpNum = 4;

  const auto *PtrTy = cast<clang::PointerType>(E->getArg(PtrOpNum)->getType());
  Value *Ptr = CGF->EmitScalarExpr(E->getArg(PtrOpNum));
  MaybeAlign MAlign = Ptr->getPointerAlignment(CGF->CGM.getDataLayout());
  unsigned AlignValue = 1;
  if (MAlign) {
    llvm::Align A = *MAlign;
    AlignValue = A.value();
  }

  Address Ptr0 = CGF->EmitLoadOfPointer(
    Address(Ptr, CharUnits::fromQuantity(AlignValue)),
    cast<clang::PointerType>(E->getArg(PtrOpNum)->getType()));

  Value *Addr = emitOperand(CGF, E->getArg(AddrOpNum));
  Value *Switches = CGF->EmitScalarExpr(E->getArg(SwOpNum));
  Value *Predicate = CGF->EvaluateExprAsBool(E->getArg(PredOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_update_addr);
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Ptr0.getPointer(), Addr, Switches, Predicate, Polarity});
  assert(Result);

  CharUnits Alignment;
  if (auto *AI = dyn_cast<AllocaInst>(Ptr))
    Alignment = CharUnits::fromQuantity(AI->getAlignment());
  else
    Alignment = CharUnits::fromQuantity(4);
  Address VarPtr(Ptr, Alignment);
  Value *PtrUpd = Result;
  CGF->EmitStoreOfScalar(PtrUpd, CGF->MakeAddrLValue(VarPtr, QualType(PtrTy, 0)));

  return UndefValue::get(CGF->VoidTy);
}


static Value *emit_THREAD_SYNC(CodeGenFunction *CGF) {
  return CGF->Builder.CreateCall(CGF->CGM.getIntrinsic(Intrinsic::tpc_thread_sync));
}

  // float s_f32_calc_fp_special(float src1, float src2, const int func, float income, bool predicate, bool polarity);
//
static Value *emit_CALC_FP_SPECIAL(CodeGenFunction *CGF, unsigned BuiltinID,
                                   const CallExpr *E, ReturnValueSlot ReturnValue,
                                   llvm::Triple::ArchType Arch) {
  SmallVector<llvm::Value *, 8> Args;

  llvm::Type *ResultTy = CGF->ConvertType(E->getType());
  Value *X0 = CGF->EmitScalarExpr(E->getArg(0));
  Value *X1 = CGF->EmitScalarExpr(E->getArg(1));
  Value *SwitchSet = CGF->EmitScalarExpr(E->getArg(2));
  auto SwVal = cast<ConstantInt>(SwitchSet);

  // In the case of unary function replace the second argument with UNDEF.
  switch (SwVal->getLimitedValue()) {
  case TPCII::SW_DIV:
  case TPCII::SW_POW:
    break;
  default:
    X1 = UndefValue::get(X1->getType());
  }

  Args.push_back(X0);
  Args.push_back(X1);
  Args.push_back( /* DT */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(0)->getType())));
  Args.push_back(SwitchSet);
  Args.push_back(/* Income */ CGF->EmitScalarExpr(E->getArg(3)));
  Value *Predicate = emitPredicate(CGF, E->getArg(4));
  Args.push_back(Predicate);
  Args.push_back(/*Polarity*/ CGF->EmitScalarExpr(E->getArg(5)));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_calc_fp_special,
                                         { ResultTy,
                                           Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee, Args);
  return Result;
}


static Value *emit_ASO(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  Value *Switches = CGF->EmitScalarExpr(E->getArg(0));
  Value *Predicate = CGF->EvaluateExprAsBool(E->getArg(1));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(2));
  Function * Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_aso);
  return CGF->Builder.CreateCall(Callee, { Switches, Predicate, Polarity });
}


static Value *emit_CACHE_FLUSH(CodeGenFunction *CGF, unsigned BuiltinID,
                               const CallExpr *E, ReturnValueSlot ReturnValue,
                               llvm::Triple::ArchType Arch) {
  Value *Switches = CGF->EmitScalarExpr(E->getArg(0));
  Value *Predicate = CGF->EvaluateExprAsBool(E->getArg(1));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(2));
  Function * Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_cache_flush);
  return CGF->Builder.CreateCall(Callee, { Switches, Predicate, Polarity });
}

static Value *emit_CACHE_INVALIDATE(CodeGenFunction *CGF, unsigned BuiltinID,
                                    const CallExpr *E,
                                    ReturnValueSlot ReturnValue,
                                    llvm::Triple::ArchType Arch) {
  Value *Switches = CGF->EmitScalarExpr(E->getArg(0));
  Value *Predicate = CGF->EvaluateExprAsBool(E->getArg(1));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(2));
  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_cache_invalidate);
  return CGF->Builder.CreateCall(Callee, { Switches, Predicate, Polarity });
}

static Value *emit_CACHE_FLUSH_INVALIDATE(CodeGenFunction *CGF, unsigned BuiltinID,
                                          const CallExpr *E, ReturnValueSlot ReturnValue,
                                          llvm::Triple::ArchType Arch) {
  assert(CGF->getContext().getTargetInfo().hasFeature("doron1"));
  Value *Addr       = CGF->EmitScalarExpr(E->getArg(0));
  Value *Switches   = CGF->EmitScalarExpr(E->getArg(1));
  Value *Predicate  = CGF->EvaluateExprAsBool(E->getArg(2));
  Value *Polarity   = CGF->EvaluateExprAsBool(E->getArg(3));
  Function * Callee = BuiltinID == TPC::BIcache_invalidate_addr ? CGF->CGM.getIntrinsic(Intrinsic::tpc_cache_invalidate_addr) :
                                                                  CGF->CGM.getIntrinsic(Intrinsic::tpc_cache_flush_addr);
  return CGF->Builder.CreateCall(Callee, { Addr, Switches, Predicate, Polarity });
}


// int64 v_i32_shuffle_b (int64 a, uchar256 b, int switches, int64 income, bool predicate, bool polarity);
//
static Value *emit_SHUFFLE(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  SmallVector<llvm::Value *, 8> Args;

  const Expr *Src1 = E->getArg(0);
  const Expr *Src2 = E->getArg(1);
  llvm::Type *ResultTy = CGF->ConvertType(E->getType());

  Args.push_back(/* Src1 */ CGF->EmitScalarExpr(Src1));
  Args.push_back(/* Src2 */ CGF->EmitScalarExpr(Src2));
  Args.push_back(/* DT   */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(Src1->getType())));
  Args.push_back(/* SW   */ CGF->EmitScalarExpr(E->getArg(2)));
  Args.push_back(/* Income    */ CGF->EmitScalarExpr(E->getArg(3)));
  Args.push_back(/* Predicate */ emitPredicate(CGF, E->getArg(4)));
  Args.push_back(/* Polarity  */ CGF->EvaluateExprAsBool(E->getArg(5)));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_shuffle,
                       { ResultTy, Args[Args.size() - 2]->getType() });
  return CGF->Builder.CreateCall(Callee, Args);
}


// short128 v_i16_pack_b(short128 a, int switches, short128 income, bool predicate, bool polarity);
//
static Value *emit_PACK(CodeGenFunction *CGF, unsigned BuiltinID,
                        const CallExpr *E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  SmallVector<llvm::Value *, 8> Args;

  const Expr *Src = E->getArg(0);
  llvm::Type *ResultTy = CGF->ConvertType(E->getType());

  Args.push_back(/* Src    */ CGF->EmitScalarExpr(Src));
  Args.push_back(/* DT     */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(Src->getType())));
  Args.push_back(/* SW     */ CGF->EmitScalarExpr(E->getArg(1)));
  Args.push_back(/* Income */ CGF->EmitScalarExpr(E->getArg(2)));
  Args.push_back(/* Predicate */ emitPredicate(CGF, E->getArg(3)));
  Args.push_back(/* Polarity  */ CGF->EmitScalarExpr(E->getArg(4)));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_pack,
                       { ResultTy, Args[Args.size() - 2]->getType() });
  return CGF->Builder.CreateCall(Callee, Args);
}


// short128 v_i16_pack_b(short128 a, int switches, short128 income, bool predicate, bool polarity);
//
static Value *emit_UNPACK(CodeGenFunction *CGF, unsigned BuiltinID,
                          const CallExpr *E, ReturnValueSlot ReturnValue,
                          llvm::Triple::ArchType Arch) {
  const unsigned IncomeValueNo = 3;
  SmallVector<llvm::Value *, 8> Args;

  const Expr *Src = E->getArg(0);
  llvm::Type *ResultTy = CGF->ConvertType(E->getType());

  Args.push_back(/* Src    */ CGF->EmitScalarExpr(Src));
  Args.push_back(/* DT     */ llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(Src->getType())));
  Args.push_back(/* SW     */ CGF->EmitScalarExpr(E->getArg(1)));
  Args.push_back(/* Income */ CGF->EmitScalarExpr(E->getArg(2)));
  Args.push_back(/* Predicate */ emitPredicate(CGF, E->getArg(3)));
  Args.push_back(/* Polarity  */ CGF->EmitScalarExpr(E->getArg(4)));

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_unpack,
                       { ResultTy, Args[IncomeValueNo + 1]->getType() });
  return CGF->Builder.CreateCall(Callee, Args);
}


// float64 get_lut_entry_and_interval_start_b(float64, const int8_t shift, int switches, uchar256 income, bool predicate, bool polarity);
//
static Value *emit_GET_LUT(CodeGenFunction *CGF, unsigned BuiltinID,
                           const CallExpr *E, ReturnValueSlot ReturnValue,
                           llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  assert(NumArgs == 6);
  const unsigned SrcOpNum = 0;
  const unsigned ShiftOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  llvm::Type *FEResultTy = Multiplicity ? CGF->ConvertType(E->getType()) : ResultTy;

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Prepare arguments.
  Value *Src = CGF->EmitScalarExpr(E->getArg(SrcOpNum));
  Value *Shift = CGF->EmitScalarExpr(E->getArg(ShiftOpNum));
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(SrcOpNum)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_get_lut_entry,
                              { ResultTy,
                                Src->getType(),
                                Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src, Shift, DT, Switches, Income, Predicate, Polarity});
  assert(Result);

  return prepareResult(CGF, ReturnValue, Result, Multiplicity, FEResultTy);
}


// float64 v_f32_form_fp_num_b(float64 a, float64 b, float64 c, int switches, float64 income, bool predicate, bool polarity)
//
static Value *emit_FORM_FP_NUMBER(CodeGenFunction *CGF, unsigned BuiltinID,
                                  const CallExpr *E, ReturnValueSlot ReturnValue,
                                  llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SrcAOpNum = 0;
  const unsigned SrcBOpNum = 1;
  const unsigned SrcCOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  unsigned RequiredSwitches;
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  switch (BuiltinID) {
  case TPC::BIv_f32_form_fp_num_b:
  case TPC::BIv_f32_form_fp_num_vb:
  case TPC::BIv_bf16_form_fp_num_b:
  case TPC::BIv_bf16_form_fp_num_vb:
  case TPC::BIv_f16_form_fp_num_b:
  case TPC::BIv_f16_form_fp_num_vb:
//fp8
  case TPC::BIv_f8_form_fp_num_b:
  case TPC::BIv_f8_form_fp_num_vb:
  case TPC::BIv_h8_form_fp_num_b:
  case TPC::BIv_h8_form_fp_num_vb:
    RequiredSwitches = 0;
    break;
  case TPC::BIv_f32_form_fp_num_ie_b:
  case TPC::BIv_f32_form_fp_num_ie_vb:
  case TPC::BIv_bf16_form_fp_num_ie_b: 
  case TPC::BIv_bf16_form_fp_num_ie_vb: 
  case TPC::BIv_f16_form_fp_num_ie_b: 
  case TPC::BIv_f16_form_fp_num_ie_vb :
  //fp8
  case TPC::BIv_f8_form_fp_num_ie_b:
  case TPC::BIv_f8_form_fp_num_ie_vb:
  case TPC::BIv_h8_form_fp_num_ie_b:
  case TPC::BIv_h8_form_fp_num_ie_vb:
    RequiredSwitches = TPCII::SW_EXP_IS_NUM;
    break;
  default:
    llvm_unreachable("Unhandled FORM_FP intrinsic");
  }
  // Switch SW_EXP_IS_NUM should not be used directly. Instead, users must use
  // corresponding functions with `_ie_` suffix, because if this switch is used,
  // type of function arguments change. Unfortunately, this switch is used in
  // kernels so don't clear the corresponding bit.
  //SwitchVal &= ~SwitchMask;
  SwitchVal |= RequiredSwitches;
  // Prepare arguments.
  Value *SrcA = CGF->EmitScalarExpr(E->getArg(SrcAOpNum));
  Value *SrcB = CGF->EmitScalarExpr(E->getArg(SrcBOpNum));
  Value *SrcC = CGF->EmitScalarExpr(E->getArg(SrcCOpNum));
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(SrcBOpNum)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_form_fp_num,
                                         { ResultTy,
                                           SrcA->getType(),
                                           Predicate->getType() });
  return CGF->Builder.CreateCall(Callee,
      {SrcA, SrcB, SrcC, DT, Switches, Income, Predicate, Polarity});
}


// int32_t s_i32_abs(int32_t a, int switches, int32_t income, bool predicate, bool polarity);
// int5 i_i32_abs(int5 a, int dimmask, int switches, int5 income, bool predicate, bool polarity);
//
static Value *emit_ABS(CodeGenFunction *CGF, unsigned BuiltinID,
                       const CallExpr *E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned DimMaskOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  bool WithMask = NumArgs == 6;
  assert(WithMask || NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Prepare arguments.
  SmallVector<llvm::Value *, 6> Args;
  Value *Src = CGF->EmitScalarExpr(E->getArg(SrcOpNum));
  Args.push_back(Src);
  if (WithMask)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(SrcOpNum)->getType())));
  Args.push_back(llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (!WithMask && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function* Callee;
  if (WithMask) {
    Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_abs_mask,
                                   { Src->getType() });
  } else {
    Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_abs,
                                   { ResultTy,
                                     Src->getType(),
                                     Predicate->getType() });
  }
  return CGF->Builder.CreateCall(Callee, Args);
}


// int64 v_i32_not_b(int64 a, int switches, int64 income, bool predicate, bool polarity);
// int5 i_i32_not(int5 a, int dimmask, const int switches, int5 income, bool predicate, bool polarity);
//
static Value *emit_NOT(CodeGenFunction* CGF, unsigned BuiltinID,
                       const CallExpr* E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned SrcOpNum = 0;
  const unsigned DimMaskOpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  bool WithMask = NumArgs == 6;
  assert(WithMask || NumArgs == 5);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Prepare arguments.
  SmallVector<llvm::Value *, 6> Args;
  Value *Src = CGF->EmitScalarExpr(E->getArg(SrcOpNum));
  Args.push_back(Src);
  if (WithMask)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(SrcOpNum)->getType())));
  Args.push_back(llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (!WithMask && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function* Callee;
  if (WithMask) {
    Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_not_mask,
                                   { Src->getType() });
  } else {
    Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_not,
                                   { ResultTy,
                                     Src->getType(),
                                     Predicate->getType() });
  }
  return CGF->Builder.CreateCall(Callee, Args);
}


// int64 v_i32_shr_b(int64 a, int64 b, int switches, int64 income, bool predicate, bool polarity);
// int5 i_i32_shr(int5 a, int5 b, int dimmask, const int switches, int5 income, bool predicate, bool polarity);
//
static Value *emit_Shift(CodeGenFunction* CGF, unsigned BuiltinID, const CallExpr* E,
                         unsigned RegularIntr, unsigned MaskIntr) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned Src1OpNum = 0;
  const unsigned Src2OpNum = 1;
  const unsigned DimMaskOpNum = 2;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;
  bool WithMask = NumArgs == 7;
  assert(WithMask || NumArgs == 6);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();

  // Prepare arguments.
  SmallVector<llvm::Value *, 6> Args;
  Value *Src1 = CGF->EmitScalarExpr(E->getArg(Src1OpNum));
  const Expr *Src2Arg = E->getArg(Src2OpNum);
  if (auto *Cast = dyn_cast<ImplicitCastExpr>(Src2Arg))
    if (Cast->getCastKind() == CastKind::CK_VectorSplat)
      Src2Arg = Cast->getSubExpr();
  Value *Src2 = CGF->EmitScalarExpr(Src2Arg);
  Args.push_back(Src1);
  Args.push_back(Src2);
  if (WithMask)
    Args.push_back(CGF->EmitScalarExpr(E->getArg(DimMaskOpNum)));
  Args.push_back(llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(Src1OpNum)->getType())));
  Args.push_back(llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal));
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (!WithMask && isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);

  Function* Callee;
  if (WithMask) {
    Callee = CGF->CGM.getIntrinsic(MaskIntr, Src2->getType());
  } else {
    Callee = CGF->CGM.getIntrinsic(RegularIntr,
                                   { ResultTy,
                                     Src2->getType(),
                                     Predicate->getType() });
  }
  return CGF->Builder.CreateCall(Callee, Args);
}

static Value *emit_SHR(CodeGenFunction* CGF, unsigned BuiltinID,
                       const CallExpr* E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  return emit_Shift(CGF, BuiltinID, E, Intrinsic::tpc_shr, Intrinsic::tpc_shr_mask);
}

static Value* emit_SHL(CodeGenFunction* CGF, unsigned BuiltinID,
                       const CallExpr* E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  return emit_Shift(CGF, BuiltinID, E, Intrinsic::tpc_shl, Intrinsic::tpc_shl_mask);
}


// int64 v_i32_ash_b(int64 a, char256 b, int switches, int64 income, bool predicate, bool polarity);
//
static Value* emit_ASH(CodeGenFunction* CGF, unsigned BuiltinID,
                       const CallExpr* E, ReturnValueSlot ReturnValue,
                       llvm::Triple::ArchType Arch) {
  const unsigned NumArgs = E->getNumArgs();
  const unsigned Src1OpNum = 0;
  const unsigned Src2OpNum = 1;
  const unsigned SwOpNum = NumArgs - 4;
  const unsigned IncomeOpNum = NumArgs - 3;
  const unsigned PredOpNum = NumArgs - 2;
  const unsigned PolarityOpNum = NumArgs -1;

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);

  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  switch (BuiltinID) {
  default:
    break;
  case TPC::BIv_i32_ash_rhaz_b:
  case TPC::BIv_i32_ash_rhaz_vb:
  case TPC::BIv_u32_ash_rhaz_b:
  case TPC::BIv_u32_ash_rhaz_vb:
    SwitchVal |= TPCII::SW_RHAZ_RS;
    break;
  }

  // Prepare arguments.
  Value *Src1 = emitOperand(CGF, E->getArg(Src1OpNum));
  Value *Src2 = CGF->EmitScalarExpr(E->getArg(Src2OpNum));
  Value *DT = llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(E->getArg(Src1OpNum)->getType()));
  Value *Switches = llvm::ConstantInt::get(CGF->Int32Ty, SwitchVal);
  Value *Predicate = emitPredicate(CGF, E->getArg(PredOpNum));
  Value *Polarity = emitPredicate(CGF, E->getArg(PolarityOpNum));
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }

  Function *Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_ash,
                                           { ResultTy,
                                             Src1->getType(),
                                             Src2->getType(),
                                             Predicate->getType() });
  Value *Result = CGF->Builder.CreateCall(Callee,
      {Src1, Src2, DT, Switches, Income, Predicate, Polarity});

  return Result;
}


static Value* emit_MSAC(CodeGenFunction* CGF, unsigned BuiltinID,
                        const CallExpr* E, ReturnValueSlot ReturnValue,
                        llvm::Triple::ArchType Arch) {
  const Expr* SrcA = E->getArg(0);
  const Expr* SrcB = E->getArg(1);
  const Expr* SrcC = E->getArg(2);
  const Expr* SrcD = E->getArg(3);
  const Expr* Sw = E->getArg(4);

  if (auto * Cast = dyn_cast<ImplicitCastExpr>(SrcB))
    if (Cast->getCastKind() == CastKind::CK_VectorSplat)
      SrcB = Cast->getSubExpr();
  if (SrcB->getType()->isVectorType())
    if (auto * Cast = dyn_cast<ImplicitCastExpr>(SrcD))
      if (Cast->getCastKind() == CastKind::CK_VectorSplat)
        SrcD = Cast->getSubExpr();

  SmallVector<llvm::Value*, 9> Args;
  Args.push_back(CGF->EmitScalarExpr(SrcA));
  Args.push_back(CGF->EmitScalarExpr(SrcB));
  Args.push_back(CGF->EmitScalarExpr(SrcC));
  Args.push_back(CGF->EmitScalarExpr(SrcD));
  Args.push_back(llvm::ConstantInt::get(CGF->Int8Ty, getOptypeValue(SrcA->getType())));
  Args.push_back(CGF->EmitScalarExpr(Sw));
  Args.push_back(CGF->EmitScalarExpr(E->getArg(5)));
  Args.push_back(emitPredicate(CGF, E->getArg(6)));
  Args.push_back(/* Polarity */ CGF->EvaluateExprAsBool(E->getArg(7)));

  Function* Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_msac,
                                           { Args[6]->getType(),
                                             Args[1]->getType(),
                                             Args[3]->getType(),
                                             Args[7]->getType() });
  Value* Result = CGF->Builder.CreateCall(Callee, Args);
  assert(Result);
  return Result;
}

// uint32_t get_dim_size(int32_t a, uint32_t dim);
static Value *emit_GET_DIM_SIZE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 2);
  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  Value *const Dim = CGF.EmitScalarExpr(E.getArg(1));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_dim_size), {TensorID, Dim});
}

// void set_dim_size(int32_t a, uint32_t dim, uint32_t value);
static Value *emit_SET_DIM_SIZE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 3);
  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  Value *const Dim = CGF.EmitScalarExpr(E.getArg(1));
  Value *const V = CGF.EmitScalarExpr(E.getArg(2));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_dim_size), {TensorID, Dim, V});
}

// uint32_t get_dim_stride(int32_t a, uint32_t dim);
static Value *emit_GET_DIM_STRIDE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 2);
  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  Value *const Dim = CGF.EmitScalarExpr(E.getArg(1));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_dim_stride), {TensorID, Dim});
}

// void set_dim_stride(int32_t a, uint32_t dim, uint32_t value);
static Value *emit_SET_DIM_STRIDE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 3);
  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  Value *const Dim = CGF.EmitScalarExpr(E.getArg(1));
  Value *const V = CGF.EmitScalarExpr(E.getArg(2));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_dim_stride), {TensorID, Dim, V});
}

// int32_t get_semaphore_value();
static Value *emit_GET_SEMAPHORE_VALUE(CodeGenFunction &CGF,
                                       const CallExpr &E) {
  assert(E.getNumArgs() == 0);
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_semaphore_value));
}

// void set_semaphore_value(int32_t);
static Value *emit_SET_SEMAPHORE_VALUE(CodeGenFunction &CGF,
                                       const CallExpr &E) {
  assert(E.getNumArgs() == 1);
  Value *const V = CGF.EmitScalarExpr(E.getArg(0));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_semaphore_value), {V});
}

// int32_t get_csr_value();
static Value *emit_GET_CSR_VALUE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 0);
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_csr_value));
}

// void set_csr_value(int32_t);
static Value *emit_SET_CSR_VALUE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 1);
  Value *const V = CGF.EmitScalarExpr(E.getArg(0));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_csr_value), {V});
}

// int32_t get_convert_csr_value();
static Value *emit_GET_CONVERT_CSR_VALUE(CodeGenFunction &CGF,
                                         const CallExpr &E) {
  assert(E.getNumArgs() == 0);
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_convert_csr_value));
}

// void set_convert_csr_value(int32_t);
static Value *emit_SET_CONVERT_CSR_VALUE(CodeGenFunction &CGF,
                                         const CallExpr &E) {
  assert(E.getNumArgs() == 1);
  Value *const V = CGF.EmitScalarExpr(E.getArg(0));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_convert_csr_value), {V});
}

// uint32_t get_pad_value_uint(int32_t a);
// int32_t  get_pad_value_int(int32_t a);
// float    get_pad_value_float(int32_t a);
// bfloat   get_pad_value_bf16(int32_t a);
// uint16_t get_pad_value_ushort(int32_t a);
// int16_t  get_pad_value_short(int32_t a);
// uint8_t  get_pad_value_uchar(int32_t a);
// int8_t   get_pad_value_char(int32_t a);
static Value *emit_GET_PAD_VALUE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 1);

  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(&CGF, E.getType(), Multiplicity);
  assert(Multiplicity == 0);

  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_pad_value, {ResultTy}),
      {TensorID});
}

// void set_pad_value_uint(int32_t a, uint32_t value);
// void set_pad_value_int(int32_t a, int32_t value);
// void set_pad_value_float(int32_t a, float value);
// void set_pad_value_bf16(int32_t a, bfloat value);
// void set_pad_value_ushort(int32_t a, uint16_t value);
// void set_pad_value_short(int32_t a, int16_t value);
// void set_pad_value_uchar(int32_t a, uint8_t value);
// void set_pad_value_char(int32_t a, int8_t value);
static Value *emit_SET_PAD_VALUE(CodeGenFunction &CGF, const CallExpr &E) {
  assert(E.getNumArgs() == 2);
  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  Value *const PadValue = CGF.EmitScalarExpr(E.getArg(1));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_pad_value, {PadValue->getType()}),
      {TensorID, PadValue});
}

// uint32_t get_tensor_hwpref_stride(int32_t tensor);
static Value *emit_GET_TENSOR_HWPREF_STRIDE(CodeGenFunction &CGF,
                                            const CallExpr &E) {
  assert(E.getNumArgs() == 1);
  Value *const TensorID = CGF.EmitScalarExpr(E.getArg(0));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_get_tensor_hwpref_stride),
      {TensorID});
}

// void set_tensor_hwpref_stride(int32_t tensor, uint32_t tensor);
static Value *emit_SET_TENSOR_HWPREF_STRIDE(CodeGenFunction &CGF,
                                            const CallExpr &E) {
  assert(E.getNumArgs() == 2);
  Value *const Tensor = CGF.EmitScalarExpr(E.getArg(0));
  Value *const Stride = CGF.EmitScalarExpr(E.getArg(1));
  return CGF.Builder.CreateCall(
      CGF.CGM.getIntrinsic(Intrinsic::tpc_set_tensor_hwpref_stride),
      {Tensor, Stride});
}

static Value *emit_READ_LFSR(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  const unsigned SwitchesOpNum = 0;
  const unsigned IncomeOpNum = 1;
  const unsigned PredicateOpNum = 2;
  const unsigned PolarityOpNum = 3;
  
  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);
  
  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  
  unsigned IntrinsicID;
  switch (SwitchVal) {
  case 0:
    IntrinsicID = Intrinsic::tpc_read_lfsr;
    break;
  case TPCII::SW_READ_ONLY:
    IntrinsicID = Intrinsic::tpc_read_lfsrnc;
    break;
  default:
    report_fatal_error("Unhandled READ_LFSR switch of intrinsic");
  }
  
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  
  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);
  
  Function* Callee = CGF->CGM.getIntrinsic(IntrinsicID, {Predicate->getType()});
  return CGF->Builder.CreateCall(Callee, Args);
}


static Value *emit_S_READ_LFSR(CodeGenFunction *CGF, unsigned BuiltinID,
                             const CallExpr *E, ReturnValueSlot ReturnValue,
                             llvm::Triple::ArchType Arch) {
  const unsigned SwitchesOpNum = 0;
  const unsigned IncomeOpNum = 1;
  const unsigned PredicateOpNum = 2;
  const unsigned PolarityOpNum = 3;
  
  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);
  
  // Determine switches.
  Expr::EvalResult ResVal;
  bool R = E->getArg(SwitchesOpNum)->EvaluateAsRValue(ResVal, CGF->getContext());
  assert(R); (void)R;
  unsigned SwitchVal = (unsigned)ResVal.Val.getInt().getLimitedValue();
  
  unsigned IntrinsicID;
  switch (SwitchVal) {
  case 0:
    IntrinsicID = Intrinsic::tpc_s_read_lfsr;
    break;
  case TPCII::SW_READ_ONLY:
    IntrinsicID = Intrinsic::tpc_s_read_lfsrnc;
    break;
  default:
    report_fatal_error("Unhandled READ_LFSR switch of intrinsic");
  }
  
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  
  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);
  
  Function* Callee = CGF->CGM.getIntrinsic(IntrinsicID);
  return CGF->Builder.CreateCall(Callee, Args);
}

static Value *emit_READ_LANE_ID(CodeGenFunction *CGF, unsigned BuiltinID,
                                const CallExpr *E, ReturnValueSlot ReturnValue,
                                llvm::Triple::ArchType Arch) {
  const unsigned IncomeOpNum = 0;
  const unsigned PredicateOpNum = 1;
  const unsigned PolarityOpNum = 2;
  
  // Result type.
  unsigned Multiplicity;
  llvm::Type *ResultTy = getIRType(CGF, E->getType(), Multiplicity);
  assert(Multiplicity == 0);
  
  Value *Predicate = emitPredicate(CGF, E->getArg(PredicateOpNum));
  Value *Polarity = CGF->EvaluateExprAsBool(E->getArg(PolarityOpNum));
  
  Value *Income;
  if (isUnconditional(Predicate, Polarity)) {
    Income = UndefValue::get(ResultTy);
  } else {
    Income = emitOperand(CGF, E->getArg(IncomeOpNum));
  }
  
  // Operands.
  SmallVector<llvm::Value *, 8> Args;
  Args.push_back(Income);
  Args.push_back(Predicate);
  Args.push_back(Polarity);
  
  Function* Callee = CGF->CGM.getIntrinsic(Intrinsic::tpc_read_lane_id,
                                           {ResultTy, Predicate->getType()});
  return CGF->Builder.CreateCall(Callee, Args);
}


// ----- Printf Tensor support
#define PRINTF_START_MARKER 0xcdcdcdcd
#define PRINTF_END_MARKER   0xffffffff

static llvm::Value *PrintIndexMetadata;

static void setTPCPrintfIndex(CodeGenFunction *cgf) {
  static StringRef TPCPrintfIndexName;
  if (TPCPrintfIndexName.empty()) {
    ASTContext &C = cgf->getContext();
    IdentifierInfo &CII = C.Idents.get("__PrintfTensorIndex");
    DeclContext::lookup_result res = C.getTranslationUnitDecl()->lookup(&CII);
    assert(res.size() == 1);
    VarDecl *VD = cast<VarDecl>(res.front());
    StorageClass SC = VD->getStorageClass();
    if (SC == StorageClass::SC_Register && VD->hasAttr<AsmLabelAttr>()) {
      AsmLabelAttr *Asm = VD->getAttr<AsmLabelAttr>();
      TPCPrintfIndexName = Asm->getLabel();
      LLVMContext &Context = cgf->CGM.getLLVMContext();
      llvm::Metadata *Ops[] = {llvm::MDString::get(Context, TPCPrintfIndexName)};
      llvm::MDNode *RegName = llvm::MDNode::get(Context, Ops);
      PrintIndexMetadata = llvm::MetadataAsValue::get(Context, RegName);
      /* initialization can't be in the 1st printf location,
      * as 1st printf can be in any construct loop, if ...
      * look PrintFindex init in TPCREgisterInfo.cpp
      // to zero all dimensions
      auto &Builder = cgf->Builder;
      llvm::Type *Int5Ty = llvm::FixedVectorType::get(cgf->Int32Ty, 5);
      llvm::Type *Types[] = {Int5Ty};
      llvm::Function *F =
          cgf->CGM.getIntrinsic(llvm::Intrinsic::read_register, Types);
      llvm::Value *Call = Builder.CreateCall(F, PrintIndexMetadata);

      llvm::Type *BitTy = llvm::IntegerType::get(cgf->getLLVMContext(), 1);
      Function *SetIndx = cgf->CGM.getIntrinsic(Intrinsic::tpc_set_indx);
      Value *Mask = llvm::ConstantInt::get(cgf->Int32Ty, 0x1f);
      Value *Val = llvm::ConstantInt::get(cgf->Int32Ty, 0);
      Value *Switches = llvm::ConstantInt::get(cgf->Int32Ty, 0);
      Value *Pred = llvm::ConstantInt::get(BitTy, 1);
      Value *Polarity = llvm::ConstantInt::get(BitTy, 0);
      llvm::Value *siArgs[6] = {Call, Mask, Val, Switches, Pred, Polarity};
      Value *Init = Builder.CreateCall(SetIndx, siArgs);
      llvm::Function *Fw =
          cgf->CGM.getIntrinsic(llvm::Intrinsic::write_register, Types);
      Builder.CreateCall(Fw, {PrintIndexMetadata, Init});
*/
    } else {
      assert(0);
    }
  }
}

static Value *getint5Printfindex(CodeGenFunction* cgf) {
  setTPCPrintfIndex(cgf);
  auto &Builder = cgf->Builder;
  llvm::Type *Int5Ty = llvm::FixedVectorType::get(cgf->Int32Ty, 5);
  llvm::Type *Types[] = {Int5Ty};
  llvm::Function *F = cgf->CGM.getIntrinsic(llvm::Intrinsic::read_register, Types);
  llvm::Value *Call = Builder.CreateCall(F, PrintIndexMetadata);
  return Call;
}

static void set_zero_printf_dim(Value* val_for_zer_dim,CodeGenFunction* cgf) {
  auto &Builder = cgf->Builder;
  Constant *Zero = ConstantInt::get(cgf->SizeTy, 0);
  Value *int5coo = getint5Printfindex(cgf);
  Value *Insert = Builder.CreateInsertElement(int5coo, val_for_zer_dim, Zero/*dim*/);

  llvm::Type *Int5Ty = llvm::FixedVectorType::get(cgf->Int32Ty, 5);
  llvm::Type *Types[] = {Int5Ty};
  llvm::Function *F = cgf->CGM.getIntrinsic(llvm::Intrinsic::write_register, Types);
  llvm::Value *ArgValue = Insert;
  Builder.CreateCall(F, {PrintIndexMetadata, ArgValue});
}

static void AddPrintf1stdim(int numbr, CodeGenFunction* cgf) {
  auto &Builder = cgf->Builder;
  Value *int5coo = getint5Printfindex(cgf);
  Constant *one = ConstantInt::get(cgf->SizeTy, 1); // now 1st dimension is growing
  Value *content1 = Builder.CreateExtractElement(int5coo, one); // extract 1-dim in int5 vector
  Value *content1_plus_1 = Builder.CreateNSWAdd(content1, ConstantInt::get(cgf->IntTy, numbr));// + numbrt
  Value *Insert = Builder.CreateInsertElement(int5coo, content1_plus_1, one);          // put in 1-dim +numbr

  llvm::Type *Int5Ty = llvm::FixedVectorType::get(cgf->Int32Ty, 5);
  llvm::Type *Types[] = {Int5Ty};
  llvm::Function *F =
      cgf->CGM.getIntrinsic(llvm::Intrinsic::write_register, Types);
  llvm::Value *ArgValue = Insert;
  Builder.CreateCall(F, {PrintIndexMetadata, ArgValue});
}

static void shiftPrintf1stdim(CodeGenFunction* cgf) {
  AddPrintf1stdim(1, cgf);
}

// 1111111 & bool256 vecto(mask) => char vector with 1 when was true 
static Value *ConvertIfBool(Value *Vecto, CodeGenFunction *cgf) {
  auto *VectTy = llvm::FixedVectorType::get(cgf->Int8Ty, 256);
  auto *BitTy = llvm::IntegerType::get(cgf->getLLVMContext(), 1);
  auto *VPredTy = llvm::FixedVectorType::get(BitTy, 256);
  auto &Builder = cgf->Builder;
  Function *charBroadcast =
      cgf->CGM.getIntrinsic(Intrinsic::tpc_mov, {VectTy, cgf->Int8Ty, BitTy});
  llvm::Type *vector_type = Vecto->getType();
  llvm::Type *element_type =
      cast<llvm::VectorType>(vector_type)->getElementType();
  int bitsize = element_type->getPrimitiveSizeInBits();
  if (bitsize == 1) {
    Value *Ones = Builder.CreateCall(
        charBroadcast,
        {ConstantInt::get(cgf->Int8Ty, 1),
         llvm::ConstantInt::get(cgf->Int8Ty, TPCII::OpType::INT8),
         llvm::ConstantInt::get(cgf->Int32Ty, 0), llvm::UndefValue::get(VectTy),
         Builder.getTrue(), Builder.getFalse()});
    Value *Zeros = Builder.CreateCall(
        charBroadcast,
        {ConstantInt::get(cgf->Int8Ty, 0),
         llvm::ConstantInt::get(cgf->Int8Ty, TPCII::OpType::INT8),
         llvm::ConstantInt::get(cgf->Int32Ty, 0), llvm::UndefValue::get(VectTy),
         Builder.getTrue(), Builder.getFalse()});
    llvm::Value *mvArgs[6] = {
        Ones,
        Zeros,
        llvm::ConstantInt::get(cgf->Int8Ty, TPCII::OpType::INT8),
        llvm::ConstantInt::get(cgf->Int32Ty, 0),
        Vecto,
        Builder.getFalse()};
    Function *movIntr = cgf->CGM.getIntrinsic(Intrinsic::tpc_mov,
                                              {VectTy, cgf->Int8Ty, VPredTy});
    Vecto = Builder.CreateCall(movIntr, mvArgs);
  }
  return Vecto;
}

static void printf_vector_element(Value*Vecto, Value*pos, CodeGenFunction* cgf)
{
  auto &Builder = cgf->Builder;
  Vecto = ConvertIfBool(Vecto, cgf);
  llvm::Type  *vector_type = Vecto->getType();
  llvm::Type *element_type = cast<llvm::VectorType>(vector_type)->getElementType();
  int bitsize = element_type->getPrimitiveSizeInBits();
  int NumWords = 32 / bitsize;
  int NShift;
  if (NumWords == 4) { NShift = 2; }
  else if (NumWords == 2) { NShift = 1; }
  else { NShift = 0; }
  Value* Vshift = pos;
  llvm::Type *BitTy = llvm::IntegerType::get(cgf->getLLVMContext(), 1);
  Value *Pred = llvm::ConstantInt::get(BitTy, 1);
  Value *Polarity = llvm::ConstantInt::get(BitTy, 0);

  // if type is short need to transform vector into int64t and to shift if needed
  if (bitsize < 32) {
    Vecto = Builder.CreateBitCast(Vecto, llvm::FixedVectorType::get(cgf->Int32Ty, 64));
    //int rightshift = ((nel * bitsize) % 32);
    Value* vproduct = Builder.CreateMul(pos, ConstantInt::get(cgf->IntTy, bitsize));
    Value* Valshift = Builder.CreateAnd(vproduct, ConstantInt::get(cgf->IntTy, 037)); // 11111
    ConstantInt *CI= dyn_cast<ConstantInt>(Valshift);
    APInt apik;
    bool shr_zero = false;
    if (CI) {
      apik = CI->getUniqueInteger();
      if (apik == 0) shr_zero = true;
    }
    if (!shr_zero) {
      Valshift = Builder.CreateVectorSplat(64, Valshift);
      Vecto = Builder.CreateLShr(Vecto, Valshift);
    }
    // and now AND with mask
    unsigned mask = 0;
    if (bitsize == 8) {
      mask = 0xff;
    }
    else if (bitsize == 16) {
      mask = 0xffff;
    }
    else {
      llvm_unreachable("Wrong bitsize. It might be 8 or 16 bits");
    }
    Value* valmask = ConstantInt::get(cgf->IntTy, mask);
    valmask = Builder.CreateVectorSplat(64, valmask);
    Vecto = Builder.CreateAnd(Vecto, valmask);
    // Vecto = Vecto >> n | xxxx;
    vector_type = Vecto->getType();
  }

  if (NShift > 0) { // Need to correct Vector Shift by dividing nel
                    // optimizing by shift
    Vshift = Builder.CreateAShr(Vshift, llvm::ConstantInt::get(cgf->IntTy, NShift));
  }
  // Vshift - value  zero printf dimension
  Value *Minushift = Builder.CreateNeg(Vshift);
  set_zero_printf_dim(Minushift, cgf);

  const unsigned MaxTensor = cgf->CGM.getCodeGenOpts().MaxTensor;
  if (NumArgumentTensors == MaxTensor  - 1)
    report_fatal_error("Number of used tensors exceeds architecture limit. "
                       "Note that printf feature requires extra (hidden) "
                       "tensor for storing output.");
  Value *Tensor = llvm::ConstantInt::get(cgf->Int8Ty, NumArgumentTensors);
  Value *printf_index = getint5Printfindex(cgf);
  // Now writing vector to PrintfTensor
  llvm::Value *stArgs[6] = { printf_index, Tensor, Vecto, llvm::ConstantInt::get(cgf->Int32Ty, 0), Pred, Polarity };
  llvm::Function *stIntrin = cgf->CGM.getIntrinsic(Intrinsic::tpc_st_tnsr, { vector_type });
  (void)Builder.CreateCall(stIntrin, stArgs);
}

// put scalar value in current position of tensor 
// and shift tensor index in 1st dimension
static void StoreValue(Value* st, CodeGenFunction *cgf) {
  // need to transform scalar to vector
  auto &Builder = cgf->Builder;
  llvm::Type* type_st = st->getType();
  int bitsize = type_st->getPrimitiveSizeInBits();
  Value* broad;
  switch (bitsize) {
  case 32: broad = Builder.CreateVectorSplat(64, st, "printfsplat"); break;
  case 16: broad = Builder.CreateVectorSplat(128, st, "printfsplat"); break;
  case 1:
  case 8: broad = Builder.CreateVectorSplat(256, st, "printfsplat"); break;
  default:
    llvm_unreachable("Invalid printf type for scalar");
  }

  printf_vector_element(broad/*vector*/, llvm::ConstantInt::get(cgf->Int32Ty, 0)/*position*/, cgf);
}

static void StoreElement(unsigned int S, CodeGenFunction *cgf) {
  Value *St = llvm::ConstantInt::get(cgf->Int32Ty, S);
  StoreValue(St, cgf);
  if (S != PRINTF_END_MARKER) {
    shiftPrintf1stdim(cgf); // write and shift printf_index
  }
}

static void StoreString(StringRef Str, CodeGenFunction *cgf) {
  int LenStr = Str.size();
  int NumElt = LenStr / 4;
  const int *buf = (const int*)Str.data();
  for (int k = 0; k < NumElt; ++k) {
    StoreElement(*(buf++), cgf);
  }
  const char *ch = Str.data();
  unsigned int S = '\0';
  if (LenStr % 4) {
    int I = LenStr % 4;  // 1,2,3
    for (int k = 1; k <= I; ++k) {
      S = S << 8;
      S = S | ch[LenStr - k];
    }
    StoreElement(S, cgf);
  }
  else if (ch[LenStr - 1] != '\0') {
    StoreElement(S, cgf);
  }
}


Value *CodeGenFunction::EmitTPCBuiltinExpr(unsigned BuiltinID, const CallExpr *E,
                                           ReturnValueSlot ReturnValue,
                                           llvm::Triple::ArchType Arch) {
  switch (BuiltinID) {
  case TPC::BIto_bool128:
  case TPC::BIto_bool64:
    return emitPredicate(this, E->getArg(0));
  case TPC::BIfrom_bool128:
  case TPC::BIfrom_bool64:
    return emitPredicate(this, E->getArg(0));

  case TPC::BIrequire_cpu_goya:
  case TPC::BIrequire_cpu_gaudi:
  case TPC::BIrequire_cpu_gaudib:
  case TPC::BIrequire_cpu_greco:
  case TPC::BIrequire_cpu_gaudi2:
  case TPC::BIrequire_cpu_doron1:
    return UndefValue::get(Builder.getVoidTy());

  case TPC::BIget_index_space_offset:
    return Builder.CreateCall(CGM.getIntrinsic(Intrinsic::tpc_get_index_space_offset), {});
  case TPC::BIget_index_space_size:
    return Builder.CreateCall(CGM.getIntrinsic(Intrinsic::tpc_get_index_space_size), {});
  case TPC::BIprintf_st: {
    UsePrintf = true;
    auto *X0 = E->getArg(0)->IgnoreParenImpCasts();
    StringRef Str = cast<clang::StringLiteral>(X0)->getString();
    StoreElement(PRINTF_START_MARKER, this);
    StoreElement(0, this); // according to spec, must be some value
    StoreString(Str, this);
    StoreElement(PRINTF_END_MARKER, this);
    return Builder.getTrue();
  }
  case TPC::BIprintf_i:
  case TPC::BIprintf_ui:
  case TPC::BIprintf_f:
  case TPC::BIprintf_f8:
  case TPC::BIprintf_h8:
  case TPC::BIprintf_h:
  case TPC::BIprintf_bf:
  case TPC::BIprintf_s:
  case TPC::BIprintf_us:
  case TPC::BIprintf_c:
  case TPC::BIprintf_uc: 
  {
    // ASTContext &Context = getContext();
    UsePrintf = true;
    const Expr *X0 = E->getArg(0)->IgnoreParenImpCasts();
    const Expr *Arg1Exp = E->getArg(1)->IgnoreParenImpCasts();
    Value *X1;
    StoreElement(PRINTF_START_MARKER, this);
    StringRef Str = cast<clang::StringLiteral>(X0)->getString();
    if (isa<ArraySubscriptExpr>(Arg1Exp)) { // printf of subscript .. a[5]
      const ArraySubscriptExpr *Esubs = cast<ArraySubscriptExpr>(Arg1Exp);
      const Expr *expindex = Esubs->getRHS();
      const Expr* ebase = Esubs->getBase();
      // cooking something from expindex
      auto ebt = ebase->getType();
      assert(ebt->isVectorType() &&
        !isa<ExtVectorElementExpr>(ebase));
      unsigned Multiplicity;
      llvm::Type *ResultTy = getIRType(this, ebt, Multiplicity);
      assert(Multiplicity == 0);
      const bool IRFOp = cast<FixedVectorType>(ResultTy)->getNumElements() == 5;
      if (IRFOp)
        goto MScalar;
      Value *Vecto = EmitScalarExpr(ebase);
      Value* Vnel = EmitScalarExpr(expindex);
      printf_vector_element(Vecto/*vector*/, Vnel/*position*/, this);
      //return  Builder.getTrue();
      shiftPrintf1stdim(this); // write and shift printf_index
    }
    else {  // printf of terminal expression ( var, number)
      MScalar:
      X1 = EmitScalarExpr(Arg1Exp);
      StoreValue(X1, this);
      shiftPrintf1stdim(this); // write and shift printf_index
    }
    StoreString(Str, this);
    StoreElement(PRINTF_END_MARKER, this);
    return Builder.getTrue();
  }

    // Autogenerated implementation.
  default:
    return emitAutogeneratedIntrinsic(this, BuiltinID, E, ReturnValue, Arch);
  }
}


// This function will be generated by script. But now it is generated manually
// and it must follow existing code patten.
//
static Value *emitAutogeneratedIntrinsic(CodeGenFunction *CGF, unsigned BuiltinID,
                                         const CallExpr *E, ReturnValueSlot ReturnValue,
                                         llvm::Triple::ArchType Arch) {
  switch (BuiltinID) {
  default:
    return nullptr;

  //------ Load slot ---------------------------------------------------------

  case TPC::BIgen_addr:
    return emit_GEN_ADDR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIprmt_indx:
    return emit_PRMT_INDX(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIset_indx:
    return emit_SET_INDX(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_ld_l:
  case TPC::BIs_bf16_ld_l:
  case TPC::BIs_f16_ld_l:
  case TPC::BIs_i32_ld_l:
  case TPC::BIs_u32_ld_l:
  case TPC::BIs_i16_ld_l:
  case TPC::BIs_u16_ld_l:
  case TPC::BIs_i8_ld_l:
  case TPC::BIs_u8_ld_l:
  case TPC::BIs_i1_ld_l:
  case TPC::BIs_f8_ld_l:
  case TPC::BIs_h8_ld_l:
    return emit_LD_L(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_ld_g:
  case TPC::BIs_bf16_ld_g:
  case TPC::BIs_f16_ld_g:
  case TPC::BIs_i32_ld_g:
  case TPC::BIs_u32_ld_g:
  case TPC::BIs_i32_x2_ld_g:
  case TPC::BIs_u32_x2_ld_g:
  case TPC::BIs_i16_ld_g:
  case TPC::BIs_u16_ld_g:
  case TPC::BIi_i32_ld_g:
    return emit_LD_G(CGF, BuiltinID, E, ReturnValue, Arch, true);
  case TPC::BIs_i8_ld_g:
  case TPC::BIs_u8_ld_g:
  case TPC::BIs_f8_ld_g:
  case TPC::BIs_h8_ld_g:
  case TPC::BIs_i1_ld_g:
  case TPC::BIv_f32_ld_g:
  case TPC::BIv_bf16_ld_g:
  case TPC::BIv_f16_ld_g:
  case TPC::BIv_f8_ld_g:
  case TPC::BIv_h8_ld_g:
  case TPC::BIv_i32_ld_g:
  case TPC::BIv_u32_ld_g:
  case TPC::BIv_i16_ld_g:
  case TPC::BIv_u16_ld_g:
  case TPC::BIv_i8_ld_g:
  case TPC::BIv_u8_ld_g:
  case TPC::BIv_f8_ld_g_vb:
  case TPC::BIv_h8_ld_g_vb:
  case TPC::BIv_f32_ld_g_vb:
  case TPC::BIv_i32_ld_g_vb:
  case TPC::BIv_u32_ld_g_vb:
  case TPC::BIv_i16_ld_g_vb:
  case TPC::BIv_u16_ld_g_vb:
  case TPC::BIv_i8_ld_g_vb:
  case TPC::BIv_u8_ld_g_vb:
  case TPC::BIv_i1_ld_g_vb:
    return emit_LD_G(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_ld_g_partial_b:
  case TPC::BIv_f16_ld_g_partial_b:
  case TPC::BIv_bf16_ld_g_partial_b:
  case TPC::BIv_i32_ld_g_partial_b:
  case TPC::BIv_u32_ld_g_partial_b:
  case TPC::BIv_i16_ld_g_partial_b:
  case TPC::BIv_u16_ld_g_partial_b:
  case TPC::BIv_i8_ld_g_partial_b:
  case TPC::BIv_u8_ld_g_partial_b:

  case TPC::BIv_f32_ld_g_partial_vb:
  case TPC::BIv_f16_ld_g_partial_vb:
  case TPC::BIv_bf16_ld_g_partial_vb:
  case TPC::BIv_f8_ld_g_partial_vb:
  case TPC::BIv_h8_ld_g_partial_vb:
  case TPC::BIv_i32_ld_g_partial_vb:
  case TPC::BIv_u32_ld_g_partial_vb:
  case TPC::BIv_i16_ld_g_partial_vb:
  case TPC::BIv_u16_ld_g_partial_vb:
  case TPC::BIv_i8_ld_g_partial_vb:
  case TPC::BIv_u8_ld_g_partial_vb:
    return emit_LD_G_P(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_ld_g_inc_partial_b:
  case TPC::BIv_f16_ld_g_inc_partial_b:
  case TPC::BIv_bf16_ld_g_inc_partial_b:
  case TPC::BIv_i32_ld_g_inc_partial_b:
  case TPC::BIv_u32_ld_g_inc_partial_b:
  case TPC::BIv_i16_ld_g_inc_partial_b:
  case TPC::BIv_u16_ld_g_inc_partial_b:
  case TPC::BIv_i8_ld_g_inc_partial_b:
  case TPC::BIv_u8_ld_g_inc_partial_b:
  case TPC::BIv_f32_ld_g_inc_partial_vb:
  case TPC::BIv_f16_ld_g_inc_partial_vb:
  case TPC::BIv_bf16_ld_g_inc_partial_vb:
  case TPC::BIv_f8_ld_g_inc_partial_vb:
  case TPC::BIv_h8_ld_g_inc_partial_vb:
  case TPC::BIv_i32_ld_g_inc_partial_vb:
  case TPC::BIv_u32_ld_g_inc_partial_vb:
  case TPC::BIv_i16_ld_g_inc_partial_vb:
  case TPC::BIv_u16_ld_g_inc_partial_vb:
  case TPC::BIv_i8_ld_g_inc_partial_vb:
  case TPC::BIv_u8_ld_g_inc_partial_vb:
    return emit_LD_G_P_INC(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_ld_g_inc:
  case TPC::BIs_bf16_ld_g_inc:
  case TPC::BIs_f16_ld_g_inc:
  case TPC::BIs_f8_ld_g_inc:
  case TPC::BIs_h8_ld_g_inc:
  case TPC::BIs_i32_ld_g_inc:
  case TPC::BIs_u32_ld_g_inc:
  case TPC::BIs_i32_x2_ld_g_inc:
  case TPC::BIs_u32_x2_ld_g_inc:
  case TPC::BIs_i16_ld_g_inc:
  case TPC::BIs_u16_ld_g_inc:
  case TPC::BIs_i8_ld_g_inc:
  case TPC::BIs_u8_ld_g_inc:
  case TPC::BIs_i1_ld_g_inc:
  case TPC::BIi_i32_ld_g_inc:
    return emit_LD_G_INC(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_lookup:
  case TPC::BIv_bf16_lookup:
  case TPC::BIv_f16_lookup:
  case TPC::BIv_i32_lookup:
  case TPC::BIv_u32_lookup:
  case TPC::BIv_i16_lookup:
  case TPC::BIv_u16_lookup:
  case TPC::BIv_i8_lookup:
  case TPC::BIv_f32_lookup_c0:
  case TPC::BIv_i32_lookup_c0:
  case TPC::BIv_u32_lookup_c0:
  case TPC::BIv_i16_lookup_c0:
  case TPC::BIv_u16_lookup_c0:
  case TPC::BIv_i8_lookup_c0:
  case TPC::BIv_f32_lookup_c1c2:
  case TPC::BIv_i16_lookup_c1c2:
  case TPC::BIv_u16_lookup_c1c2:
  case TPC::BIv_i8_lookup_c1c2:
  case TPC::BIv_f32_lookup_1c:
  case TPC::BIv_i32_lookup_1c:
  case TPC::BIv_u32_lookup_1c:
  case TPC::BIv_i16_lookup_1c:
  case TPC::BIv_u16_lookup_1c:
  case TPC::BIv_bf16_lookup_1c:
  case TPC::BIv_f16_lookup_1c:
  case TPC::BIv_f32_lookup_2c:
  case TPC::BIv_i32_lookup_2c:
  case TPC::BIv_u32_lookup_2c:
  case TPC::BIv_i16_lookup_2c:
  case TPC::BIv_u16_lookup_2c:
  case TPC::BIv_bf16_lookup_2c:
  case TPC::BIv_f16_lookup_2c:
    return emit_LOOKUP(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_i8_msac_b:
  case TPC::BIv_i8_msac_vb:
  case TPC::BIv_u8_msac_b:
  case TPC::BIv_u8_msac_vb:
  case TPC::BIv_i16_msac_b:
  case TPC::BIv_i16_msac_vb:
  case TPC::BIv_u16_msac_b:
  case TPC::BIv_u16_msac_vb:
    return emit_MSAC(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIprefetch:
    return emit_PREFETCH(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_ld_l_v_vb:
  case TPC::BIv_bf16_ld_l_v_vb:
  case TPC::BIv_f16_ld_l_v_vb:
  case TPC::BIv_i32_ld_l_v_vb:
  case TPC::BIv_u32_ld_l_v_vb:
  case TPC::BIv_i16_ld_l_v_vb:
  case TPC::BIv_u16_ld_l_v_vb:
  case TPC::BIv_i8_ld_l_v_vb:
  case TPC::BIv_u8_ld_l_v_vb:
  case TPC::BIv_i1_ld_l_v_vb:
  case TPC::BIv_f8_ld_l_v_vb:
  case TPC::BIv_h8_ld_l_v_vb:
  case TPC::BIv_f32_ld_l_v_b:
  case TPC::BIv_bf16_ld_l_v_b:
  case TPC::BIv_f16_ld_l_v_b:
  case TPC::BIv_i32_ld_l_v_b:
  case TPC::BIv_u32_ld_l_v_b:
  case TPC::BIv_i16_ld_l_v_b:
  case TPC::BIv_u16_ld_l_v_b:
  case TPC::BIv_i8_ld_l_v_b:
  case TPC::BIv_u8_ld_l_v_b:
  case TPC::BIv_i1_ld_l_v_b:
  case TPC::BIv_f8_ld_l_v_b:
  case TPC::BIv_h8_ld_l_v_b:
    return emit_LD_L_V(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_ld_l_v_low_vb:
  case TPC::BIv_bf16_ld_l_v_low_vb:
  case TPC::BIv_f16_ld_l_v_low_vb:
  case TPC::BIv_i32_ld_l_v_low_vb:
  case TPC::BIv_u32_ld_l_v_low_vb:
  case TPC::BIv_i16_ld_l_v_low_vb:
  case TPC::BIv_u16_ld_l_v_low_vb:
  case TPC::BIv_i8_ld_l_v_low_vb:
  case TPC::BIv_u8_ld_l_v_low_vb:
  case TPC::BIv_i1_ld_l_v_low_vb:
  case TPC::BIv_f8_ld_l_v_low_vb:
  case TPC::BIv_h8_ld_l_v_low_vb:
  case TPC::BIv_f32_ld_l_v_low_b:
  case TPC::BIv_bf16_ld_l_v_low_b:
  case TPC::BIv_f16_ld_l_v_low_b:
  case TPC::BIv_i32_ld_l_v_low_b:
  case TPC::BIv_u32_ld_l_v_low_b:
  case TPC::BIv_i16_ld_l_v_low_b:
  case TPC::BIv_u16_ld_l_v_low_b:
  case TPC::BIv_i8_ld_l_v_low_b:
  case TPC::BIv_u8_ld_l_v_low_b:
  case TPC::BIv_i1_ld_l_v_low_b:
  case TPC::BIv_f8_ld_l_v_low_b:
  case TPC::BIv_h8_ld_l_v_low_b:
    return emit_LD_L_V_LOW(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_ld_l_v_high_vb:
  case TPC::BIv_bf16_ld_l_v_high_vb:
  case TPC::BIv_f16_ld_l_v_high_vb:
  case TPC::BIv_i32_ld_l_v_high_vb:
  case TPC::BIv_u32_ld_l_v_high_vb:
  case TPC::BIv_i16_ld_l_v_high_vb:
  case TPC::BIv_u16_ld_l_v_high_vb:
  case TPC::BIv_i8_ld_l_v_high_vb:
  case TPC::BIv_u8_ld_l_v_high_vb:
  case TPC::BIv_i1_ld_l_v_high_vb:
  case TPC::BIv_f8_ld_l_v_high_vb:
  case TPC::BIv_h8_ld_l_v_high_vb:
  case TPC::BIv_f32_ld_l_v_high_b:
  case TPC::BIv_bf16_ld_l_v_high_b:
  case TPC::BIv_f16_ld_l_v_high_b:
  case TPC::BIv_i32_ld_l_v_high_b:
  case TPC::BIv_u32_ld_l_v_high_b:
  case TPC::BIv_i16_ld_l_v_high_b:
  case TPC::BIv_u16_ld_l_v_high_b:
  case TPC::BIv_i8_ld_l_v_high_b:
  case TPC::BIv_u8_ld_l_v_high_b:
  case TPC::BIv_i1_ld_l_v_high_b:
  case TPC::BIv_f8_ld_l_v_high_b:
  case TPC::BIv_h8_ld_l_v_high_b:
    return emit_LD_L_V_HIGH(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_ld_tnsr_b:
  case TPC::BIv_bf16_ld_tnsr_b:
  case TPC::BIv_f16_ld_tnsr_b:
  case TPC::BIv_f8_ld_tnsr_b:
  case TPC::BIv_h8_ld_tnsr_b:
  case TPC::BIv_i32_ld_tnsr_b:
  case TPC::BIv_u32_ld_tnsr_b:
  case TPC::BIv_i16_ld_tnsr_b:
  case TPC::BIv_u16_ld_tnsr_b:
  case TPC::BIv_i8_ld_tnsr_b:
  case TPC::BIv_u8_ld_tnsr_b:
  case TPC::BIv_i1_ld_tnsr_b:
  case TPC::BIv_f32_ld_tnsr_vb:
  case TPC::BIv_bf16_ld_tnsr_vb:
  case TPC::BIv_f16_ld_tnsr_vb:
  case TPC::BIv_f8_ld_tnsr_vb:
  case TPC::BIv_h8_ld_tnsr_vb:
  case TPC::BIv_i32_ld_tnsr_vb:
  case TPC::BIv_u32_ld_tnsr_vb:
  case TPC::BIv_i16_ld_tnsr_vb:
  case TPC::BIv_u16_ld_tnsr_vb:
  case TPC::BIv_i8_ld_tnsr_vb:
  case TPC::BIv_u8_ld_tnsr_vb:
  case TPC::BIv_i1_ld_tnsr_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                        Intrinsic::tpc_ld_tnsr, false);
    
  case TPC::BIv_f32_ld_tnsr_partial_b:
  case TPC::BIv_bf16_ld_tnsr_partial_b:
  case TPC::BIv_f16_ld_tnsr_partial_b:
  case TPC::BIv_f8_ld_tnsr_partial_b:
  case TPC::BIv_h8_ld_tnsr_partial_b:
  case TPC::BIv_i32_ld_tnsr_partial_b:
  case TPC::BIv_u32_ld_tnsr_partial_b:
  case TPC::BIv_i16_ld_tnsr_partial_b:
  case TPC::BIv_u16_ld_tnsr_partial_b:
  case TPC::BIv_i8_ld_tnsr_partial_b:
  case TPC::BIv_u8_ld_tnsr_partial_b:
  case TPC::BIv_i1_ld_tnsr_partial_b:
  case TPC::BIv_f32_ld_tnsr_partial_vb:
  case TPC::BIv_bf16_ld_tnsr_partial_vb:
  case TPC::BIv_f16_ld_tnsr_partial_vb:
  case TPC::BIv_f8_ld_tnsr_partial_vb:
  case TPC::BIv_h8_ld_tnsr_partial_vb:
  case TPC::BIv_i32_ld_tnsr_partial_vb:
  case TPC::BIv_u32_ld_tnsr_partial_vb:
  case TPC::BIv_i16_ld_tnsr_partial_vb:
  case TPC::BIv_u16_ld_tnsr_partial_vb:
  case TPC::BIv_i8_ld_tnsr_partial_vb:
  case TPC::BIv_u8_ld_tnsr_partial_vb:
  case TPC::BIv_i1_ld_tnsr_partial_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                        Intrinsic::tpc_ld_tnsr_partial, true);

  case TPC::BIv_f32_ld_tnsr_low_b:
  case TPC::BIv_bf16_ld_tnsr_low_b:
  case TPC::BIv_f16_ld_tnsr_low_b:
  case TPC::BIv_f8_ld_tnsr_low_b:
  case TPC::BIv_h8_ld_tnsr_low_b:
  case TPC::BIv_i32_ld_tnsr_low_b:
  case TPC::BIv_u32_ld_tnsr_low_b:
  case TPC::BIv_i16_ld_tnsr_low_b:
  case TPC::BIv_u16_ld_tnsr_low_b:
  case TPC::BIv_i8_ld_tnsr_low_b:
  case TPC::BIv_u8_ld_tnsr_low_b:
  case TPC::BIv_i1_ld_tnsr_low_b:
  case TPC::BIv_f32_ld_tnsr_low_vb:
  case TPC::BIv_bf16_ld_tnsr_low_vb:
  case TPC::BIv_f16_ld_tnsr_low_vb:
  case TPC::BIv_f8_ld_tnsr_low_vb:
  case TPC::BIv_h8_ld_tnsr_low_vb:
  case TPC::BIv_i32_ld_tnsr_low_vb:
  case TPC::BIv_u32_ld_tnsr_low_vb:
  case TPC::BIv_i16_ld_tnsr_low_vb:
  case TPC::BIv_u16_ld_tnsr_low_vb:
  case TPC::BIv_i8_ld_tnsr_low_vb:
  case TPC::BIv_u8_ld_tnsr_low_vb:
  case TPC::BIv_i1_ld_tnsr_low_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                        Intrinsic::tpc_ld_tnsr_low, false);
    
  case TPC::BIv_f32_ld_tnsr_low_partial_b:
  case TPC::BIv_bf16_ld_tnsr_low_partial_b:
  case TPC::BIv_f16_ld_tnsr_low_partial_b:
  case TPC::BIv_f8_ld_tnsr_low_partial_b:
  case TPC::BIv_h8_ld_tnsr_low_partial_b:
  case TPC::BIv_i32_ld_tnsr_low_partial_b:
  case TPC::BIv_u32_ld_tnsr_low_partial_b:
  case TPC::BIv_i16_ld_tnsr_low_partial_b:
  case TPC::BIv_u16_ld_tnsr_low_partial_b:
  case TPC::BIv_i8_ld_tnsr_low_partial_b:
  case TPC::BIv_u8_ld_tnsr_low_partial_b:
  case TPC::BIv_i1_ld_tnsr_low_partial_b:
  case TPC::BIv_f32_ld_tnsr_low_partial_vb:
  case TPC::BIv_bf16_ld_tnsr_low_partial_vb:
  case TPC::BIv_f16_ld_tnsr_low_partial_vb:
  case TPC::BIv_f8_ld_tnsr_low_partial_vb:
  case TPC::BIv_h8_ld_tnsr_low_partial_vb:
  case TPC::BIv_i32_ld_tnsr_low_partial_vb:
  case TPC::BIv_u32_ld_tnsr_low_partial_vb:
  case TPC::BIv_i16_ld_tnsr_low_partial_vb:
  case TPC::BIv_u16_ld_tnsr_low_partial_vb:
  case TPC::BIv_i8_ld_tnsr_low_partial_vb:
  case TPC::BIv_u8_ld_tnsr_low_partial_vb:
  case TPC::BIv_i1_ld_tnsr_low_partial_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                        Intrinsic::tpc_ld_tnsr_low_partial, true);

  case TPC::BIv_f32_ld_tnsr_high_b:
  case TPC::BIv_bf16_ld_tnsr_high_b:
  case TPC::BIv_f16_ld_tnsr_high_b:
  case TPC::BIv_f8_ld_tnsr_high_b:
  case TPC::BIv_h8_ld_tnsr_high_b:
  case TPC::BIv_i32_ld_tnsr_high_b:
  case TPC::BIv_u32_ld_tnsr_high_b:
  case TPC::BIv_i16_ld_tnsr_high_b:
  case TPC::BIv_u16_ld_tnsr_high_b:
  case TPC::BIv_i8_ld_tnsr_high_b:
  case TPC::BIv_u8_ld_tnsr_high_b:
  case TPC::BIv_i1_ld_tnsr_high_b:
  case TPC::BIv_f32_ld_tnsr_high_vb:
  case TPC::BIv_bf16_ld_tnsr_high_vb:
  case TPC::BIv_f16_ld_tnsr_high_vb:
  case TPC::BIv_f8_ld_tnsr_high_vb:
  case TPC::BIv_h8_ld_tnsr_high_vb:
  case TPC::BIv_i32_ld_tnsr_high_vb:
  case TPC::BIv_u32_ld_tnsr_high_vb:
  case TPC::BIv_i16_ld_tnsr_high_vb:
  case TPC::BIv_u16_ld_tnsr_high_vb:
  case TPC::BIv_i8_ld_tnsr_high_vb:
  case TPC::BIv_u8_ld_tnsr_high_vb:
  case TPC::BIv_i1_ld_tnsr_high_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                        Intrinsic::tpc_ld_tnsr_high, false);
    
  case TPC::BIv_f32_ld_tnsr_high_partial_b:
  case TPC::BIv_bf16_ld_tnsr_high_partial_b:
  case TPC::BIv_f16_ld_tnsr_high_partial_b:
  case TPC::BIv_f8_ld_tnsr_high_partial_b:
  case TPC::BIv_h8_ld_tnsr_high_partial_b:
  case TPC::BIv_i32_ld_tnsr_high_partial_b:
  case TPC::BIv_u32_ld_tnsr_high_partial_b:
  case TPC::BIv_i16_ld_tnsr_high_partial_b:
  case TPC::BIv_u16_ld_tnsr_high_partial_b:
  case TPC::BIv_i8_ld_tnsr_high_partial_b:
  case TPC::BIv_u8_ld_tnsr_high_partial_b:
  case TPC::BIv_i1_ld_tnsr_high_partial_b:
  case TPC::BIv_f32_ld_tnsr_high_partial_vb:
  case TPC::BIv_bf16_ld_tnsr_high_partial_vb:
  case TPC::BIv_f16_ld_tnsr_high_partial_vb:
  case TPC::BIv_f8_ld_tnsr_high_partial_vb:
  case TPC::BIv_h8_ld_tnsr_high_partial_vb:
  case TPC::BIv_i32_ld_tnsr_high_partial_vb:
  case TPC::BIv_u32_ld_tnsr_high_partial_vb:
  case TPC::BIv_i16_ld_tnsr_high_partial_vb:
  case TPC::BIv_u16_ld_tnsr_high_partial_vb:
  case TPC::BIv_i8_ld_tnsr_high_partial_vb:
  case TPC::BIv_u8_ld_tnsr_high_partial_vb:
  case TPC::BIv_i1_ld_tnsr_high_partial_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                        Intrinsic::tpc_ld_tnsr_high_partial, true);

  case TPC::BIv_bf16_ld_tnsr_cnvrt_b:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_BF16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt, false);
  case TPC::BIv_f16_ld_tnsr_cnvrt_b:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_FP16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt, false);
  case TPC::BIv_bf16_ld_tnsr_cnvrt_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_BF16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt, false);
  case TPC::BIv_f16_ld_tnsr_cnvrt_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_FP16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt, false);
    
  case TPC::BIv_bf16_ld_tnsr_cnvrt_partial_b:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_BF16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt_partial, true);
  case TPC::BIv_f16_ld_tnsr_cnvrt_partial_b:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_FP16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt_partial, true);
  case TPC::BIv_bf16_ld_tnsr_cnvrt_partial_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_BF16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt_partial, true);
  case TPC::BIv_f16_ld_tnsr_cnvrt_partial_vb:
    return emit_LD_TNSR(CGF, BuiltinID, E, ReturnValue, Arch,
                        TPCII::SW_FP32_TO_FP16, TPCII::SW_CNVRT_DT,
                        Intrinsic::tpc_ld_tnsr_cnvrt_partial, true);
      
  case TPC::BIv_f32_ld_tnsr_direct_b:  
  case TPC::BIv_i32_ld_tnsr_direct_b:  
  case TPC::BIv_u32_ld_tnsr_direct_b:  
  case TPC::BIv_i16_ld_tnsr_direct_b:  
  case TPC::BIv_u16_ld_tnsr_direct_b:  
  case TPC::BIv_i8_ld_tnsr_direct_b:   
  case TPC::BIv_u8_ld_tnsr_direct_b:   
  case TPC::BIv_i1_ld_tnsr_direct_b:   
  case TPC::BIv_f16_ld_tnsr_direct_b:  
  case TPC::BIv_f8_ld_tnsr_direct_b:  
  case TPC::BIv_h8_ld_tnsr_direct_b:  
  case TPC::BIv_f32_ld_tnsr_direct_vb: 
  case TPC::BIv_bf16_ld_tnsr_direct_vb:
  case TPC::BIv_f16_ld_tnsr_direct_vb: 
  case TPC::BIv_f8_ld_tnsr_direct_vb:
  case TPC::BIv_h8_ld_tnsr_direct_vb: 
  case TPC::BIv_i32_ld_tnsr_direct_vb: 
  case TPC::BIv_u32_ld_tnsr_direct_vb: 
  case TPC::BIv_i16_ld_tnsr_direct_vb: 
  case TPC::BIv_u16_ld_tnsr_direct_vb: 
  case TPC::BIv_i8_ld_tnsr_direct_vb:  
  case TPC::BIv_u8_ld_tnsr_direct_vb:  
  case TPC::BIv_i1_ld_tnsr_direct_vb:  
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                               Intrinsic::tpc_ld_tnsr_direct, false);

  case TPC::BIv_f32_ld_tnsr_high_direct_b:  
  case TPC::BIv_bf16_ld_tnsr_high_direct_b: 
  case TPC::BIv_f16_ld_tnsr_high_direct_b:  
  case TPC::BIv_f8_ld_tnsr_high_direct_b: 
  case TPC::BIv_h8_ld_tnsr_high_direct_b:  
  case TPC::BIv_i32_ld_tnsr_high_direct_b:  
  case TPC::BIv_u32_ld_tnsr_high_direct_b:  
  case TPC::BIv_i16_ld_tnsr_high_direct_b:  
  case TPC::BIv_u16_ld_tnsr_high_direct_b:  
  case TPC::BIv_i8_ld_tnsr_high_direct_b:   
  case TPC::BIv_u8_ld_tnsr_high_direct_b:   
  case TPC::BIv_i1_ld_tnsr_high_direct_b:   
  case TPC::BIv_f32_ld_tnsr_high_direct_vb: 
  case TPC::BIv_bf16_ld_tnsr_high_direct_vb:
  case TPC::BIv_f16_ld_tnsr_high_direct_vb: 
  case TPC::BIv_f8_ld_tnsr_high_direct_vb:
  case TPC::BIv_h8_ld_tnsr_high_direct_vb: 
  case TPC::BIv_i32_ld_tnsr_high_direct_vb: 
  case TPC::BIv_u32_ld_tnsr_high_direct_vb: 
  case TPC::BIv_i16_ld_tnsr_high_direct_vb: 
  case TPC::BIv_u16_ld_tnsr_high_direct_vb: 
  case TPC::BIv_i8_ld_tnsr_high_direct_vb:  
  case TPC::BIv_u8_ld_tnsr_high_direct_vb:  
  case TPC::BIv_i1_ld_tnsr_high_direct_vb:  
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                               Intrinsic::tpc_ld_tnsr_high_direct, false);

  case TPC::BIv_f32_ld_tnsr_low_direct_b:
  case TPC::BIv_bf16_ld_tnsr_low_direct_b:
  case TPC::BIv_f16_ld_tnsr_low_direct_b:
  case TPC::BIv_f8_ld_tnsr_low_direct_b:
  case TPC::BIv_h8_ld_tnsr_low_direct_b:
  case TPC::BIv_i32_ld_tnsr_low_direct_b:
  case TPC::BIv_u32_ld_tnsr_low_direct_b:
  case TPC::BIv_i16_ld_tnsr_low_direct_b:
  case TPC::BIv_u16_ld_tnsr_low_direct_b:
  case TPC::BIv_i8_ld_tnsr_low_direct_b:
  case TPC::BIv_u8_ld_tnsr_low_direct_b:
  case TPC::BIv_i1_ld_tnsr_low_direct_b:
  case TPC::BIv_f32_ld_tnsr_low_direct_vb:
  case TPC::BIv_bf16_ld_tnsr_low_direct_vb:
  case TPC::BIv_f16_ld_tnsr_low_direct_vb:
  case TPC::BIv_f8_ld_tnsr_low_direct_vb:
  case TPC::BIv_h8_ld_tnsr_low_direct_vb:
  case TPC::BIv_i32_ld_tnsr_low_direct_vb:
  case TPC::BIv_u32_ld_tnsr_low_direct_vb:
  case TPC::BIv_i16_ld_tnsr_low_direct_vb:
  case TPC::BIv_u16_ld_tnsr_low_direct_vb:
  case TPC::BIv_i8_ld_tnsr_low_direct_vb:
  case TPC::BIv_u8_ld_tnsr_low_direct_vb:
  case TPC::BIv_i1_ld_tnsr_low_direct_vb:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                               Intrinsic::tpc_ld_tnsr_low_direct, false);

  case TPC::BIv_bf16_ld_tnsr_cnvrt_direct_b:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_BF16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_direct, false);
  case TPC::BIv_f16_ld_tnsr_cnvrt_direct_b:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_FP16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_direct, false);
  case TPC::BIv_bf16_ld_tnsr_cnvrt_direct_vb:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_BF16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_direct, false);
  case TPC::BIv_f16_ld_tnsr_cnvrt_direct_vb:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_FP16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_direct, false);
    
  case TPC::BIv_f32_ld_tnsr_partial_direct_b:   
  case TPC::BIv_bf16_ld_tnsr_partial_direct_b:  
  case TPC::BIv_f16_ld_tnsr_partial_direct_b:   
  case TPC::BIv_f8_ld_tnsr_partial_direct_b:  
  case TPC::BIv_h8_ld_tnsr_partial_direct_b:   
  case TPC::BIv_i32_ld_tnsr_partial_direct_b:   
  case TPC::BIv_u32_ld_tnsr_partial_direct_b:   
  case TPC::BIv_i16_ld_tnsr_partial_direct_b:   
  case TPC::BIv_u16_ld_tnsr_partial_direct_b:   
  case TPC::BIv_i8_ld_tnsr_partial_direct_b:    
  case TPC::BIv_u8_ld_tnsr_partial_direct_b:    
  case TPC::BIv_i1_ld_tnsr_partial_direct_b:    
  case TPC::BIv_f32_ld_tnsr_partial_direct_vb:  
  case TPC::BIv_bf16_ld_tnsr_partial_direct_vb: 
  case TPC::BIv_f16_ld_tnsr_partial_direct_vb:
  case TPC::BIv_f8_ld_tnsr_partial_direct_vb: 
  case TPC::BIv_h8_ld_tnsr_partial_direct_vb:
  case TPC::BIv_i32_ld_tnsr_partial_direct_vb:  
  case TPC::BIv_u32_ld_tnsr_partial_direct_vb:  
  case TPC::BIv_i16_ld_tnsr_partial_direct_vb:  
  case TPC::BIv_u16_ld_tnsr_partial_direct_vb:  
  case TPC::BIv_i8_ld_tnsr_partial_direct_vb:   
  case TPC::BIv_u8_ld_tnsr_partial_direct_vb:   
  case TPC::BIv_i1_ld_tnsr_partial_direct_vb:   
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                               Intrinsic::tpc_ld_tnsr_partial_direct, true);

  case TPC::BIv_f32_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_bf16_ld_tnsr_high_partial_direct_b: 
  case TPC::BIv_f16_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_f8_ld_tnsr_high_partial_direct_b: 
  case TPC::BIv_h8_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_i32_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_u32_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_i16_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_u16_ld_tnsr_high_partial_direct_b:  
  case TPC::BIv_i8_ld_tnsr_high_partial_direct_b:   
  case TPC::BIv_u8_ld_tnsr_high_partial_direct_b:   
  case TPC::BIv_i1_ld_tnsr_high_partial_direct_b:   
  case TPC::BIv_f32_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_bf16_ld_tnsr_high_partial_direct_vb:
  case TPC::BIv_f16_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_f8_ld_tnsr_high_partial_direct_vb:
  case TPC::BIv_h8_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_i32_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_u32_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_i16_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_u16_ld_tnsr_high_partial_direct_vb: 
  case TPC::BIv_i8_ld_tnsr_high_partial_direct_vb:  
  case TPC::BIv_u8_ld_tnsr_high_partial_direct_vb:  
  case TPC::BIv_i1_ld_tnsr_high_partial_direct_vb:  
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                               Intrinsic::tpc_ld_tnsr_high_partial_direct, true);

  case TPC::BIv_f32_ld_tnsr_low_partial_direct_b:  
  case TPC::BIv_bf16_ld_tnsr_low_partial_direct_b: 
  case TPC::BIv_f16_ld_tnsr_low_partial_direct_b:  

  case TPC::BIv_f8_ld_tnsr_low_partial_direct_b: 
  case TPC::BIv_h8_ld_tnsr_low_partial_direct_b:  
  case TPC::BIv_i32_ld_tnsr_low_partial_direct_b:  
  case TPC::BIv_u32_ld_tnsr_low_partial_direct_b:  
  case TPC::BIv_i16_ld_tnsr_low_partial_direct_b:  
  case TPC::BIv_u16_ld_tnsr_low_partial_direct_b:  
  case TPC::BIv_i8_ld_tnsr_low_partial_direct_b:   
  case TPC::BIv_u8_ld_tnsr_low_partial_direct_b:   
  case TPC::BIv_i1_ld_tnsr_low_partial_direct_b:   
  case TPC::BIv_f32_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_bf16_ld_tnsr_low_partial_direct_vb:
  case TPC::BIv_f16_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_f8_ld_tnsr_low_partial_direct_vb:
  case TPC::BIv_h8_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_i32_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_u32_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_i16_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_u16_ld_tnsr_low_partial_direct_vb: 
  case TPC::BIv_i8_ld_tnsr_low_partial_direct_vb:  
  case TPC::BIv_u8_ld_tnsr_low_partial_direct_vb:  
  case TPC::BIv_i1_ld_tnsr_low_partial_direct_vb:  
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch, 0, 0,
                               Intrinsic::tpc_ld_tnsr_low_partial_direct, true);
    
  case TPC::BIv_bf16_ld_tnsr_cnvrt_partial_direct_b:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_BF16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_partial_direct, true);
  case TPC::BIv_f16_ld_tnsr_cnvrt_partial_direct_b:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_FP16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_partial_direct, true);
  case TPC::BIv_bf16_ld_tnsr_cnvrt_partial_direct_vb:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_BF16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_partial_direct, true);
  case TPC::BIv_f16_ld_tnsr_cnvrt_partial_direct_vb:
    return emit_LD_TNSR_DIRECT(CGF, BuiltinID, E, ReturnValue, Arch,
                               TPCII::SW_FP32_TO_FP16,
                               TPCII::SW_CNVRT_DT | TPCII::SW_AUTO_INC_DIM,
                               Intrinsic::tpc_ld_tnsr_cnvrt_partial_direct, true);

  //------ Scalar and Scalar/Vector instructioins ------------------------------

  case TPC::BIs_f32_mac:
  case TPC::BIs_i8_mac:
  case TPC::BIs_u8_mac:
  case TPC::BIs_i16_mac:
  case TPC::BIs_u16_mac:
  case TPC::BIs_bf16_mac:
  case TPC::BIs_f16_mac:
  case TPC::BIs_i8_mac_acc16:
  case TPC::BIs_u8_mac_acc16:
  case TPC::BIs_bf16_mac_acc32:
  case TPC::BIs_f16_mac_acc32:
  case TPC::BIs_f8_mac_acc32:
  case TPC::BIs_h8_mac_acc32:
  case TPC::BIs_u8_mac_acc32:
  case TPC::BIs_u16_mac_acc32:
  case TPC::BIv_f32_mac_b:
  case TPC::BIv_f32_mac_vb:
  case TPC::BIv_bf16_mac_b:
  case TPC::BIv_bf16_mac_vb:
  case TPC::BIv_f16_mac_b:
  case TPC::BIv_f16_mac_vb:
  case TPC::BIv_i8_mac_b:
  case TPC::BIv_i8_mac_vb:
  case TPC::BIv_u8_mac_b:
  case TPC::BIv_u8_mac_vb:
  case TPC::BIv_i16_mac_b:
  case TPC::BIv_i16_mac_vb:
  case TPC::BIv_u16_mac_b:
  case TPC::BIv_u16_mac_vb:
  case TPC::BIv_bf16_mac_acc32_b:
  case TPC::BIv_bf16_mac_acc32_vb:
  case TPC::BIv_f16_mac_acc32_b:
  case TPC::BIv_f16_mac_acc32_vb:
  case TPC::BIv_f8_mac_acc32_b:
  case TPC::BIv_f8_mac_acc32_vb:
  case TPC::BIv_h8_mac_acc32_b:
  case TPC::BIv_h8_mac_acc32_vb:
  case TPC::BIv_i8_mac_acc16_b:
  case TPC::BIv_i8_mac_acc16_vb:
  case TPC::BIv_u8_mac_acc16_b:
  case TPC::BIv_u8_mac_acc16_vb:
  case TPC::BIv_u8_mac_acc32_b:
  case TPC::BIv_u8_mac_acc32_vb:
  case TPC::BIv_u16_mac_acc32_b:
  case TPC::BIv_u16_mac_acc32_vb:
  case TPC::BIv_i8_mac_x2_vb:
  case TPC::BIv_i8_mac_x2_b:
  case TPC::BIv_u8_mac_x2_vb:
  case TPC::BIv_u8_mac_x2_b:
  case TPC::BIv_f32_mac_x2_vb:
  case TPC::BIv_f32_mac_x2_b:
  case TPC::BIv_f32_mac_x2_svv_vb:
  case TPC::BIv_f32_mac_x2_svv_b:
  case TPC::BIv_i8_mac_x2_acc16_vb:
  case TPC::BIv_i8_mac_x2_acc16_b:
  case TPC::BIv_u8_mac_x2_acc16_vb:
  case TPC::BIv_u8_mac_x2_acc16_b:
  case TPC::BIv_u8_mac_x2_acc32_vb:
  case TPC::BIv_u8_mac_x2_acc32_b:
  case TPC::BIv_i8_mac_zp_vb:
  case TPC::BIv_i8_mac_zp_b:
  case TPC::BIv_u8_mac_zp_vb:
  case TPC::BIv_u8_mac_zp_b:
  case TPC::BIv_i8_mac_zp_acc16_vb:
  case TPC::BIv_i8_mac_zp_acc16_b:
  case TPC::BIv_u8_mac_zp_acc16_vb:
  case TPC::BIv_u8_mac_zp_acc16_b:
  case TPC::BIv_u8_mac_zp_acc32_vb:
  case TPC::BIv_u8_mac_zp_acc32_b:
  case TPC::BIv_i8_mac_x2_zp_vb:
  case TPC::BIv_i8_mac_x2_zp_b:
  case TPC::BIv_u8_mac_x2_zp_vb:
  case TPC::BIv_u8_mac_x2_zp_b:
  case TPC::BIv_i8_mac_x2_zp_acc16_vb:
  case TPC::BIv_i8_mac_x2_zp_acc16_b:
  case TPC::BIv_u8_mac_x2_zp_acc16_vb:
  case TPC::BIv_u8_mac_x2_zp_acc16_b:
  case TPC::BIv_u8_mac_x2_zp_acc32_vb:
  case TPC::BIv_u8_mac_x2_zp_acc32_b:
    return emit_MAC(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_madd_b:
  case TPC::BIv_f32_madd_vb:
  case TPC::BIv_bf16_madd_b:
  case TPC::BIv_bf16_madd_vb:
  case TPC::BIv_f16_madd_b:
  case TPC::BIv_f16_madd_vb:
  case TPC::BIv_i8_madd_b:
  case TPC::BIv_i8_madd_vb:
  case TPC::BIv_u8_madd_b:
  case TPC::BIv_u8_madd_vb:
  case TPC::BIv_i16_madd_b:
  case TPC::BIv_i16_madd_vb:
  case TPC::BIv_u16_madd_b:
  case TPC::BIv_u16_madd_vb:
  case TPC::BIv_bf16_madd_acc32_b:
  case TPC::BIv_bf16_madd_acc32_vb:
  case TPC::BIv_f16_madd_acc32_b:
  case TPC::BIv_f16_madd_acc32_vb:
  case TPC::BIv_f8_madd_acc32_b:
  case TPC::BIv_f8_madd_acc32_vb:
  case TPC::BIv_h8_madd_acc32_b:
  case TPC::BIv_h8_madd_acc32_vb:
  case TPC::BIv_i8_madd_acc16_b:
  case TPC::BIv_i8_madd_acc16_vb:
  case TPC::BIv_u8_madd_acc16_b:
  case TPC::BIv_u8_madd_acc16_vb:
  case TPC::BIv_u8_madd_acc32_b:
  case TPC::BIv_u8_madd_acc32_vb:
  case TPC::BIv_u16_madd_acc32_b:
  case TPC::BIv_u16_madd_acc32_vb:
  case TPC::BIv_i8_madd_zp_vb:
  case TPC::BIv_i8_madd_zp_b:
  case TPC::BIv_u8_madd_zp_vb:
  case TPC::BIv_u8_madd_zp_b:
  case TPC::BIv_i8_madd_zp_acc16_vb:
  case TPC::BIv_i8_madd_zp_acc16_b:
  case TPC::BIv_u8_madd_zp_acc16_vb:
  case TPC::BIv_u8_madd_zp_acc16_b:
  case TPC::BIv_u8_madd_zp_acc32_vb:
  case TPC::BIv_u8_madd_zp_acc32_b:
  case TPC::BIv_f32_madd_x2_vb:
  case TPC::BIv_f32_madd_x2_b:
  case TPC::BIv_f32_madd_x2_svvv_vb:
  case TPC::BIv_f32_madd_x2_svvv_b:
  case TPC::BIv_f32_madd_x2_vvsv_vb:
  case TPC::BIv_f32_madd_x2_vvsv_b:
    return emit_MADD(CGF, BuiltinID, E, ReturnValue, Arch);
  case TPC::BIs_convert_int32_to_i16:
  case TPC::BIv_convert_int32_to_i16_b:
  case TPC::BIv_convert_int32_to_i16_vb:
  case TPC::BIv_convert_int32_to_i16_single_b:
  case TPC::BIv_convert_int32_to_i16_single_vb:
  case TPC::BIv_convert_int32_to_i16_all_b:
  case TPC::BIv_convert_int32_to_i16_all_vb:
  case TPC::BIs_convert_int32_to_i8:
  case TPC::BIv_convert_int32_to_i8_b:
  case TPC::BIv_convert_int32_to_i8_vb:
  case TPC::BIv_convert_int32_to_i8_single_b:
  case TPC::BIv_convert_int32_to_i8_single_vb:
  case TPC::BIv_convert_int32_to_i8_all_b:
  case TPC::BIv_convert_int32_to_i8_all_vb:
  case TPC::BIs_convert_uint32_to_u16:
  case TPC::BIv_convert_uint32_to_u16_b:
  case TPC::BIv_convert_uint32_to_u16_vb:
  case TPC::BIv_convert_uint32_to_u16_single_b:
  case TPC::BIv_convert_uint32_to_u16_single_vb:
  case TPC::BIv_convert_uint32_to_u16_all_b:
  case TPC::BIv_convert_uint32_to_u16_all_vb:
  case TPC::BIs_convert_uint32_to_u8:
  case TPC::BIv_convert_uint32_to_u8_b:
  case TPC::BIv_convert_uint32_to_u8_vb:
  case TPC::BIv_convert_uint32_to_u8_single_b:
  case TPC::BIv_convert_uint32_to_u8_single_vb:
  case TPC::BIv_convert_uint32_to_u8_all_b:
  case TPC::BIv_convert_uint32_to_u8_all_vb:
  case TPC::BIs_convert_int16_to_i8:
  case TPC::BIv_convert_int16_to_i8_b:
  case TPC::BIv_convert_int16_to_i8_vb:
  case TPC::BIv_convert_int16_to_i8_single_b:
  case TPC::BIv_convert_int16_to_i8_single_vb:
  case TPC::BIv_convert_int16_to_i8_all_b:
  case TPC::BIv_convert_int16_to_i8_all_vb:
  case TPC::BIs_convert_int8_to_i4:
  case TPC::BIv_convert_int8_to_i4_all_b:
  case TPC::BIv_convert_int8_to_i4_all_vb:
  case TPC::BIs_convert_uint16_to_u8:
  case TPC::BIv_convert_uint16_to_u8_b:
  case TPC::BIv_convert_uint16_to_u8_vb:
  case TPC::BIv_convert_uint16_to_u8_single_b:
  case TPC::BIv_convert_uint16_to_u8_single_vb:
  case TPC::BIv_convert_uint16_to_u8_all_b:
  case TPC::BIv_convert_uint16_to_u8_all_vb:
  case TPC::BIs_convert_uint8_to_u4:
  case TPC::BIv_convert_uint8_to_u4_all_b:
  case TPC::BIv_convert_uint8_to_u4_all_vb:
    return emit_CONVERT_INT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_convert_i64_to_i32:
    return emit_CONVERT_INT64(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_convert_f32_to_bf16:
  case TPC::BIs_convert_f32_to_f16:
  case TPC::BIs_convert_f32_to_i32:
  case TPC::BIs_convert_f32_to_i16:
  case TPC::BIs_convert_f32_to_i8:
  case TPC::BIs_convert_f32_to_u32:
  case TPC::BIs_convert_f32_to_u16:
  case TPC::BIs_convert_f32_to_u8:
  case TPC::BIs_convert_f32_to_f8:
  case TPC::BIs_convert_f32_to_h8:

  case TPC::BIs_convert_bf16_to_f32:
  case TPC::BIs_convert_bf16_to_f16:
  case TPC::BIs_convert_bf16_to_i16:
  case TPC::BIs_convert_bf16_to_i8:
  case TPC::BIs_convert_bf16_to_i32:
  case TPC::BIs_convert_bf16_to_u32:
  case TPC::BIs_convert_bf16_to_u16:
  case TPC::BIs_convert_bf16_to_u8:
  case TPC::BIs_convert_bf16_to_f8:
  case TPC::BIs_convert_bf16_to_h8:

  case TPC::BIs_convert_f16_to_f32:
  case TPC::BIs_convert_f16_to_bf16:
  case TPC::BIs_convert_f16_to_i16:
  case TPC::BIs_convert_f16_to_i8:
  case TPC::BIs_convert_f16_to_i32:
  case TPC::BIs_convert_f16_to_u32:
  case TPC::BIs_convert_f16_to_u16:
  case TPC::BIs_convert_f16_to_u8:
  case TPC::BIs_convert_f16_to_f8:
  case TPC::BIs_convert_f16_to_h8:

  case TPC::BIs_convert_f8_to_f32:
  case TPC::BIs_convert_f8_to_bf16:
  case TPC::BIs_convert_f8_to_f16:
  case TPC::BIs_convert_f8_to_i32:
  case TPC::BIs_convert_f8_to_u32:
  case TPC::BIs_convert_f8_to_i16:
  case TPC::BIs_convert_f8_to_u16:
  case TPC::BIs_convert_f8_to_i8:
  case TPC::BIs_convert_f8_to_u8:
  case TPC::BIs_convert_f8_to_h8:
  case TPC::BIs_convert_h8_to_f32:
  case TPC::BIs_convert_h8_to_bf16:
  case TPC::BIs_convert_h8_to_f16:
  case TPC::BIs_convert_h8_to_i32:
  case TPC::BIs_convert_h8_to_u32:
  case TPC::BIs_convert_h8_to_i16:
  case TPC::BIs_convert_h8_to_u16:
  case TPC::BIs_convert_h8_to_i8:
  case TPC::BIs_convert_h8_to_u8:
  case TPC::BIs_convert_h8_to_f8:

  case TPC::BIs_convert_i32_to_f32:
  case TPC::BIs_convert_i32_to_bf16:
  case TPC::BIs_convert_i32_to_f16:
  case TPC::BIs_convert_i32_to_u32:
  case TPC::BIs_convert_i32_to_u8:
  case TPC::BIs_convert_i32_to_i16:
  case TPC::BIs_convert_i32_to_u16:
  case TPC::BIs_convert_i32_to_i8:
  case TPC::BIs_convert_i32_to_f8:
  case TPC::BIs_convert_i32_to_h8:

  case TPC::BIs_convert_u32_to_f32:
  case TPC::BIs_convert_u32_to_bf16:
  case TPC::BIs_convert_u32_to_f16:
  case TPC::BIs_convert_u32_to_i32:
  case TPC::BIs_convert_u32_to_i16:
  case TPC::BIs_convert_u32_to_u16:
  case TPC::BIs_convert_u32_to_i8:
  case TPC::BIs_convert_u32_to_u8:
  case TPC::BIs_convert_u32_to_f8:
  case TPC::BIs_convert_u32_to_h8:

  case TPC::BIs_convert_i16_to_f32:
  case TPC::BIs_convert_i16_to_bf16:
  case TPC::BIs_convert_i16_to_f16:
  case TPC::BIs_convert_i16_to_i32:
  case TPC::BIs_convert_i16_to_u32:
  case TPC::BIs_convert_i16_to_u16:
  case TPC::BIs_convert_i16_to_u8:
  case TPC::BIs_convert_i16_to_i8:
  case TPC::BIs_convert_i16_to_f8:
  case TPC::BIs_convert_i16_to_h8:

  case TPC::BIs_convert_u16_to_bf16:
  case TPC::BIs_convert_u16_to_f16:
  case TPC::BIs_convert_u16_to_i32:
  case TPC::BIs_convert_u16_to_u32:
  case TPC::BIs_convert_u16_to_i16:
  case TPC::BIs_convert_u16_to_i8:
  case TPC::BIs_convert_u16_to_u8:
  case TPC::BIs_convert_u16_to_f32:
  case TPC::BIs_convert_u16_to_f8:
  case TPC::BIs_convert_u16_to_h8:

  case TPC::BIs_convert_i8_to_f32:
  case TPC::BIs_convert_i8_to_bf16:
  case TPC::BIs_convert_i8_to_f16:
  case TPC::BIs_convert_i8_to_i32:
  case TPC::BIs_convert_i8_to_u32:
  case TPC::BIs_convert_i8_to_i16:
  case TPC::BIs_convert_i8_to_u16:
  case TPC::BIs_convert_i8_to_u8:
  case TPC::BIs_convert_i8_to_f8:
  case TPC::BIs_convert_i8_to_h8:

  case TPC::BIs_convert_u8_to_f32:
  case TPC::BIs_convert_u8_to_bf16:
  case TPC::BIs_convert_u8_to_f16:
  case TPC::BIs_convert_u8_to_i32:
  case TPC::BIs_convert_u8_to_u32:
  case TPC::BIs_convert_u8_to_i16:
  case TPC::BIs_convert_u8_to_u16:
  case TPC::BIs_convert_u8_to_i8:
  case TPC::BIs_convert_u8_to_f8:
  case TPC::BIs_convert_u8_to_h8:

  case TPC::BIs_convert_i4_to_i8:
  case TPC::BIs_convert_u4_to_u8:

  case TPC::BIv_convert_f32_to_i32_b:
  case TPC::BIv_convert_f32_to_i32_vb:
  case TPC::BIv_convert_f32_to_i16_b:
  case TPC::BIv_convert_f32_to_i16_vb:
  case TPC::BIv_convert_f32_to_i8_b:
  case TPC::BIv_convert_f32_to_i8_vb:
  case TPC::BIv_convert_f32_to_bf16_b:
  case TPC::BIv_convert_f32_to_bf16_vb:
  case TPC::BIv_convert_f32_to_f16_b:
  case TPC::BIv_convert_f32_to_f16_vb:
  case TPC::BIv_convert_f32_to_bf16_single_b:
  case TPC::BIv_convert_f32_to_bf16_single_vb:
  case TPC::BIv_convert_f32_to_f16_single_b:
  case TPC::BIv_convert_f32_to_f16_single_vb:
  case TPC::BIv_convert_f32_to_u32_b:
  case TPC::BIv_convert_f32_to_u32_vb:
  case TPC::BIv_convert_f32_to_u16_b:
  case TPC::BIv_convert_f32_to_u16_vb:
  case TPC::BIv_convert_f32_to_u8_b:
  case TPC::BIv_convert_f32_to_u8_vb:
  case TPC::BIv_convert_f32_to_f8_b:
  case TPC::BIv_convert_f32_to_f8_vb:
  case TPC::BIv_convert_f32_to_h8_b:
  case TPC::BIv_convert_f32_to_h8_vb:

  case TPC::BIv_convert_bf16_to_i8_b:
  case TPC::BIv_convert_bf16_to_i8_vb:
  case TPC::BIv_convert_bf16_to_f32_b:
  case TPC::BIv_convert_bf16_to_f32_vb:
  case TPC::BIv_convert_bf16_to_f16_b:
  case TPC::BIv_convert_bf16_to_f16_vb:
  case TPC::BIv_convert_bf16_to_i16_b:
  case TPC::BIv_convert_bf16_to_i16_vb:
  case TPC::BIv_convert_bf16_to_u16_b:
  case TPC::BIv_convert_bf16_to_u16_vb:
  case TPC::BIv_convert_bf16_to_i32_b:
  case TPC::BIv_convert_bf16_to_i32_vb:
  case TPC::BIv_convert_bf16_to_u32_b:
  case TPC::BIv_convert_bf16_to_u32_vb:
  case TPC::BIv_convert_bf16_to_u8_b:
  case TPC::BIv_convert_bf16_to_u8_vb:
  case TPC::BIv_convert_bf16_to_f8_b:
  case TPC::BIv_convert_bf16_to_f8_vb:
  case TPC::BIv_convert_bf16_to_h8_b:
  case TPC::BIv_convert_bf16_to_h8_vb:

  case TPC::BIv_convert_f16_to_f32_b:
  case TPC::BIv_convert_f16_to_f32_vb:
  case TPC::BIv_convert_f16_to_bf16_b:
  case TPC::BIv_convert_f16_to_bf16_vb:
  case TPC::BIv_convert_f16_to_i16_b:
  case TPC::BIv_convert_f16_to_i16_vb:
  case TPC::BIv_convert_f16_to_i8_b:
  case TPC::BIv_convert_f16_to_i8_vb:
  case TPC::BIv_convert_f16_to_u16_b:
  case TPC::BIv_convert_f16_to_u16_vb:
  case TPC::BIv_convert_f16_to_i32_b:
  case TPC::BIv_convert_f16_to_i32_vb:
  case TPC::BIv_convert_f16_to_u32_b:
  case TPC::BIv_convert_f16_to_u32_vb:
  case TPC::BIv_convert_f16_to_u8_b:
  case TPC::BIv_convert_f16_to_u8_vb:
  case TPC::BIv_convert_f16_to_f8_b:
  case TPC::BIv_convert_f16_to_f8_vb:
  case TPC::BIv_convert_f16_to_h8_b:
  case TPC::BIv_convert_f16_to_h8_vb:

  case TPC::BIv_convert_f8_to_f32_b:
  case TPC::BIv_convert_f8_to_f32_vb:
  case TPC::BIv_convert_h8_to_f32_b:
  case TPC::BIv_convert_h8_to_f32_vb:
  case TPC::BIv_convert_f8_to_bf16_b:
  case TPC::BIv_convert_f8_to_bf16_vb:
  case TPC::BIv_convert_h8_to_bf16_b:
  case TPC::BIv_convert_h8_to_bf16_vb:
  case TPC::BIv_convert_f8_to_f16_b:
  case TPC::BIv_convert_f8_to_f16_vb:
  case TPC::BIv_convert_h8_to_f16_b:
  case TPC::BIv_convert_h8_to_f16_vb:
  case TPC::BIv_convert_f8_to_i32_b:
  case TPC::BIv_convert_f8_to_i32_vb:
  case TPC::BIv_convert_h8_to_i32_b:
  case TPC::BIv_convert_h8_to_i32_vb:
  case TPC::BIv_convert_f8_to_u32_b:
  case TPC::BIv_convert_f8_to_u32_vb:
  case TPC::BIv_convert_h8_to_u32_b:
  case TPC::BIv_convert_h8_to_u32_vb:
  case TPC::BIv_convert_f8_to_i16_b:
  case TPC::BIv_convert_f8_to_i16_vb:
  case TPC::BIv_convert_h8_to_i16_b:
  case TPC::BIv_convert_h8_to_i16_vb:
  case TPC::BIv_convert_f8_to_u16_b:
  case TPC::BIv_convert_f8_to_u16_vb:
  case TPC::BIv_convert_h8_to_u16_b:
  case TPC::BIv_convert_h8_to_u16_vb:
  case TPC::BIv_convert_f8_to_h8_b:
  case TPC::BIv_convert_f8_to_h8_vb:
  case TPC::BIv_convert_h8_to_f8_b:
  case TPC::BIv_convert_h8_to_f8_vb:
  case TPC::BIv_convert_f8_to_i8_b:
  case TPC::BIv_convert_f8_to_i8_vb:
  case TPC::BIv_convert_h8_to_i8_b:
  case TPC::BIv_convert_h8_to_i8_vb:
  case TPC::BIv_convert_f8_to_u8_b:
  case TPC::BIv_convert_f8_to_u8_vb:
  case TPC::BIv_convert_h8_to_u8_b:
  case TPC::BIv_convert_h8_to_u8_vb:

  case TPC::BIv_convert_i32_to_bf16_b:
  case TPC::BIv_convert_i32_to_bf16_vb:
  case TPC::BIv_convert_i32_to_f16_b:
  case TPC::BIv_convert_i32_to_f16_vb:
  case TPC::BIv_convert_i32_to_f32_b:
  case TPC::BIv_convert_i32_to_f32_vb:
  case TPC::BIv_convert_i32_to_u32_b:
  case TPC::BIv_convert_i32_to_u32_vb:
  case TPC::BIv_convert_i32_to_u8_b:
  case TPC::BIv_convert_i32_to_u8_vb:
  case TPC::BIv_convert_i32_to_i16_b:
  case TPC::BIv_convert_i32_to_i16_vb:
  case TPC::BIv_convert_i32_to_u16_b:
  case TPC::BIv_convert_i32_to_u16_vb:
  case TPC::BIv_convert_i32_to_i8_b:
  case TPC::BIv_convert_i32_to_i8_vb:
  case TPC::BIv_convert_i32_to_f8_b:
  case TPC::BIv_convert_i32_to_f8_vb:
  case TPC::BIv_convert_i32_to_h8_b:
  case TPC::BIv_convert_i32_to_h8_vb:

  case TPC::BIv_convert_u32_to_f32_b:
  case TPC::BIv_convert_u32_to_f32_vb:
  case TPC::BIv_convert_u32_to_i32_b:
  case TPC::BIv_convert_u32_to_i32_vb:
  case TPC::BIv_convert_u32_to_bf16_b:
  case TPC::BIv_convert_u32_to_bf16_vb:
  case TPC::BIv_convert_u32_to_f16_b:
  case TPC::BIv_convert_u32_to_f16_vb:
  case TPC::BIv_convert_u32_to_i16_b:
  case TPC::BIv_convert_u32_to_i16_vb:
  case TPC::BIv_convert_u32_to_u16_b:
  case TPC::BIv_convert_u32_to_u16_vb:
  case TPC::BIv_convert_u32_to_i8_b:
  case TPC::BIv_convert_u32_to_i8_vb:
  case TPC::BIv_convert_u32_to_u8_b:
  case TPC::BIv_convert_u32_to_u8_vb:
  case TPC::BIv_convert_u32_to_f8_b:
  case TPC::BIv_convert_u32_to_f8_vb:
  case TPC::BIv_convert_u32_to_h8_b:
  case TPC::BIv_convert_u32_to_h8_vb:

  case TPC::BIv_convert_i16_to_f32_b:
  case TPC::BIv_convert_i16_to_f32_vb:
  case TPC::BIv_convert_i16_to_i32_b:
  case TPC::BIv_convert_i16_to_i32_vb:
  case TPC::BIv_convert_i16_to_u32_b:
  case TPC::BIv_convert_i16_to_u32_vb:
  case TPC::BIv_convert_i16_to_u16_b:
  case TPC::BIv_convert_i16_to_u16_vb:
  case TPC::BIv_convert_i16_to_bf16_b:
  case TPC::BIv_convert_i16_to_bf16_vb:
  case TPC::BIv_convert_i16_to_f16_b:
  case TPC::BIv_convert_i16_to_f16_vb:
  case TPC::BIv_convert_i16_to_u8_b:
  case TPC::BIv_convert_i16_to_u8_vb:
  case TPC::BIv_convert_i16_to_i8_b:
  case TPC::BIv_convert_i16_to_i8_vb:
  case TPC::BIv_convert_i16_to_f8_b:
  case TPC::BIv_convert_i16_to_f8_vb:
  case TPC::BIv_convert_i16_to_h8_b:
  case TPC::BIv_convert_i16_to_h8_vb:

  case TPC::BIv_convert_u16_to_i16_b:
  case TPC::BIv_convert_u16_to_i16_vb:
  case TPC::BIv_convert_u16_to_i32_b:
  case TPC::BIv_convert_u16_to_i32_vb:
  case TPC::BIv_convert_u16_to_u32_b:
  case TPC::BIv_convert_u16_to_u32_vb:
  case TPC::BIv_convert_u16_to_f32_b:
  case TPC::BIv_convert_u16_to_f32_vb:
  case TPC::BIv_convert_u16_to_i8_b:
  case TPC::BIv_convert_u16_to_i8_vb:
  case TPC::BIv_convert_u16_to_u8_b:
  case TPC::BIv_convert_u16_to_u8_vb:
  case TPC::BIv_convert_u16_to_f8_b:
  case TPC::BIv_convert_u16_to_f8_vb:
  case TPC::BIv_convert_u16_to_h8_b:
  case TPC::BIv_convert_u16_to_h8_vb:

  case TPC::BIv_convert_i8_to_f32_b:
  case TPC::BIv_convert_i8_to_f32_vb:
  case TPC::BIv_convert_i8_to_i32_b:
  case TPC::BIv_convert_i8_to_i32_vb:
  case TPC::BIv_convert_i8_to_u32_b:
  case TPC::BIv_convert_i8_to_u32_vb:
  case TPC::BIv_convert_i8_to_i16_b:
  case TPC::BIv_convert_i8_to_i16_vb:
  case TPC::BIv_convert_i8_to_u16_b:
  case TPC::BIv_convert_i8_to_u16_vb:
  case TPC::BIv_convert_i8_to_u8_b:
  case TPC::BIv_convert_i8_to_u8_vb:
  case TPC::BIv_convert_i8_to_bf16_b:
  case TPC::BIv_convert_i8_to_bf16_vb:
  case TPC::BIv_convert_i8_to_f16_b:
  case TPC::BIv_convert_i8_to_f16_vb:
  case TPC::BIv_convert_i8_to_f8_b:
  case TPC::BIv_convert_i8_to_f8_vb:
  case TPC::BIv_convert_i8_to_h8_b:
  case TPC::BIv_convert_i8_to_h8_vb:

  case TPC::BIv_convert_u16_to_bf16_b:
  case TPC::BIv_convert_u16_to_bf16_vb:
  case TPC::BIv_convert_u16_to_f16_b:
  case TPC::BIv_convert_u16_to_f16_vb:

  case TPC::BIv_convert_u8_to_f32_b:
  case TPC::BIv_convert_u8_to_f32_vb:
  case TPC::BIv_convert_u8_to_bf16_b:
  case TPC::BIv_convert_u8_to_bf16_vb:
  case TPC::BIv_convert_u8_to_i32_b:
  case TPC::BIv_convert_u8_to_i32_vb:
  case TPC::BIv_convert_u8_to_i16_b:
  case TPC::BIv_convert_u8_to_i16_vb:
  case TPC::BIv_convert_u8_to_u32_b:
  case TPC::BIv_convert_u8_to_u32_vb:
  case TPC::BIv_convert_u8_to_u16_b:
  case TPC::BIv_convert_u8_to_u16_vb:
  case TPC::BIv_convert_u8_to_f16_b:
  case TPC::BIv_convert_u8_to_f16_vb:
  case TPC::BIv_convert_u8_to_i8_b:
  case TPC::BIv_convert_u8_to_i8_vb:
  case TPC::BIv_convert_u8_to_f8_b:
  case TPC::BIv_convert_u8_to_f8_vb:
  case TPC::BIv_convert_u8_to_h8_b:
  case TPC::BIv_convert_u8_to_h8_vb:

  case TPC::BIv_convert_i4_to_i8_b:
  case TPC::BIv_convert_i4_to_i8_vb:

  case TPC::BIv_convert_u4_to_u8_b:
  case TPC::BIv_convert_u4_to_u8_vb:

  case TPC::BIv_convert_i32_to_f32_x4_b:
  case TPC::BIv_convert_i32_to_f32_x4_vb:
  case TPC::BIv_convert_u32_to_f32_x4_b:
  case TPC::BIv_convert_u32_to_f32_x4_vb:
  case TPC::BIv_convert_i32_to_f32_x2_b:
  case TPC::BIv_convert_i32_to_f32_x2_vb:
  case TPC::BIv_convert_u32_to_f32_x2_b:
  case TPC::BIv_convert_u32_to_f32_x2_vb:

  case TPC::BIv_convert_f32_to_i16_all_b:
  case TPC::BIv_convert_f32_to_i16_all_vb:
  case TPC::BIv_convert_f32_to_i8_all_b:
  case TPC::BIv_convert_f32_to_i8_all_vb:
  case TPC::BIv_convert_f32_to_f16_all_b:
  case TPC::BIv_convert_f32_to_f16_all_vb:
  case TPC::BIv_convert_f32_to_bf16_all_b:
  case TPC::BIv_convert_f32_to_bf16_all_vb:
  case TPC::BIv_convert_bf16_to_f32_all_b:
  case TPC::BIv_convert_bf16_to_f32_all_vb:
  case TPC::BIv_convert_bf16_to_i8_all_b:
  case TPC::BIv_convert_bf16_to_i8_all_vb:
  case TPC::BIv_convert_f16_to_f32_all_b:
  case TPC::BIv_convert_f16_to_f32_all_vb:
  case TPC::BIv_convert_f16_to_i8_all_b:
  case TPC::BIv_convert_f16_to_i8_all_vb:
  case TPC::BIv_convert_i32_to_bf16_all_b:
  case TPC::BIv_convert_i32_to_bf16_all_vb:
  case TPC::BIv_convert_i32_to_f16_all_b:
  case TPC::BIv_convert_i32_to_f16_all_vb:
  case TPC::BIv_convert_i16_to_f32_all_b:
  case TPC::BIv_convert_i16_to_f32_all_vb:
  case TPC::BIv_convert_i16_to_i32_all_b:
  case TPC::BIv_convert_i16_to_i32_all_vb:
  case TPC::BIv_convert_i16_to_u32_all_b:
  case TPC::BIv_convert_i16_to_u32_all_vb:
  case TPC::BIv_convert_i16_to_u8_all_b:
  case TPC::BIv_convert_i16_to_u8_all_vb:
  case TPC::BIv_convert_i8_to_f32_all_b:
  case TPC::BIv_convert_i8_to_f32_all_vb:
  case TPC::BIv_convert_i8_to_i32_all_b:
  case TPC::BIv_convert_i8_to_i32_all_vb:
  case TPC::BIv_convert_i8_to_u32_all_b:
  case TPC::BIv_convert_i8_to_u32_all_vb:
  case TPC::BIv_convert_i8_to_i16_all_b:
  case TPC::BIv_convert_i8_to_i16_all_vb:
  case TPC::BIv_convert_i8_to_u16_all_b:
  case TPC::BIv_convert_i8_to_u16_all_vb:
  case TPC::BIv_convert_i8_to_bf16_all_b:
  case TPC::BIv_convert_i8_to_bf16_all_vb:
  case TPC::BIv_convert_i8_to_f16_all_b:
  case TPC::BIv_convert_i8_to_f16_all_vb:
  case TPC::BIv_convert_u8_to_f32_all_b:
  case TPC::BIv_convert_u8_to_f32_all_vb:
  case TPC::BIv_convert_u8_to_bf16_all_b:
  case TPC::BIv_convert_u8_to_bf16_all_vb:
  case TPC::BIv_convert_u8_to_i32_all_b:
  case TPC::BIv_convert_u8_to_i32_all_vb:
  case TPC::BIv_convert_u8_to_i16_all_b:
  case TPC::BIv_convert_u8_to_i16_all_vb:
  case TPC::BIv_convert_u8_to_u32_all_b:
  case TPC::BIv_convert_u8_to_u32_all_vb:
  case TPC::BIv_convert_u8_to_u16_all_b:
  case TPC::BIv_convert_u8_to_u16_all_vb:
  case TPC::BIv_convert_u8_to_f16_all_b:
  case TPC::BIv_convert_u8_to_f16_all_vb:
  case TPC::BIv_convert_i4_to_i8_all_b:
  case TPC::BIv_convert_i4_to_i8_all_vb:
  case TPC::BIv_convert_u4_to_u8_all_b:
  case TPC::BIv_convert_u4_to_u8_all_vb:
  case TPC::BIv_convert_f32_to_u16_all_b:
  case TPC::BIv_convert_f32_to_u16_all_vb:
  case TPC::BIv_convert_f32_to_u8_all_b:
  case TPC::BIv_convert_f32_to_u8_all_vb:
  case TPC::BIv_convert_bf16_to_i32_all_b:
  case TPC::BIv_convert_bf16_to_i32_all_vb:
  case TPC::BIv_convert_bf16_to_u32_all_b:
  case TPC::BIv_convert_bf16_to_u32_all_vb:
  case TPC::BIv_convert_bf16_to_u8_all_b:
  case TPC::BIv_convert_bf16_to_u8_all_vb:
  case TPC::BIv_convert_f16_to_u32_all_b:
  case TPC::BIv_convert_f16_to_u32_all_vb:
  case TPC::BIv_convert_f16_to_i32_all_b:
  case TPC::BIv_convert_f16_to_i32_all_vb:
  case TPC::BIv_convert_f16_to_u8_all_b:
  case TPC::BIv_convert_f16_to_u8_all_vb:
  case TPC::BIv_convert_i32_to_i16_all_b:
  case TPC::BIv_convert_i32_to_i16_all_vb:
  case TPC::BIv_convert_i32_to_u16_all_b:
  case TPC::BIv_convert_i32_to_u16_all_vb:
  case TPC::BIv_convert_i32_to_i8_all_b:
  case TPC::BIv_convert_i32_to_i8_all_vb:
  case TPC::BIv_convert_i32_to_u8_all_b:
  case TPC::BIv_convert_i32_to_u8_all_vb:
  case TPC::BIv_convert_u32_to_bf16_all_b:
  case TPC::BIv_convert_u32_to_bf16_all_vb:
  case TPC::BIv_convert_u32_to_f16_all_b:
  case TPC::BIv_convert_u32_to_f16_all_vb:
  case TPC::BIv_convert_u32_to_i16_all_b:
  case TPC::BIv_convert_u32_to_i16_all_vb:
  case TPC::BIv_convert_u32_to_u16_all_b:
  case TPC::BIv_convert_u32_to_u16_all_vb:
  case TPC::BIv_convert_u32_to_i8_all_b:
  case TPC::BIv_convert_u32_to_i8_all_vb:
  case TPC::BIv_convert_u32_to_u8_all_b:
  case TPC::BIv_convert_u32_to_u8_all_vb:
  case TPC::BIv_convert_i16_to_i8_all_b:
  case TPC::BIv_convert_i16_to_i8_all_vb:
  case TPC::BIv_convert_u16_to_f32_all_b:
  case TPC::BIv_convert_u16_to_f32_all_vb:
  case TPC::BIv_convert_u16_to_i32_all_b:
  case TPC::BIv_convert_u16_to_i32_all_vb:
  case TPC::BIv_convert_u16_to_u32_all_b:
  case TPC::BIv_convert_u16_to_u32_all_vb:
  case TPC::BIv_convert_u16_to_i8_all_b:
  case TPC::BIv_convert_u16_to_i8_all_vb:
  case TPC::BIv_convert_u16_to_u8_all_b:
  case TPC::BIv_convert_u16_to_u8_all_vb:
  case TPC::BIv_convert_f32_to_f8_all_b:
  case TPC::BIv_convert_f32_to_f8_all_vb:
  case TPC::BIv_convert_f32_to_h8_all_b:
  case TPC::BIv_convert_f32_to_h8_all_vb:
  case TPC::BIv_convert_bf16_to_f8_all_b:
  case TPC::BIv_convert_bf16_to_f8_all_vb:
  case TPC::BIv_convert_bf16_to_h8_all_b:
  case TPC::BIv_convert_bf16_to_h8_all_vb:
  case TPC::BIv_convert_f16_to_f8_all_b:
  case TPC::BIv_convert_f16_to_f8_all_vb:
  case TPC::BIv_convert_f16_to_h8_all_b:
  case TPC::BIv_convert_f16_to_h8_all_vb:
  case TPC::BIv_convert_f8_to_f32_all_b:
  case TPC::BIv_convert_f8_to_f32_all_vb:
  case TPC::BIv_convert_h8_to_f32_all_b:
  case TPC::BIv_convert_h8_to_f32_all_vb:
  case TPC::BIv_convert_f8_to_bf16_all_b:
  case TPC::BIv_convert_f8_to_bf16_all_vb:
  case TPC::BIv_convert_h8_to_bf16_all_b:
  case TPC::BIv_convert_h8_to_bf16_all_vb:
  case TPC::BIv_convert_f8_to_f16_all_b:
  case TPC::BIv_convert_f8_to_f16_all_vb:
  case TPC::BIv_convert_h8_to_f16_all_b:
  case TPC::BIv_convert_h8_to_f16_all_vb:
  case TPC::BIv_convert_f8_to_i32_all_b:
  case TPC::BIv_convert_f8_to_i32_all_vb:
  case TPC::BIv_convert_h8_to_i32_all_b:
  case TPC::BIv_convert_h8_to_i32_all_vb:
  case TPC::BIv_convert_f8_to_u32_all_b:
  case TPC::BIv_convert_f8_to_u32_all_vb:
  case TPC::BIv_convert_h8_to_u32_all_b:
  case TPC::BIv_convert_h8_to_u32_all_vb:
  case TPC::BIv_convert_f8_to_i16_all_b:
  case TPC::BIv_convert_f8_to_i16_all_vb:
  case TPC::BIv_convert_h8_to_i16_all_b:
  case TPC::BIv_convert_h8_to_i16_all_vb:
  case TPC::BIv_convert_f8_to_u16_all_b:
  case TPC::BIv_convert_f8_to_u16_all_vb:
  case TPC::BIv_convert_h8_to_u16_all_b:
  case TPC::BIv_convert_h8_to_u16_all_vb:
  case TPC::BIv_convert_i32_to_f8_all_b:
  case TPC::BIv_convert_i32_to_f8_all_vb:
  case TPC::BIv_convert_i32_to_h8_all_b:
  case TPC::BIv_convert_i32_to_h8_all_vb:
  case TPC::BIv_convert_u32_to_f8_all_b:
  case TPC::BIv_convert_u32_to_f8_all_vb:
  case TPC::BIv_convert_u32_to_h8_all_b:
  case TPC::BIv_convert_u32_to_h8_all_vb:
  case TPC::BIv_convert_i16_to_f8_all_b:
  case TPC::BIv_convert_i16_to_f8_all_vb:
  case TPC::BIv_convert_i16_to_h8_all_b:
  case TPC::BIv_convert_i16_to_h8_all_vb:
  case TPC::BIv_convert_u16_to_f8_all_b:
  case TPC::BIv_convert_u16_to_f8_all_vb:
  case TPC::BIv_convert_u16_to_h8_all_b:
  case TPC::BIv_convert_u16_to_h8_all_vb:
    return emit_CONVERT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_mul:
  case TPC::BIs_i32_mul:
  case TPC::BIs_u32_mul:
  case TPC::BIs_i16_mul:
  case TPC::BIs_u16_mul:
  case TPC::BIs_i8_mul:
  case TPC::BIs_u8_mul:
  case TPC::BIs_bf16_mul:
  case TPC::BIs_f16_mul:
  case TPC::BIs_bf16_mul_acc32:
  case TPC::BIs_f16_mul_acc32:
  case TPC::BIs_f8_mul_acc32:
  case TPC::BIs_h8_mul_acc32:
  case TPC::BIi_i32_mul:
  case TPC::BIv_f32_mul_vb:
  case TPC::BIv_f32_mul_b:
  case TPC::BIv_bf16_mul_vb:
  case TPC::BIv_bf16_mul_b:
  case TPC::BIv_f16_mul_vb:
  case TPC::BIv_f16_mul_b:
  case TPC::BIv_i32_mul_vb:
  case TPC::BIv_i32_mul_b:
  case TPC::BIv_u32_mul_vb:
  case TPC::BIv_u32_mul_b:
  case TPC::BIv_i16_mul_vb:
  case TPC::BIv_i16_mul_b:
  case TPC::BIv_u16_mul_vb:
  case TPC::BIv_u16_mul_b:
  case TPC::BIv_i8_mul_vb:
  case TPC::BIv_i8_mul_b:
  case TPC::BIv_u8_mul_vb:
  case TPC::BIv_u8_mul_b:
  case TPC::BIv_bf16_mul_acc32_vb:
  case TPC::BIv_bf16_mul_acc32_b:
  case TPC::BIv_f16_mul_acc32_vb:
  case TPC::BIv_f16_mul_acc32_b:
  case TPC::BIv_f8_mul_acc32_vb:
  case TPC::BIv_f8_mul_acc32_b:
  case TPC::BIv_h8_mul_acc32_vb:
  case TPC::BIv_h8_mul_acc32_b:
  case TPC::BIv_i32_mul_round_vb:
  case TPC::BIv_i32_mul_round_b:
  case TPC::BIv_u32_mul_round_vb:
  case TPC::BIv_u32_mul_round_b:
  case TPC::BIv_f32_mul_x2_vb:
  case TPC::BIv_f32_mul_x2_b:
  case TPC::BIv_f32_mul_x2_svv_vb:
  case TPC::BIv_f32_mul_x2_svv_b:
    return emit_MUL(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_add:
  case TPC::BIs_i32_add:
  case TPC::BIs_u32_add:
  case TPC::BIs_i16_add:
  case TPC::BIs_u16_add:
  case TPC::BIs_i8_add:
  case TPC::BIs_u8_add:
  case TPC::BIs_bf16_add:
  case TPC::BIs_f16_add:
  case TPC::BIs_f8_add:
  case TPC::BIs_h8_add:
  case TPC::BIi_i32_add:
  case TPC::BIv_f32_add_vb:
  case TPC::BIv_f32_add_b:
  case TPC::BIv_bf16_add_vb:
  case TPC::BIv_bf16_add_b:
  case TPC::BIv_f16_add_vb:
  case TPC::BIv_f16_add_b:
  case TPC::BIv_f8_add_vb:
  case TPC::BIv_f8_add_b:
  case TPC::BIv_h8_add_vb:
  case TPC::BIv_h8_add_b:
  case TPC::BIv_i32_add_vb:
  case TPC::BIv_i32_add_b:
  case TPC::BIv_u32_add_vb:
  case TPC::BIv_u32_add_b:
  case TPC::BIv_i16_add_vb:
  case TPC::BIv_i16_add_b:
  case TPC::BIv_u16_add_vb:
  case TPC::BIv_u16_add_b:
  case TPC::BIv_i8_add_vb:
  case TPC::BIv_i8_add_b:
  case TPC::BIv_u8_add_vb:
  case TPC::BIv_u8_add_b:
  case TPC::BIv_f32_add_x2_vb:
  case TPC::BIv_f32_add_x2_b:
    return emit_ADD(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_sub:
  case TPC::BIs_i32_sub:
  case TPC::BIs_u32_sub:
  case TPC::BIs_i16_sub:
  case TPC::BIs_u16_sub:
  case TPC::BIs_i8_sub:
  case TPC::BIs_u8_sub:
  case TPC::BIs_bf16_sub:
  case TPC::BIs_f16_sub:
  case TPC::BIs_f8_sub:
  case TPC::BIs_h8_sub:
  case TPC::BIi_i32_sub:
  case TPC::BIv_f32_sub_vb:
  case TPC::BIv_f32_sub_b:
  case TPC::BIv_bf16_sub_vb:
  case TPC::BIv_bf16_sub_b:
  case TPC::BIv_f16_sub_vb:
  case TPC::BIv_f16_sub_b:
  case TPC::BIv_f8_sub_vb:
  case TPC::BIv_f8_sub_b:
  case TPC::BIv_h8_sub_vb:
  case TPC::BIv_h8_sub_b:
  case TPC::BIv_i32_sub_vb:
  case TPC::BIv_i32_sub_b:
  case TPC::BIv_u32_sub_vb:
  case TPC::BIv_u32_sub_b:
  case TPC::BIv_i16_sub_vb:
  case TPC::BIv_i16_sub_b:
  case TPC::BIv_u16_sub_vb:
  case TPC::BIv_u16_sub_b:
  case TPC::BIv_i8_sub_vb:
  case TPC::BIv_i8_sub_b:
  case TPC::BIv_u8_sub_vb:
  case TPC::BIv_u8_sub_b:
  case TPC::BIv_f32_sub_x2_vb:
  case TPC::BIv_f32_sub_x2_b:
    return emit_SUB(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_max:
  case TPC::BIs_i32_max:
  case TPC::BIs_u32_max:
  case TPC::BIs_i16_max:
  case TPC::BIs_u16_max:
  case TPC::BIs_i8_max:
  case TPC::BIs_u8_max:
  case TPC::BIs_bf16_max:
  case TPC::BIs_f16_max:
  case TPC::BIs_f8_max:
  case TPC::BIs_h8_max:
  case TPC::BIi_i32_max:
  case TPC::BIv_f32_max_vb:
  case TPC::BIv_f32_max_b:
  case TPC::BIv_bf16_max_vb:
  case TPC::BIv_bf16_max_b:
  case TPC::BIv_f16_max_vb:
  case TPC::BIv_f16_max_b:
  case TPC::BIv_f8_max_vb:
  case TPC::BIv_f8_max_b:
  case TPC::BIv_h8_max_vb:
  case TPC::BIv_h8_max_b:
  case TPC::BIv_i32_max_vb:
  case TPC::BIv_i32_max_b:
  case TPC::BIv_u32_max_vb:
  case TPC::BIv_u32_max_b:
  case TPC::BIv_i16_max_vb:
  case TPC::BIv_i16_max_b:
  case TPC::BIv_u16_max_vb:
  case TPC::BIv_u16_max_b:
  case TPC::BIv_i8_max_vb:
  case TPC::BIv_i8_max_b:
  case TPC::BIv_u8_max_vb:
  case TPC::BIv_u8_max_b:
    return emit_MAX(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_min:
  case TPC::BIs_i32_min:
  case TPC::BIs_u32_min:
  case TPC::BIs_i16_min:
  case TPC::BIs_u16_min:
  case TPC::BIs_i8_min:
  case TPC::BIs_u8_min:
  case TPC::BIs_bf16_min:
  case TPC::BIs_f16_min:
  case TPC::BIs_f8_min:
  case TPC::BIs_h8_min:
  case TPC::BIi_i32_min:
  case TPC::BIv_f32_min_vb:
  case TPC::BIv_f32_min_b:
  case TPC::BIv_bf16_min_vb:
  case TPC::BIv_bf16_min_b:
  case TPC::BIv_f16_min_vb:
  case TPC::BIv_f16_min_b:
  case TPC::BIv_f8_min_vb:
  case TPC::BIv_f8_min_b:
  case TPC::BIv_h8_min_vb:
  case TPC::BIv_h8_min_b:
  case TPC::BIv_i32_min_vb:
  case TPC::BIv_i32_min_b:
  case TPC::BIv_u32_min_vb:
  case TPC::BIv_u32_min_b:
  case TPC::BIv_i16_min_vb:
  case TPC::BIv_i16_min_b:
  case TPC::BIv_u16_min_vb:
  case TPC::BIv_u16_min_b:
  case TPC::BIv_i8_min_vb:
  case TPC::BIv_i8_min_b:
  case TPC::BIv_u8_min_vb:
  case TPC::BIv_u8_min_b:
    return emit_MIN(CGF, BuiltinID, E, ReturnValue, Arch);


  case TPC::BIs_f32_not:
  case TPC::BIs_bf16_not:
  case TPC::BIs_f16_not:
  case TPC::BIs_f8_not:
  case TPC::BIs_h8_not:
  case TPC::BIs_i32_not:
  case TPC::BIs_u32_not:
  case TPC::BIs_i16_not:
  case TPC::BIs_u16_not:
  case TPC::BIs_i8_not:
  case TPC::BIs_u8_not:
  case TPC::BIs_i1_not:
  case TPC::BIi_i32_not:
  case TPC::BIv_f32_not_b:
  case TPC::BIv_f32_not_vb:
  case TPC::BIv_bf16_not_b:
  case TPC::BIv_bf16_not_vb:
  case TPC::BIv_f16_not_b:
  case TPC::BIv_f16_not_vb:
  case TPC::BIv_f8_not_b:
  case TPC::BIv_f8_not_vb:
  case TPC::BIv_h8_not_b:
  case TPC::BIv_h8_not_vb:
  case TPC::BIv_i32_not_b:
  case TPC::BIv_i32_not_vb:
  case TPC::BIv_u32_not_b:
  case TPC::BIv_u32_not_vb:
  case TPC::BIv_i16_not_b:
  case TPC::BIv_i16_not_vb:
  case TPC::BIv_u16_not_b:
  case TPC::BIv_u16_not_vb:
  case TPC::BIv_i8_not_b:
  case TPC::BIv_i8_not_vb:
  case TPC::BIv_u8_not_b:
  case TPC::BIv_u8_not_vb:
  case TPC::BIv_i1_not_b:
  case TPC::BIv_i1_not_vb:
    return emit_NOT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_shr:
  case TPC::BIs_bf16_shr:
  case TPC::BIs_f16_shr:
  case TPC::BIs_f8_shr:
  case TPC::BIs_h8_shr:
  case TPC::BIs_i32_shr:
  case TPC::BIs_u32_shr:
  case TPC::BIs_i16_shr:
  case TPC::BIs_u16_shr:
  case TPC::BIs_i8_shr:
  case TPC::BIs_u8_shr:
  case TPC::BIi_i32_shr:
  case TPC::BIv_f32_shr_b:
  case TPC::BIv_f32_shr_vb:
  case TPC::BIv_bf16_shr_b:
  case TPC::BIv_bf16_shr_vb:
  case TPC::BIv_f16_shr_b:
  case TPC::BIv_f16_shr_vb:
  case TPC::BIv_f8_shr_b:
  case TPC::BIv_f8_shr_vb:
  case TPC::BIv_h8_shr_b:
  case TPC::BIv_h8_shr_vb:
  case TPC::BIv_i32_shr_b:
  case TPC::BIv_i32_shr_vb:
  case TPC::BIv_u32_shr_b:
  case TPC::BIv_u32_shr_vb:
  case TPC::BIv_i16_shr_b:
  case TPC::BIv_i16_shr_vb:
  case TPC::BIv_u16_shr_b:
  case TPC::BIv_u16_shr_vb:
  case TPC::BIv_i8_shr_b:
  case TPC::BIv_i8_shr_vb:
  case TPC::BIv_u8_shr_b:
  case TPC::BIv_u8_shr_vb:
    return emit_SHR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_shl:
  case TPC::BIs_bf16_shl:
  case TPC::BIs_f16_shl:
  case TPC::BIs_f8_shl:
  case TPC::BIs_h8_shl:
  case TPC::BIs_i32_shl:
  case TPC::BIs_u32_shl:
  case TPC::BIs_i16_shl:
  case TPC::BIs_u16_shl:
  case TPC::BIs_i8_shl:
  case TPC::BIs_u8_shl:
  case TPC::BIi_i32_shl:
  case TPC::BIv_f32_shl_b:
  case TPC::BIv_f32_shl_vb:
  case TPC::BIv_bf16_shl_b:
  case TPC::BIv_bf16_shl_vb:
  case TPC::BIv_f16_shl_b:
  case TPC::BIv_f16_shl_vb:
  case TPC::BIv_f8_shl_b:
  case TPC::BIv_f8_shl_vb:
  case TPC::BIv_h8_shl_b:
  case TPC::BIv_h8_shl_vb:
  case TPC::BIv_i32_shl_b:
  case TPC::BIv_i32_shl_vb:
  case TPC::BIv_u32_shl_b:
  case TPC::BIv_u32_shl_vb:
  case TPC::BIv_i16_shl_b:
  case TPC::BIv_i16_shl_vb:
  case TPC::BIv_u16_shl_b:
  case TPC::BIv_u16_shl_vb:
  case TPC::BIv_i8_shl_b:
  case TPC::BIv_i8_shl_vb:
  case TPC::BIv_u8_shl_b:
  case TPC::BIv_u8_shl_vb:
    return emit_SHL(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_i32_ash:
  case TPC::BIs_u32_ash:
  case TPC::BIs_i16_ash:
  case TPC::BIs_u16_ash:
  case TPC::BIs_i8_ash:
  case TPC::BIs_u8_ash:
  case TPC::BIv_i32_ash_b:
  case TPC::BIv_i32_ash_vb:
  case TPC::BIv_u32_ash_b:
  case TPC::BIv_u32_ash_vb:
  case TPC::BIv_i16_ash_b:
  case TPC::BIv_i16_ash_vb:
  case TPC::BIv_u16_ash_b:
  case TPC::BIv_u16_ash_vb:
  case TPC::BIv_i8_ash_b:
  case TPC::BIv_i8_ash_vb:
  case TPC::BIv_u8_ash_b:
  case TPC::BIv_u8_ash_vb:
  case TPC::BIv_i32_ash_rhaz_b:
  case TPC::BIv_i32_ash_rhaz_vb:
  case TPC::BIv_u32_ash_rhaz_b:
  case TPC::BIv_u32_ash_rhaz_vb:
    return emit_ASH(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_abs:
  case TPC::BIs_bf16_abs:
  case TPC::BIs_f16_abs:
  case TPC::BIs_f8_abs:
  case TPC::BIs_h8_abs:
  case TPC::BIs_i32_abs:
  case TPC::BIs_i16_abs:
  case TPC::BIs_i8_abs:
  case TPC::BIi_i32_abs:
  case TPC::BIv_f32_abs_b:
  case TPC::BIv_f32_abs_vb:
  case TPC::BIv_bf16_abs_b:
  case TPC::BIv_bf16_abs_vb:
  case TPC::BIv_f16_abs_b:
  case TPC::BIv_f16_abs_vb:

  case TPC::BIv_f8_abs_b:
  case TPC::BIv_f8_abs_vb:
  case TPC::BIv_h8_abs_b:
  case TPC::BIv_h8_abs_vb:

  case TPC::BIv_i32_abs_b:
  case TPC::BIv_i32_abs_vb:
  case TPC::BIv_i16_abs_b:
  case TPC::BIv_i16_abs_vb:
  case TPC::BIv_i8_abs_b:
  case TPC::BIv_i8_abs_vb:
    return emit_ABS(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_and:
  case TPC::BIs_i32_and:
  case TPC::BIs_u32_and:
  case TPC::BIs_i16_and:
  case TPC::BIs_u16_and:
  case TPC::BIs_i8_and:
  case TPC::BIs_u8_and:
  case TPC::BIs_bf16_and:
  case TPC::BIs_f16_and:
  case TPC::BIs_f8_and:
  case TPC::BIs_h8_and:
  case TPC::BIi_i32_and:
  case TPC::BIv_f32_and_vb:
  case TPC::BIv_f32_and_b:
  case TPC::BIv_bf16_and_vb:
  case TPC::BIv_bf16_and_b:
  case TPC::BIv_f16_and_vb:
  case TPC::BIv_f16_and_b:
  case TPC::BIv_f8_and_vb:
  case TPC::BIv_f8_and_b:
  case TPC::BIv_h8_and_vb:
  case TPC::BIv_h8_and_b:
  case TPC::BIv_i32_and_vb:
  case TPC::BIv_i32_and_b:
  case TPC::BIv_u32_and_vb:
  case TPC::BIv_u32_and_b:
  case TPC::BIv_i16_and_vb:
  case TPC::BIv_i16_and_b:
  case TPC::BIv_u16_and_vb:
  case TPC::BIv_u16_and_b:
  case TPC::BIv_i8_and_vb:
  case TPC::BIv_i8_and_b:
  case TPC::BIv_u8_and_vb:
  case TPC::BIv_u8_and_b:
  case TPC::BIs_i1_and:
  case TPC::BIv_i1_and_b:
  case TPC::BIv_i1_and_vb:
    return emit_AND(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_or:
  case TPC::BIs_i32_or:
  case TPC::BIs_u32_or:
  case TPC::BIs_i16_or:
  case TPC::BIs_u16_or:
  case TPC::BIs_i8_or:
  case TPC::BIs_u8_or:
  case TPC::BIs_bf16_or:
  case TPC::BIs_f16_or:
  case TPC::BIs_f8_or:
  case TPC::BIs_h8_or:
  case TPC::BIi_i32_or:
  case TPC::BIv_f32_or_vb:
  case TPC::BIv_f32_or_b:
  case TPC::BIv_bf16_or_vb:
  case TPC::BIv_bf16_or_b:
  case TPC::BIv_f16_or_vb:
  case TPC::BIv_f16_or_b:
  case TPC::BIv_f8_or_vb:
  case TPC::BIv_f8_or_b:
  case TPC::BIv_h8_or_vb:
  case TPC::BIv_h8_or_b:
  case TPC::BIv_i32_or_vb:
  case TPC::BIv_i32_or_b:
  case TPC::BIv_u32_or_vb:
  case TPC::BIv_u32_or_b:
  case TPC::BIv_i16_or_vb:
  case TPC::BIv_i16_or_b:
  case TPC::BIv_u16_or_vb:
  case TPC::BIv_u16_or_b:
  case TPC::BIv_i8_or_vb:
  case TPC::BIv_i8_or_b:
  case TPC::BIv_u8_or_vb:
  case TPC::BIv_u8_or_b:
  case TPC::BIs_i1_or:
  case TPC::BIv_i1_or_b:
  case TPC::BIv_i1_or_vb:
    return emit_OR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_xor:
  case TPC::BIs_i32_xor:
  case TPC::BIs_u32_xor:
  case TPC::BIs_i16_xor:
  case TPC::BIs_u16_xor:
  case TPC::BIs_i8_xor:
  case TPC::BIs_u8_xor:
  case TPC::BIs_bf16_xor:
  case TPC::BIs_f16_xor:
  case TPC::BIs_f8_xor:
  case TPC::BIs_h8_xor:
  case TPC::BIi_i32_xor:
  case TPC::BIv_f32_xor_vb:
  case TPC::BIv_f32_xor_b:
  case TPC::BIv_bf16_xor_vb:
  case TPC::BIv_bf16_xor_b:
  case TPC::BIv_f16_xor_vb:
  case TPC::BIv_f16_xor_b:
  case TPC::BIv_f8_xor_vb:
  case TPC::BIv_f8_xor_b:
  case TPC::BIv_h8_xor_vb:
  case TPC::BIv_h8_xor_b:
  case TPC::BIv_i32_xor_vb:
  case TPC::BIv_i32_xor_b:
  case TPC::BIv_u32_xor_vb:
  case TPC::BIv_u32_xor_b:
  case TPC::BIv_i16_xor_vb:
  case TPC::BIv_i16_xor_b:
  case TPC::BIv_u16_xor_vb:
  case TPC::BIv_u16_xor_b:
  case TPC::BIv_i8_xor_vb:
  case TPC::BIv_i8_xor_b:
  case TPC::BIv_u8_xor_vb:
  case TPC::BIv_u8_xor_b:
  case TPC::BIs_i1_xor:
  case TPC::BIv_i1_xor_b:
  case TPC::BIv_i1_xor_vb:
    return emit_XOR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_cmp_eq:
  case TPC::BIs_bf16_cmp_eq:
  case TPC::BIs_f16_cmp_eq:
  case TPC::BIs_f8_cmp_eq:
  case TPC::BIs_h8_cmp_eq:
  case TPC::BIs_i32_x2_cmp_eq:
  case TPC::BIs_u32_x2_cmp_eq:
  case TPC::BIs_i32_cmp_eq:
  case TPC::BIs_u32_cmp_eq:
  case TPC::BIs_i16_cmp_eq:
  case TPC::BIs_u16_cmp_eq:
  case TPC::BIs_i8_cmp_eq:
  case TPC::BIs_u8_cmp_eq:
  case TPC::BIv_f32_cmp_eq_vb:
  case TPC::BIv_bf16_cmp_eq_vb:
  case TPC::BIv_f16_cmp_eq_vb:
  case TPC::BIv_f8_cmp_eq_vb:
  case TPC::BIv_h8_cmp_eq_vb:
  case TPC::BIv_i32_cmp_eq_vb:
  case TPC::BIv_u32_cmp_eq_vb:
  case TPC::BIv_i16_cmp_eq_vb:
  case TPC::BIv_u16_cmp_eq_vb:
  case TPC::BIv_i8_cmp_eq_vb:
  case TPC::BIv_u8_cmp_eq_vb:
  case TPC::BIv_f32_cmp_eq_b:
  case TPC::BIv_bf16_cmp_eq_b:
  case TPC::BIv_f16_cmp_eq_b:
  case TPC::BIv_f8_cmp_eq_b:
  case TPC::BIv_h8_cmp_eq_b:
  case TPC::BIv_i32_cmp_eq_b:
  case TPC::BIv_u32_cmp_eq_b:
  case TPC::BIv_i16_cmp_eq_b:
  case TPC::BIv_u16_cmp_eq_b:
  case TPC::BIv_i8_cmp_eq_b:
  case TPC::BIv_u8_cmp_eq_b:
    return emit_CMP_EQ(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_cmp_neq:
  case TPC::BIs_bf16_cmp_neq:
  case TPC::BIs_f16_cmp_neq:
  case TPC::BIs_f8_cmp_neq:
  case TPC::BIs_h8_cmp_neq:
  case TPC::BIs_i32_x2_cmp_neq:
  case TPC::BIs_u32_x2_cmp_neq:
  case TPC::BIs_i32_cmp_neq:
  case TPC::BIs_u32_cmp_neq:
  case TPC::BIs_i16_cmp_neq:
  case TPC::BIs_u16_cmp_neq:
  case TPC::BIs_i8_cmp_neq:
  case TPC::BIs_u8_cmp_neq:
  case TPC::BIv_f32_cmp_neq_vb:
  case TPC::BIv_bf16_cmp_neq_vb:
  case TPC::BIv_f16_cmp_neq_vb:
  case TPC::BIv_f8_cmp_neq_vb:
  case TPC::BIv_h8_cmp_neq_vb:
  case TPC::BIv_i32_cmp_neq_vb:
  case TPC::BIv_u32_cmp_neq_vb:
  case TPC::BIv_i16_cmp_neq_vb:
  case TPC::BIv_u16_cmp_neq_vb:
  case TPC::BIv_i8_cmp_neq_vb:
  case TPC::BIv_u8_cmp_neq_vb:
  case TPC::BIv_f32_cmp_neq_b:
  case TPC::BIv_bf16_cmp_neq_b:
  case TPC::BIv_f16_cmp_neq_b:
  case TPC::BIv_f8_cmp_neq_b:
  case TPC::BIv_h8_cmp_neq_b:
  case TPC::BIv_i32_cmp_neq_b:
  case TPC::BIv_u32_cmp_neq_b:
  case TPC::BIv_i16_cmp_neq_b:
  case TPC::BIv_u16_cmp_neq_b:
  case TPC::BIv_i8_cmp_neq_b:
  case TPC::BIv_u8_cmp_neq_b:
    return emit_CMP_NEQ(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_cmp_less:
  case TPC::BIs_bf16_cmp_less:
  case TPC::BIs_f16_cmp_less:
  case TPC::BIs_f8_cmp_less:
  case TPC::BIs_h8_cmp_less:
  case TPC::BIs_i32_x2_cmp_less:
  case TPC::BIs_u32_x2_cmp_less:
  case TPC::BIs_i32_cmp_less:
  case TPC::BIs_u32_cmp_less:
  case TPC::BIs_i16_cmp_less:
  case TPC::BIs_u16_cmp_less:
  case TPC::BIs_i8_cmp_less:
  case TPC::BIs_u8_cmp_less:
  case TPC::BIv_f32_cmp_less_vb:
  case TPC::BIv_bf16_cmp_less_vb:
  case TPC::BIv_f16_cmp_less_vb:
  case TPC::BIv_f8_cmp_less_vb:
  case TPC::BIv_h8_cmp_less_vb:
  case TPC::BIv_i32_cmp_less_vb:
  case TPC::BIv_u32_cmp_less_vb:
  case TPC::BIv_i16_cmp_less_vb:
  case TPC::BIv_u16_cmp_less_vb:
  case TPC::BIv_i8_cmp_less_vb:
  case TPC::BIv_u8_cmp_less_vb:
  case TPC::BIv_f32_cmp_less_b:
  case TPC::BIv_bf16_cmp_less_b:
  case TPC::BIv_f16_cmp_less_b:
  case TPC::BIv_f8_cmp_less_b:
  case TPC::BIv_h8_cmp_less_b:
  case TPC::BIv_i32_cmp_less_b:
  case TPC::BIv_u32_cmp_less_b:
  case TPC::BIv_i16_cmp_less_b:
  case TPC::BIv_u16_cmp_less_b:
  case TPC::BIv_i8_cmp_less_b:
  case TPC::BIv_u8_cmp_less_b:
    return emit_CMP_LESS(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_cmp_leq:
  case TPC::BIs_bf16_cmp_leq:
  case TPC::BIs_f16_cmp_leq:
  case TPC::BIs_f8_cmp_leq:
  case TPC::BIs_h8_cmp_leq:
  case TPC::BIs_i32_x2_cmp_leq:
  case TPC::BIs_u32_x2_cmp_leq:
  case TPC::BIs_i32_cmp_leq:
  case TPC::BIs_u32_cmp_leq:
  case TPC::BIs_i16_cmp_leq:
  case TPC::BIs_u16_cmp_leq:
  case TPC::BIs_i8_cmp_leq:
  case TPC::BIs_u8_cmp_leq:
  case TPC::BIv_f32_cmp_leq_vb:
  case TPC::BIv_bf16_cmp_leq_vb:
  case TPC::BIv_f16_cmp_leq_vb:
  case TPC::BIv_f8_cmp_leq_vb:
  case TPC::BIv_h8_cmp_leq_vb:
  case TPC::BIv_i32_cmp_leq_vb:
  case TPC::BIv_u32_cmp_leq_vb:
  case TPC::BIv_i16_cmp_leq_vb:
  case TPC::BIv_u16_cmp_leq_vb:
  case TPC::BIv_i8_cmp_leq_vb:
  case TPC::BIv_u8_cmp_leq_vb:
  case TPC::BIv_f32_cmp_leq_b:
  case TPC::BIv_bf16_cmp_leq_b:
  case TPC::BIv_f16_cmp_leq_b:
  case TPC::BIv_f8_cmp_leq_b:
  case TPC::BIv_h8_cmp_leq_b:
  case TPC::BIv_i32_cmp_leq_b:
  case TPC::BIv_u32_cmp_leq_b:
  case TPC::BIv_i16_cmp_leq_b:
  case TPC::BIv_u16_cmp_leq_b:
  case TPC::BIv_i8_cmp_leq_b:
  case TPC::BIv_u8_cmp_leq_b:
    return emit_CMP_LEQ(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_cmp_grt:
  case TPC::BIs_bf16_cmp_grt:
  case TPC::BIs_f16_cmp_grt:
  case TPC::BIs_f8_cmp_grt:
  case TPC::BIs_h8_cmp_grt:
  case TPC::BIs_i32_x2_cmp_grt:
  case TPC::BIs_u32_x2_cmp_grt:
  case TPC::BIs_i32_cmp_grt:
  case TPC::BIs_u32_cmp_grt:
  case TPC::BIs_i16_cmp_grt:
  case TPC::BIs_u16_cmp_grt:
  case TPC::BIs_i8_cmp_grt:
  case TPC::BIs_u8_cmp_grt:
  case TPC::BIv_f32_cmp_grt_vb:
  case TPC::BIv_bf16_cmp_grt_vb:
  case TPC::BIv_f16_cmp_grt_vb:
  case TPC::BIv_f8_cmp_grt_vb:
  case TPC::BIv_h8_cmp_grt_vb:
  case TPC::BIv_i32_cmp_grt_vb:
  case TPC::BIv_u32_cmp_grt_vb:
  case TPC::BIv_i16_cmp_grt_vb:
  case TPC::BIv_u16_cmp_grt_vb:
  case TPC::BIv_i8_cmp_grt_vb:
  case TPC::BIv_u8_cmp_grt_vb:
  case TPC::BIv_f32_cmp_grt_b:
  case TPC::BIv_bf16_cmp_grt_b:
  case TPC::BIv_f16_cmp_grt_b:
  case TPC::BIv_f8_cmp_grt_b:
  case TPC::BIv_h8_cmp_grt_b:
  case TPC::BIv_i32_cmp_grt_b:
  case TPC::BIv_u32_cmp_grt_b:
  case TPC::BIv_i16_cmp_grt_b:
  case TPC::BIv_u16_cmp_grt_b:
  case TPC::BIv_i8_cmp_grt_b:
  case TPC::BIv_u8_cmp_grt_b:
    return emit_CMP_GRT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_cmp_geq:
  case TPC::BIs_bf16_cmp_geq:
  case TPC::BIs_f16_cmp_geq:
  case TPC::BIs_f8_cmp_geq:
  case TPC::BIs_h8_cmp_geq:
  case TPC::BIs_i32_x2_cmp_geq:
  case TPC::BIs_u32_x2_cmp_geq:
  case TPC::BIs_i32_cmp_geq:
  case TPC::BIs_u32_cmp_geq:
  case TPC::BIs_i16_cmp_geq:
  case TPC::BIs_u16_cmp_geq:
  case TPC::BIs_i8_cmp_geq:
  case TPC::BIs_u8_cmp_geq:
  case TPC::BIv_f32_cmp_geq_vb:
  case TPC::BIv_bf16_cmp_geq_vb:
  case TPC::BIv_f16_cmp_geq_vb:
  case TPC::BIv_f8_cmp_geq_vb:
  case TPC::BIv_h8_cmp_geq_vb:
  case TPC::BIv_i32_cmp_geq_vb:
  case TPC::BIv_u32_cmp_geq_vb:
  case TPC::BIv_i16_cmp_geq_vb:
  case TPC::BIv_u16_cmp_geq_vb:
  case TPC::BIv_i8_cmp_geq_vb:
  case TPC::BIv_u8_cmp_geq_vb:
  case TPC::BIv_f32_cmp_geq_b:
  case TPC::BIv_bf16_cmp_geq_b:
  case TPC::BIv_f16_cmp_geq_b:
  case TPC::BIv_f8_cmp_geq_b:
  case TPC::BIv_h8_cmp_geq_b:
  case TPC::BIv_i32_cmp_geq_b:
  case TPC::BIv_u32_cmp_geq_b:
  case TPC::BIv_i16_cmp_geq_b:
  case TPC::BIv_u16_cmp_geq_b:
  case TPC::BIv_i8_cmp_geq_b:
  case TPC::BIv_u8_cmp_geq_b:
    return emit_CMP_GEQ(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIevent:
    return emit_EVENT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_popcnt:
  case TPC::BIs_bf16_popcnt:
  case TPC::BIs_f16_popcnt:
  case TPC::BIs_f8_popcnt:
  case TPC::BIs_h8_popcnt:
  case TPC::BIs_i32_popcnt:
  case TPC::BIs_u32_popcnt:
  case TPC::BIs_i16_popcnt:
  case TPC::BIs_u16_popcnt:
  case TPC::BIs_i8_popcnt:
  case TPC::BIs_u8_popcnt:
  case TPC::BIv_f32_popcnt_b:
  case TPC::BIv_f32_popcnt_vb:
  case TPC::BIv_bf16_popcnt_b:
  case TPC::BIv_bf16_popcnt_vb:
  case TPC::BIv_f16_popcnt_b:
  case TPC::BIv_f16_popcnt_vb:
  case TPC::BIv_f8_popcnt_b:
  case TPC::BIv_f8_popcnt_vb:
  case TPC::BIv_h8_popcnt_b:
  case TPC::BIv_h8_popcnt_vb:
  case TPC::BIv_i32_popcnt_b:
  case TPC::BIv_i32_popcnt_vb:
  case TPC::BIv_u32_popcnt_b:
  case TPC::BIv_u32_popcnt_vb:
  case TPC::BIv_i16_popcnt_b:
  case TPC::BIv_i16_popcnt_vb:
  case TPC::BIv_u16_popcnt_b:
  case TPC::BIv_u16_popcnt_vb:
  case TPC::BIv_i8_popcnt_b:
  case TPC::BIv_i8_popcnt_vb:
  case TPC::BIv_u8_popcnt_b:
  case TPC::BIv_u8_popcnt_vb:
    return emit_POPCNT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_find_first:
  case TPC::BIs_bf16_find_first:
  case TPC::BIs_f16_find_first:
  case TPC::BIs_f8_find_first:
  case TPC::BIs_h8_find_first:
  case TPC::BIs_i32_find_first:
  case TPC::BIs_u32_find_first:
  case TPC::BIs_i16_find_first:
  case TPC::BIs_u16_find_first:
  case TPC::BIs_i8_find_first:
  case TPC::BIs_u8_find_first:
  case TPC::BIv_f32_find_first_b:
  case TPC::BIv_f32_find_first_vb:
  case TPC::BIv_bf16_find_first_b:
  case TPC::BIv_bf16_find_first_vb:
  case TPC::BIv_f16_find_first_b:
  case TPC::BIv_f16_find_first_vb:
   case TPC::BIv_f8_find_first_b:
  case TPC::BIv_f8_find_first_vb:
  case TPC::BIv_h8_find_first_b:
  case TPC::BIv_h8_find_first_vb:
  case TPC::BIv_i32_find_first_b:
  case TPC::BIv_i32_find_first_vb:
  case TPC::BIv_u32_find_first_b:
  case TPC::BIv_u32_find_first_vb:
  case TPC::BIv_i16_find_first_b:
  case TPC::BIv_i16_find_first_vb:
  case TPC::BIv_u16_find_first_b:
  case TPC::BIv_u16_find_first_vb:
  case TPC::BIv_i8_find_first_b:
  case TPC::BIv_i8_find_first_vb:
  case TPC::BIv_u8_find_first_b:
  case TPC::BIv_u8_find_first_vb:
    return emit_FIND_FIRST(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_nearbyint:
  case TPC::BIs_bf16_nearbyint:
  case TPC::BIs_f16_nearbyint:
  case TPC::BIs_f8_nearbyint:
  case TPC::BIs_h8_nearbyint:
  case TPC::BIv_f32_nearbyint_b:
  case TPC::BIv_f32_nearbyint_vb:
  case TPC::BIv_bf16_nearbyint_b:
  case TPC::BIv_bf16_nearbyint_vb:
  case TPC::BIv_f16_nearbyint_b:
  case TPC::BIv_f16_nearbyint_vb:
  case TPC::BIv_f8_nearbyint_b:
  case TPC::BIv_f8_nearbyint_vb:
  case TPC::BIv_h8_nearbyint_b:
  case TPC::BIv_h8_nearbyint_vb:
  case TPC::BIv_f32_nearbyint_cnvrt_b:
  case TPC::BIv_f32_nearbyint_cnvrt_vb:
  case TPC::BIv_bf16_nearbyint_cnvrt_b:
  case TPC::BIv_bf16_nearbyint_cnvrt_vb:
  case TPC::BIv_f16_nearbyint_cnvrt_b:
  case TPC::BIv_f16_nearbyint_cnvrt_vb:
  case TPC::BIv_f8_nearbyint_cnvrt_b:
  case TPC::BIv_f8_nearbyint_cnvrt_vb:
  case TPC::BIv_h8_nearbyint_cnvrt_b:
  case TPC::BIv_h8_nearbyint_cnvrt_vb:
    return emit_NEARBYINT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_extract_exp:
  case TPC::BIs_bf16_extract_exp:
  case TPC::BIs_f16_extract_exp:
  case TPC::BIs_f8_extract_exp:
  case TPC::BIs_h8_extract_exp:
  case TPC::BIv_f32_extract_exp_vb:
  case TPC::BIv_f32_extract_exp_b:
  case TPC::BIv_bf16_extract_exp_vb:
  case TPC::BIv_bf16_extract_exp_b:
  case TPC::BIv_f16_extract_exp_vb:
  case TPC::BIv_f16_extract_exp_b:
  case TPC::BIv_f8_extract_exp_vb:
  case TPC::BIv_f8_extract_exp_b:
  case TPC::BIv_h8_extract_exp_vb:
  case TPC::BIv_h8_extract_exp_b:
      return emit_EXTRACT_EXP(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_fclass:
  case TPC::BIs_bf16_fclass:
  case TPC::BIs_f16_fclass:
  case TPC::BIs_f8_fclass:
  case TPC::BIs_h8_fclass:
  case TPC::BIv_f32_fclass_b:
  case TPC::BIv_bf16_fclass_b:
  case TPC::BIv_f16_fclass_b:
  case TPC::BIv_f8_fclass_b:
  case TPC::BIv_h8_fclass_b:
  case TPC::BIv_f32_fclass_vb:
  case TPC::BIv_bf16_fclass_vb:
  case TPC::BIv_f16_fclass_vb:
  case TPC::BIv_f8_fclass_vb:
  case TPC::BIv_h8_fclass_vb:
  case TPC::BIv_f32_fclass_limit_b:
  case TPC::BIv_f32_fclass_limit_vb:
  case TPC::BIv_bf16_fclass_limit_b:
  case TPC::BIv_bf16_fclass_limit_vb:
  case TPC::BIv_f16_fclass_limit_b:
  case TPC::BIv_f16_fclass_limit_vb:
  case TPC::BIv_f8_fclass_limit_b:
  case TPC::BIv_f8_fclass_limit_vb:
  case TPC::BIv_h8_fclass_limit_b:
  case TPC::BIv_h8_fclass_limit_vb:
    return emit_FCLASS(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_brev:
  case TPC::BIs_bf16_brev:
  case TPC::BIs_f16_brev:
  case TPC::BIs_f8_brev:
  case TPC::BIs_h8_brev:
  case TPC::BIs_i32_brev:
  case TPC::BIs_u32_brev:
  case TPC::BIs_i16_brev:
  case TPC::BIs_u16_brev:
  case TPC::BIs_i8_brev:
  case TPC::BIs_u8_brev:
  case TPC::BIv_f32_brev_b:
  case TPC::BIv_f32_brev_vb:
  case TPC::BIv_bf16_brev_b:
  case TPC::BIv_bf16_brev_vb:
  case TPC::BIv_f16_brev_b:
  case TPC::BIv_f16_brev_vb:
  case TPC::BIv_f8_brev_b:
  case TPC::BIv_f8_brev_vb:
  case TPC::BIv_h8_brev_b:
  case TPC::BIv_h8_brev_vb:
  case TPC::BIv_i32_brev_b:
  case TPC::BIv_i32_brev_vb:
  case TPC::BIv_u32_brev_b:
  case TPC::BIv_u32_brev_vb:
  case TPC::BIv_i16_brev_b:
  case TPC::BIv_i16_brev_vb:
  case TPC::BIv_u16_brev_b:
  case TPC::BIv_u16_brev_vb:
  case TPC::BIv_i8_brev_b:
  case TPC::BIv_i8_brev_vb:
  case TPC::BIv_u8_brev_b:
  case TPC::BIv_u8_brev_vb:
    return emit_BREV(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BImov_irf_dim:
  case TPC::BIlong_irf_dim:
    return emit_MOV_IRF_DIM(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_i1_mov_flavor_b:
  case TPC::BIv_i1_mov_flavor_vb:
    return emit_MOV_FLAVOR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIi_i32_mov:
    return emit_MOV_IRF(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_i1_mov:
  case TPC::BIv_i1_mov_b:
  case TPC::BIv_i1_mov_vb:
  case TPC::BIv_i1_mov_i1_b:
  case TPC::BIv_i1_mov_i1_vb:
  case TPC::BIv_i1_mov_u32_b:
  case TPC::BIv_i1_mov_u32_vb:
  case TPC::BIv_u32_mov_i1_b:
  case TPC::BIv_u32_mov_i1_vb:
  case TPC::BIs_f32_mov:
  case TPC::BIs_bf16_mov:
  case TPC::BIs_f16_mov:
  case TPC::BIs_f8_mov:
  case TPC::BIs_h8_mov:
  case TPC::BIs_i32_mov:
  case TPC::BIs_u32_mov:
  case TPC::BIs_i16_mov:
  case TPC::BIs_u16_mov:
  case TPC::BIs_i8_mov:
  case TPC::BIs_u8_mov:
  case TPC::BIv_f32_mov_vb:
  case TPC::BIv_bf16_mov_vb:
  case TPC::BIv_f16_mov_vb:
  case TPC::BIv_f8_mov_vb:
  case TPC::BIv_h8_mov_vb:
  case TPC::BIv_i32_mov_vb:
  case TPC::BIv_u32_mov_vb:
  case TPC::BIv_i16_mov_vb:
  case TPC::BIv_u16_mov_vb:
  case TPC::BIv_i8_mov_vb:
  case TPC::BIv_u8_mov_vb:
  case TPC::BIv_f32_mov_b:
  case TPC::BIv_bf16_mov_b:
  case TPC::BIv_f16_mov_b:
  case TPC::BIv_f8_mov_b:
  case TPC::BIv_h8_mov_b:
  case TPC::BIv_i32_mov_b:
  case TPC::BIv_u32_mov_b:
  case TPC::BIv_i16_mov_b:
  case TPC::BIv_u16_mov_b:
  case TPC::BIv_i8_mov_b:
  case TPC::BIv_u8_mov_b:
  case TPC::BIv_f32_mov_x2_b:
  case TPC::BIv_f32_mov_x2_vb:
  case TPC::BIv_bf16_mov_x2_b:
  case TPC::BIv_bf16_mov_x2_vb:
  case TPC::BIv_f16_mov_x2_b:
  case TPC::BIv_f16_mov_x2_vb:
  case TPC::BIv_i32_mov_x2_b:
  case TPC::BIv_i32_mov_x2_vb:
  case TPC::BIv_u32_mov_x2_b:
  case TPC::BIv_u32_mov_x2_vb:
  case TPC::BIv_i16_mov_x2_b:
  case TPC::BIv_i16_mov_x2_vb:
  case TPC::BIv_u16_mov_x2_b:
  case TPC::BIv_u16_mov_x2_vb:
  case TPC::BIv_i8_mov_x2_b:
  case TPC::BIv_i8_mov_x2_vb:
  case TPC::BIv_u8_mov_x2_b:
  case TPC::BIv_u8_mov_x2_vb:
  //case TPC::BIv_f8_mov_x2_b:
  case TPC::BIv_f8_mov_x2_vb:
  //case TPC::BIv_h8_mov_x2_b:
  case TPC::BIv_h8_mov_x2_vb:
    return emit_MOV(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIget_addr:
    return emit_GET_ADDR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIupdate_addr:
    return emit_UPDATE_ADDR(CGF, BuiltinID, E, ReturnValue, Arch);
      
  case TPC::BIu32_udiv_step:
  case TPC::BIu16_udiv_step:
  case TPC::BIu8_udiv_step:
  case TPC::BIu32_udiv_4step:
  case TPC::BIu16_udiv_4step:
  case TPC::BIu8_udiv_4step:
    return emit_UDIV_STEP(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIu32_udiv_both:
  case TPC::BIu16_udiv_both:
  case TPC::BIu8_udiv_both:
  case TPC::BIu32_udiv:
  case TPC::BIu16_udiv:
  case TPC::BIu8_udiv:
    return emit_UDIV(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_calc_fp_special:
  case TPC::BIs_bf16_calc_fp_special:
  case TPC::BIs_f16_calc_fp_special:
  case TPC::BIv_f32_calc_fp_special_b:
  case TPC::BIv_f32_calc_fp_special_vb:
  case TPC::BIv_bf16_calc_fp_special_b:
  case TPC::BIv_bf16_calc_fp_special_vb:
  case TPC::BIv_f16_calc_fp_special_b:
  case TPC::BIv_f16_calc_fp_special_vb:
    return emit_CALC_FP_SPECIAL(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIthread_sync:
    return emit_THREAD_SYNC(CGF);

  //------ Vector only instructions --------------------------------------------

  case TPC::BIv_f32_shuffle_b:
  case TPC::BIv_f32_shuffle_vb:
  case TPC::BIv_bf16_shuffle_b:
  case TPC::BIv_bf16_shuffle_vb:
  case TPC::BIv_f16_shuffle_b:
  case TPC::BIv_f16_shuffle_vb:
  case TPC::BIv_i32_shuffle_b:
  case TPC::BIv_i32_shuffle_vb:
  case TPC::BIv_u32_shuffle_b:
  case TPC::BIv_u32_shuffle_vb:
  case TPC::BIv_i16_shuffle_b:
  case TPC::BIv_i16_shuffle_vb:
  case TPC::BIv_u16_shuffle_b:
  case TPC::BIv_u16_shuffle_vb:
  case TPC::BIv_i8_shuffle_b:
  case TPC::BIv_i8_shuffle_vb:
  case TPC::BIv_u8_shuffle_b:
  case TPC::BIv_u8_shuffle_vb:
  case TPC::BIv_f8_shuffle_b:
  case TPC::BIv_f8_shuffle_vb:
  case TPC::BIv_h8_shuffle_b:
  case TPC::BIv_h8_shuffle_vb:
    return emit_SHUFFLE(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_bf16_pack_b:
  case TPC::BIv_bf16_pack_vb:
  case TPC::BIv_f16_pack_b:
  case TPC::BIv_f16_pack_vb:
  case TPC::BIv_f8_pack_b:
  case TPC::BIv_f8_pack_vb:
  case TPC::BIv_h8_pack_b:
  case TPC::BIv_h8_pack_vb:
  case TPC::BIv_i16_pack_b:
  case TPC::BIv_i16_pack_vb:
  case TPC::BIv_u16_pack_b:
  case TPC::BIv_u16_pack_vb:
  case TPC::BIv_i8_pack_b:
  case TPC::BIv_i8_pack_vb:
  case TPC::BIv_u8_pack_b:
  case TPC::BIv_u8_pack_vb:
    return emit_PACK(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_bf16_unpack_b:
  case TPC::BIv_bf16_unpack_vb:
  case TPC::BIv_f16_unpack_b:
  case TPC::BIv_f16_unpack_vb:
  case TPC::BIv_f8_unpack_b:
  case TPC::BIv_f8_unpack_vb:
  case TPC::BIv_h8_unpack_b:
  case TPC::BIv_h8_unpack_vb:
  case TPC::BIv_i16_unpack_b:
  case TPC::BIv_i16_unpack_vb:
  case TPC::BIv_u16_unpack_b:
  case TPC::BIv_u16_unpack_vb:
  case TPC::BIv_i8_unpack_b:
  case TPC::BIv_i8_unpack_vb:
  case TPC::BIv_u8_unpack_b:
  case TPC::BIv_u8_unpack_vb:
    return emit_UNPACK(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_get_lut_entry_and_interval_start_b:
  case TPC::BIv_f32_get_lut_entry_and_interval_start_vb:
  case TPC::BIv_bf16_get_lut_entry_and_interval_start_b:
  case TPC::BIv_bf16_get_lut_entry_and_interval_start_vb:
  case TPC::BIv_f16_get_lut_entry_and_interval_start_b:
  case TPC::BIv_f16_get_lut_entry_and_interval_start_vb:
    return emit_GET_LUT(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_form_fp_num_b:
  case TPC::BIv_f32_form_fp_num_vb:
  case TPC::BIv_bf16_form_fp_num_b:
  case TPC::BIv_bf16_form_fp_num_vb:
  case TPC::BIv_f16_form_fp_num_b:
  case TPC::BIv_f16_form_fp_num_vb:
  
  case TPC::BIv_f8_form_fp_num_b:
  case TPC::BIv_f8_form_fp_num_vb:
  case TPC::BIv_h8_form_fp_num_b:
  case TPC::BIv_h8_form_fp_num_vb:

  case TPC::BIv_f32_form_fp_num_ie_b:
  case TPC::BIv_f32_form_fp_num_ie_vb:
  case TPC::BIv_bf16_form_fp_num_ie_b:
  case TPC::BIv_bf16_form_fp_num_ie_vb:
  case TPC::BIv_f16_form_fp_num_ie_b:
  case TPC::BIv_f16_form_fp_num_ie_vb:

  case TPC::BIv_f8_form_fp_num_ie_b:
  case TPC::BIv_f8_form_fp_num_ie_vb:
  case TPC::BIv_h8_form_fp_num_ie_b:
  case TPC::BIv_h8_form_fp_num_ie_vb:
    return emit_FORM_FP_NUMBER(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_mov_dual_group_b:
  case TPC::BIv_f32_mov_dual_group_vb:
  case TPC::BIv_bf16_mov_dual_group_b:
  case TPC::BIv_bf16_mov_dual_group_vb:
  case TPC::BIv_f16_mov_dual_group_b:
  case TPC::BIv_f16_mov_dual_group_vb:
  case TPC::BIv_i32_mov_dual_group_b:
  case TPC::BIv_i32_mov_dual_group_vb:
  case TPC::BIv_u32_mov_dual_group_b:
  case TPC::BIv_u32_mov_dual_group_vb:
  case TPC::BIv_i16_mov_dual_group_b:
  case TPC::BIv_i16_mov_dual_group_vb:
  case TPC::BIv_u16_mov_dual_group_b:
  case TPC::BIv_u16_mov_dual_group_vb:
  case TPC::BIv_i8_mov_dual_group_b:
  case TPC::BIv_i8_mov_dual_group_vb:
  case TPC::BIv_u8_mov_dual_group_b:
  case TPC::BIv_u8_mov_dual_group_vb:
  case TPC::BIv_f8_mov_dual_group_b:
  case TPC::BIv_f8_mov_dual_group_vb:
  case TPC::BIv_h8_mov_dual_group_b:
  case TPC::BIv_h8_mov_dual_group_vb:
    return emit_MOV_DUAL_GROUP(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_mov_dg_b:
  case TPC::BIv_f32_mov_dg_vb:
  case TPC::BIv_bf16_mov_dg_b:
  case TPC::BIv_bf16_mov_dg_vb:
  case TPC::BIv_f16_mov_dg_b:
  case TPC::BIv_f16_mov_dg_vb:
  case TPC::BIv_i32_mov_dg_b:
  case TPC::BIv_i32_mov_dg_vb:
  case TPC::BIv_u32_mov_dg_b:
  case TPC::BIv_u32_mov_dg_vb:
  case TPC::BIv_i16_mov_dg_b:
  case TPC::BIv_i16_mov_dg_vb:
  case TPC::BIv_u16_mov_dg_b:
  case TPC::BIv_u16_mov_dg_vb:
  case TPC::BIv_i8_mov_dg_b:
  case TPC::BIv_i8_mov_dg_vb:
  case TPC::BIv_u8_mov_dg_b:
  case TPC::BIv_u8_mov_dg_vb:
  case TPC::BIv_f8_mov_dg_b:
  case TPC::BIv_f8_mov_dg_vb:
  case TPC::BIv_h8_mov_dg_b:
  case TPC::BIv_h8_mov_dg_vb:
    return emit_MOV_DG(CGF, Intrinsic::tpc_mov_dual_group, E, ReturnValue, Arch);

  case TPC::BIv_f32_mov_dual_group_all_b:
  case TPC::BIv_f32_mov_dual_group_all_vb:
  case TPC::BIv_bf16_mov_dual_group_all_b:
  case TPC::BIv_bf16_mov_dual_group_all_vb:
  case TPC::BIv_f16_mov_dual_group_all_b:
  case TPC::BIv_f16_mov_dual_group_all_vb:
  case TPC::BIv_i32_mov_dual_group_all_b:
  case TPC::BIv_i32_mov_dual_group_all_vb:
  case TPC::BIv_u32_mov_dual_group_all_b:
  case TPC::BIv_u32_mov_dual_group_all_vb:
  case TPC::BIv_i16_mov_dual_group_all_b:
  case TPC::BIv_i16_mov_dual_group_all_vb:
  case TPC::BIv_u16_mov_dual_group_all_b:
  case TPC::BIv_u16_mov_dual_group_all_vb:
  case TPC::BIv_i8_mov_dual_group_all_b:
  case TPC::BIv_i8_mov_dual_group_all_vb:
  case TPC::BIv_u8_mov_dual_group_all_b:
  case TPC::BIv_u8_mov_dual_group_all_vb:
  case TPC::BIv_f8_mov_dual_group_all_b:
  case TPC::BIv_f8_mov_dual_group_all_vb:
  case TPC::BIv_h8_mov_dual_group_all_b:
  case TPC::BIv_h8_mov_dual_group_all_vb:
    return emit_MOV_DUAL_GROUP_ALL(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_mov_dg_all_b:
  case TPC::BIv_f32_mov_dg_all_vb:
  case TPC::BIv_bf16_mov_dg_all_b:
  case TPC::BIv_bf16_mov_dg_all_vb:
  case TPC::BIv_f16_mov_dg_all_b:
  case TPC::BIv_f16_mov_dg_all_vb:
  case TPC::BIv_i32_mov_dg_all_b:
  case TPC::BIv_i32_mov_dg_all_vb:
  case TPC::BIv_u32_mov_dg_all_b:
  case TPC::BIv_u32_mov_dg_all_vb:
  case TPC::BIv_i16_mov_dg_all_b:
  case TPC::BIv_i16_mov_dg_all_vb:
  case TPC::BIv_u16_mov_dg_all_b:
  case TPC::BIv_u16_mov_dg_all_vb:
  case TPC::BIv_i8_mov_dg_all_b:
  case TPC::BIv_i8_mov_dg_all_vb:
  case TPC::BIv_u8_mov_dg_all_b:
  case TPC::BIv_u8_mov_dg_all_vb:
  case TPC::BIv_f8_mov_dg_all_b:
  case TPC::BIv_f8_mov_dg_all_vb:
  case TPC::BIv_h8_mov_dg_all_b:
  case TPC::BIv_h8_mov_dg_all_vb:
    return emit_MOV_DG(CGF, Intrinsic::tpc_mov_dual_group_all, E, ReturnValue, Arch);

  case TPC::BIv_f32_mov_dual_group_unpack_b:
  case TPC::BIv_f32_mov_dual_group_unpack_vb:
  case TPC::BIv_bf16_mov_dual_group_unpack_b:
  case TPC::BIv_bf16_mov_dual_group_unpack_vb:
  case TPC::BIv_f16_mov_dual_group_unpack_b:
  case TPC::BIv_f16_mov_dual_group_unpack_vb:
  case TPC::BIv_i32_mov_dual_group_unpack_b:
  case TPC::BIv_i32_mov_dual_group_unpack_vb:
  case TPC::BIv_u32_mov_dual_group_unpack_b:
  case TPC::BIv_u32_mov_dual_group_unpack_vb:
  case TPC::BIv_i16_mov_dual_group_unpack_b:
  case TPC::BIv_i16_mov_dual_group_unpack_vb:
  case TPC::BIv_u16_mov_dual_group_unpack_b:
  case TPC::BIv_u16_mov_dual_group_unpack_vb:
  case TPC::BIv_i8_mov_dual_group_unpack_b:
  case TPC::BIv_i8_mov_dual_group_unpack_vb:
  case TPC::BIv_u8_mov_dual_group_unpack_b:
  case TPC::BIv_u8_mov_dual_group_unpack_vb:
  case TPC::BIv_f8_mov_dual_group_unpack_b:
  case TPC::BIv_f8_mov_dual_group_unpack_vb:
  case TPC::BIv_h8_mov_dual_group_unpack_b:
  case TPC::BIv_h8_mov_dual_group_unpack_vb:
    return emit_MOV_DUAL_GROUP_UNPACK(CGF, E);

  case TPC::BIv_f32_mov_dual_group_pack_b:
  case TPC::BIv_f32_mov_dual_group_pack_vb:
  case TPC::BIv_bf16_mov_dual_group_pack_b:
  case TPC::BIv_bf16_mov_dual_group_pack_vb:
  case TPC::BIv_f16_mov_dual_group_pack_b:
  case TPC::BIv_f16_mov_dual_group_pack_vb:
  case TPC::BIv_i32_mov_dual_group_pack_b:
  case TPC::BIv_i32_mov_dual_group_pack_vb:
  case TPC::BIv_u32_mov_dual_group_pack_b:
  case TPC::BIv_u32_mov_dual_group_pack_vb:
  case TPC::BIv_i16_mov_dual_group_pack_b:
  case TPC::BIv_i16_mov_dual_group_pack_vb:
  case TPC::BIv_u16_mov_dual_group_pack_b:
  case TPC::BIv_u16_mov_dual_group_pack_vb:
  case TPC::BIv_i8_mov_dual_group_pack_b:
  case TPC::BIv_i8_mov_dual_group_pack_vb:
  case TPC::BIv_u8_mov_dual_group_pack_b:
  case TPC::BIv_u8_mov_dual_group_pack_vb:
  case TPC::BIv_f8_mov_dual_group_pack_b:
  case TPC::BIv_f8_mov_dual_group_pack_vb:
  case TPC::BIv_h8_mov_dual_group_pack_b:
  case TPC::BIv_h8_mov_dual_group_pack_vb:
    return emit_MOV_DUAL_GROUP_PACK(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_mov_group_b:
  case TPC::BIv_f32_mov_group_vb:
  case TPC::BIv_bf16_mov_group_b:
  case TPC::BIv_bf16_mov_group_vb:
  case TPC::BIv_f16_mov_group_b:
  case TPC::BIv_f16_mov_group_vb:
  case TPC::BIv_f8_mov_group_b:
  case TPC::BIv_f8_mov_group_vb:
  case TPC::BIv_h8_mov_group_b:
  case TPC::BIv_h8_mov_group_vb:
  case TPC::BIv_i32_mov_group_b:
  case TPC::BIv_i32_mov_group_vb:
  case TPC::BIv_u32_mov_group_b:
  case TPC::BIv_u32_mov_group_vb:
  case TPC::BIv_i16_mov_group_b:
  case TPC::BIv_i16_mov_group_vb:
  case TPC::BIv_u16_mov_group_b:
  case TPC::BIv_u16_mov_group_vb:
  case TPC::BIv_i8_mov_group_b:
  case TPC::BIv_i8_mov_group_vb:
  case TPC::BIv_u8_mov_group_b:
  case TPC::BIv_u8_mov_group_vb:
    return emit_MOV_GROUP(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_sel_eq_f32_vb:
  case TPC::BIv_f32_sel_eq_f32_b:
  case TPC::BIv_f32_sel_eq_i32_vb:
  case TPC::BIv_f32_sel_eq_i32_b:
  case TPC::BIv_f32_sel_eq_u32_vb:
  case TPC::BIv_f32_sel_eq_u32_b:
  case TPC::BIv_bf16_sel_eq_bf16_b:
  case TPC::BIv_bf16_sel_eq_bf16_vb:
  case TPC::BIv_bf16_sel_eq_f16_b:
  case TPC::BIv_bf16_sel_eq_f16_vb:
  case TPC::BIv_bf16_sel_eq_i16_vb:
  case TPC::BIv_bf16_sel_eq_i16_b:
  case TPC::BIv_bf16_sel_eq_u16_vb:
  case TPC::BIv_bf16_sel_eq_u16_b:
  case TPC::BIv_f16_sel_eq_bf16_b:
  case TPC::BIv_f16_sel_eq_bf16_vb:
  case TPC::BIv_f16_sel_eq_f16_b:
  case TPC::BIv_f16_sel_eq_f16_vb:
  case TPC::BIv_f16_sel_eq_i16_vb:
  case TPC::BIv_f16_sel_eq_i16_b:
  case TPC::BIv_f16_sel_eq_u16_vb:
  case TPC::BIv_f16_sel_eq_u16_b:
  case TPC::BIv_i32_sel_eq_f32_vb:
  case TPC::BIv_i32_sel_eq_f32_b:
  case TPC::BIv_i32_sel_eq_i32_vb:
  case TPC::BIv_i32_sel_eq_i32_b:
  case TPC::BIv_i32_sel_eq_u32_vb:
  case TPC::BIv_i32_sel_eq_u32_b:
  case TPC::BIv_u32_sel_eq_f32_vb:
  case TPC::BIv_u32_sel_eq_f32_b:
  case TPC::BIv_u32_sel_eq_i32_vb:
  case TPC::BIv_u32_sel_eq_i32_b:
  case TPC::BIv_u32_sel_eq_u32_vb:
  case TPC::BIv_u32_sel_eq_u32_b:
  case TPC::BIv_i16_sel_eq_bf16_vb:
  case TPC::BIv_i16_sel_eq_bf16_b:
  case TPC::BIv_i16_sel_eq_f16_vb:
  case TPC::BIv_i16_sel_eq_f16_b:
  case TPC::BIv_i16_sel_eq_i16_vb:
  case TPC::BIv_i16_sel_eq_i16_b:
  case TPC::BIv_i16_sel_eq_u16_vb:
  case TPC::BIv_i16_sel_eq_u16_b:
  case TPC::BIv_u16_sel_eq_bf16_vb:
  case TPC::BIv_u16_sel_eq_bf16_b:
  case TPC::BIv_u16_sel_eq_f16_vb:
  case TPC::BIv_u16_sel_eq_f16_b:
  case TPC::BIv_u16_sel_eq_i16_vb:
  case TPC::BIv_u16_sel_eq_i16_b:
  case TPC::BIv_u16_sel_eq_u16_vb:
  case TPC::BIv_u16_sel_eq_u16_b:
  case TPC::BIv_i8_sel_eq_i8_vb:
  case TPC::BIv_i8_sel_eq_i8_b:
  case TPC::BIv_i8_sel_eq_u8_vb:
  case TPC::BIv_i8_sel_eq_u8_b:
  case TPC::BIv_u8_sel_eq_i8_vb:
  case TPC::BIv_u8_sel_eq_i8_b:
  case TPC::BIv_u8_sel_eq_u8_vb:
  case TPC::BIv_u8_sel_eq_u8_b:
//fp8
  case TPC::BIv_f8_sel_eq_f8_b:
  case TPC::BIv_f8_sel_eq_f8_vb:
  case TPC::BIv_f8_sel_eq_h8_b:
  case TPC::BIv_f8_sel_eq_h8_vb:
  case TPC::BIv_f8_sel_eq_i8_vb:
  case TPC::BIv_f8_sel_eq_i8_b:
  case TPC::BIv_f8_sel_eq_u8_vb:
  case TPC::BIv_f8_sel_eq_u8_b:
  case TPC::BIv_h8_sel_eq_f8_b:
  case TPC::BIv_h8_sel_eq_f8_vb:
  case TPC::BIv_h8_sel_eq_h8_b:
  case TPC::BIv_h8_sel_eq_h8_vb:
  case TPC::BIv_h8_sel_eq_i8_vb:
  case TPC::BIv_h8_sel_eq_i8_b:
  case TPC::BIv_h8_sel_eq_u8_vb:
  case TPC::BIv_h8_sel_eq_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel_eq);

  case TPC::BIv_f32_sel_neq_f32_vb:
  case TPC::BIv_f32_sel_neq_f32_b:
  case TPC::BIv_f32_sel_neq_i32_vb:
  case TPC::BIv_f32_sel_neq_i32_b:
  case TPC::BIv_f32_sel_neq_u32_vb:
  case TPC::BIv_f32_sel_neq_u32_b:
  case TPC::BIv_bf16_sel_neq_bf16_b:
  case TPC::BIv_bf16_sel_neq_bf16_vb:
  case TPC::BIv_bf16_sel_neq_f16_b:
  case TPC::BIv_bf16_sel_neq_f16_vb:
  case TPC::BIv_bf16_sel_neq_i16_vb:
  case TPC::BIv_bf16_sel_neq_i16_b:
  case TPC::BIv_bf16_sel_neq_u16_vb:
  case TPC::BIv_bf16_sel_neq_u16_b:
  case TPC::BIv_f16_sel_neq_bf16_b:
  case TPC::BIv_f16_sel_neq_bf16_vb:
  case TPC::BIv_f16_sel_neq_f16_b:
  case TPC::BIv_f16_sel_neq_f16_vb:
  case TPC::BIv_f16_sel_neq_i16_vb:
  case TPC::BIv_f16_sel_neq_i16_b:
  case TPC::BIv_f16_sel_neq_u16_vb:
  case TPC::BIv_f16_sel_neq_u16_b:
  case TPC::BIv_i32_sel_neq_f32_vb:
  case TPC::BIv_i32_sel_neq_f32_b:
  case TPC::BIv_i32_sel_neq_i32_vb:
  case TPC::BIv_i32_sel_neq_i32_b:
  case TPC::BIv_i32_sel_neq_u32_vb:
  case TPC::BIv_i32_sel_neq_u32_b:
  case TPC::BIv_u32_sel_neq_f32_vb:
  case TPC::BIv_u32_sel_neq_f32_b:
  case TPC::BIv_u32_sel_neq_i32_vb:
  case TPC::BIv_u32_sel_neq_i32_b:
  case TPC::BIv_u32_sel_neq_u32_vb:
  case TPC::BIv_u32_sel_neq_u32_b:
  case TPC::BIv_i16_sel_neq_bf16_vb:
  case TPC::BIv_i16_sel_neq_bf16_b:
  case TPC::BIv_i16_sel_neq_f16_vb:
  case TPC::BIv_i16_sel_neq_f16_b:
  case TPC::BIv_i16_sel_neq_i16_vb:
  case TPC::BIv_i16_sel_neq_i16_b:
  case TPC::BIv_i16_sel_neq_u16_vb:
  case TPC::BIv_i16_sel_neq_u16_b:
  case TPC::BIv_u16_sel_neq_bf16_vb:
  case TPC::BIv_u16_sel_neq_bf16_b:
  case TPC::BIv_u16_sel_neq_f16_vb:
  case TPC::BIv_u16_sel_neq_f16_b:
  case TPC::BIv_u16_sel_neq_i16_vb:
  case TPC::BIv_u16_sel_neq_i16_b:
  case TPC::BIv_u16_sel_neq_u16_vb:
  case TPC::BIv_u16_sel_neq_u16_b:
  case TPC::BIv_i8_sel_neq_i8_vb:
  case TPC::BIv_i8_sel_neq_i8_b:
  case TPC::BIv_i8_sel_neq_u8_vb:
  case TPC::BIv_i8_sel_neq_u8_b:
  case TPC::BIv_u8_sel_neq_i8_vb:
  case TPC::BIv_u8_sel_neq_i8_b:
  case TPC::BIv_u8_sel_neq_u8_vb:
  case TPC::BIv_u8_sel_neq_u8_b:
//fp8
  case TPC::BIv_f8_sel_neq_f8_b:
  case TPC::BIv_f8_sel_neq_f8_vb:
  case TPC::BIv_f8_sel_neq_h8_b:
  case TPC::BIv_f8_sel_neq_h8_vb:
  case TPC::BIv_f8_sel_neq_i8_vb:
  case TPC::BIv_f8_sel_neq_i8_b:
  case TPC::BIv_f8_sel_neq_u8_vb:
  case TPC::BIv_f8_sel_neq_u8_b:
  case TPC::BIv_h8_sel_neq_f8_b:
  case TPC::BIv_h8_sel_neq_f8_vb:
  case TPC::BIv_h8_sel_neq_h8_b:
  case TPC::BIv_h8_sel_neq_h8_vb:
  case TPC::BIv_h8_sel_neq_i8_vb:
  case TPC::BIv_h8_sel_neq_i8_b:
  case TPC::BIv_h8_sel_neq_u8_vb:
  case TPC::BIv_h8_sel_neq_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel_neq);

  case TPC::BIv_f32_sel_less_f32_vb:
  case TPC::BIv_f32_sel_less_f32_b:
  case TPC::BIv_f32_sel_less_i32_vb:
  case TPC::BIv_f32_sel_less_i32_b:
  case TPC::BIv_f32_sel_less_u32_vb:
  case TPC::BIv_f32_sel_less_u32_b:
  case TPC::BIv_bf16_sel_less_bf16_b:
  case TPC::BIv_bf16_sel_less_bf16_vb:
  case TPC::BIv_bf16_sel_less_f16_b:
  case TPC::BIv_bf16_sel_less_f16_vb:
  case TPC::BIv_bf16_sel_less_i16_vb:
  case TPC::BIv_bf16_sel_less_i16_b:
  case TPC::BIv_bf16_sel_less_u16_vb:
  case TPC::BIv_bf16_sel_less_u16_b:
  case TPC::BIv_f16_sel_less_bf16_b:
  case TPC::BIv_f16_sel_less_bf16_vb:
  case TPC::BIv_f16_sel_less_f16_b:
  case TPC::BIv_f16_sel_less_f16_vb:
  case TPC::BIv_f16_sel_less_i16_vb:
  case TPC::BIv_f16_sel_less_i16_b:
  case TPC::BIv_f16_sel_less_u16_vb:
  case TPC::BIv_f16_sel_less_u16_b:
  case TPC::BIv_i32_sel_less_f32_vb:
  case TPC::BIv_i32_sel_less_f32_b:
  case TPC::BIv_i32_sel_less_i32_vb:
  case TPC::BIv_i32_sel_less_i32_b:
  case TPC::BIv_i32_sel_less_u32_vb:
  case TPC::BIv_i32_sel_less_u32_b:
  case TPC::BIv_u32_sel_less_f32_vb:
  case TPC::BIv_u32_sel_less_f32_b:
  case TPC::BIv_u32_sel_less_i32_vb:
  case TPC::BIv_u32_sel_less_i32_b:
  case TPC::BIv_u32_sel_less_u32_vb:
  case TPC::BIv_u32_sel_less_u32_b:
  case TPC::BIv_i16_sel_less_bf16_vb:
  case TPC::BIv_i16_sel_less_bf16_b:
  case TPC::BIv_i16_sel_less_f16_vb:
  case TPC::BIv_i16_sel_less_f16_b:
  case TPC::BIv_i16_sel_less_i16_vb:
  case TPC::BIv_i16_sel_less_i16_b:
  case TPC::BIv_i16_sel_less_u16_vb:
  case TPC::BIv_i16_sel_less_u16_b:
  case TPC::BIv_u16_sel_less_bf16_vb:
  case TPC::BIv_u16_sel_less_bf16_b:
  case TPC::BIv_u16_sel_less_f16_vb:
  case TPC::BIv_u16_sel_less_f16_b:
  case TPC::BIv_u16_sel_less_i16_vb:
  case TPC::BIv_u16_sel_less_i16_b:
  case TPC::BIv_u16_sel_less_u16_vb:
  case TPC::BIv_u16_sel_less_u16_b:
  case TPC::BIv_i8_sel_less_i8_vb:
  case TPC::BIv_i8_sel_less_i8_b:
  case TPC::BIv_i8_sel_less_u8_vb:
  case TPC::BIv_i8_sel_less_u8_b:
  case TPC::BIv_u8_sel_less_i8_vb:
  case TPC::BIv_u8_sel_less_i8_b:
  case TPC::BIv_u8_sel_less_u8_vb:
  case TPC::BIv_u8_sel_less_u8_b:
//fp8
  case TPC::BIv_f8_sel_less_f8_b:
  case TPC::BIv_f8_sel_less_f8_vb:
  case TPC::BIv_f8_sel_less_h8_b:
  case TPC::BIv_f8_sel_less_h8_vb:
  case TPC::BIv_f8_sel_less_i8_vb:
  case TPC::BIv_f8_sel_less_i8_b:
  case TPC::BIv_f8_sel_less_u8_vb:
  case TPC::BIv_f8_sel_less_u8_b:
  case TPC::BIv_h8_sel_less_f8_b:
  case TPC::BIv_h8_sel_less_f8_vb:
  case TPC::BIv_h8_sel_less_h8_b:
  case TPC::BIv_h8_sel_less_h8_vb:
  case TPC::BIv_h8_sel_less_i8_vb:
  case TPC::BIv_h8_sel_less_i8_b:
  case TPC::BIv_h8_sel_less_u8_vb:
  case TPC::BIv_h8_sel_less_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel_less);

  case TPC::BIv_f32_sel_leq_f32_vb:
  case TPC::BIv_f32_sel_leq_f32_b:
  case TPC::BIv_f32_sel_leq_i32_vb:
  case TPC::BIv_f32_sel_leq_i32_b:
  case TPC::BIv_f32_sel_leq_u32_vb:
  case TPC::BIv_f32_sel_leq_u32_b:
  case TPC::BIv_bf16_sel_leq_bf16_b:
  case TPC::BIv_bf16_sel_leq_bf16_vb:
  case TPC::BIv_bf16_sel_leq_f16_b:
  case TPC::BIv_bf16_sel_leq_f16_vb:
  case TPC::BIv_bf16_sel_leq_i16_vb:
  case TPC::BIv_bf16_sel_leq_i16_b:
  case TPC::BIv_bf16_sel_leq_u16_vb:
  case TPC::BIv_bf16_sel_leq_u16_b:
  case TPC::BIv_f16_sel_leq_bf16_b:
  case TPC::BIv_f16_sel_leq_bf16_vb:
  case TPC::BIv_f16_sel_leq_f16_b:
  case TPC::BIv_f16_sel_leq_f16_vb:
  case TPC::BIv_f16_sel_leq_i16_vb:
  case TPC::BIv_f16_sel_leq_i16_b:
  case TPC::BIv_f16_sel_leq_u16_vb:
  case TPC::BIv_f16_sel_leq_u16_b:
  case TPC::BIv_i32_sel_leq_f32_vb:
  case TPC::BIv_i32_sel_leq_f32_b:
  case TPC::BIv_i32_sel_leq_i32_vb:
  case TPC::BIv_i32_sel_leq_i32_b:
  case TPC::BIv_i32_sel_leq_u32_vb:
  case TPC::BIv_i32_sel_leq_u32_b:
  case TPC::BIv_u32_sel_leq_f32_vb:
  case TPC::BIv_u32_sel_leq_f32_b:
  case TPC::BIv_u32_sel_leq_i32_vb:
  case TPC::BIv_u32_sel_leq_i32_b:
  case TPC::BIv_u32_sel_leq_u32_vb:
  case TPC::BIv_u32_sel_leq_u32_b:
  case TPC::BIv_i16_sel_leq_bf16_vb:
  case TPC::BIv_i16_sel_leq_bf16_b:
  case TPC::BIv_i16_sel_leq_f16_vb:
  case TPC::BIv_i16_sel_leq_f16_b:
  case TPC::BIv_i16_sel_leq_i16_vb:
  case TPC::BIv_i16_sel_leq_i16_b:
  case TPC::BIv_i16_sel_leq_u16_vb:
  case TPC::BIv_i16_sel_leq_u16_b:
  case TPC::BIv_u16_sel_leq_bf16_vb:
  case TPC::BIv_u16_sel_leq_bf16_b:
  case TPC::BIv_u16_sel_leq_f16_vb:
  case TPC::BIv_u16_sel_leq_f16_b:
  case TPC::BIv_u16_sel_leq_i16_vb:
  case TPC::BIv_u16_sel_leq_i16_b:
  case TPC::BIv_u16_sel_leq_u16_vb:
  case TPC::BIv_u16_sel_leq_u16_b:
  case TPC::BIv_i8_sel_leq_i8_vb:
  case TPC::BIv_i8_sel_leq_i8_b:
  case TPC::BIv_i8_sel_leq_u8_vb:
  case TPC::BIv_i8_sel_leq_u8_b:
  case TPC::BIv_u8_sel_leq_i8_vb:
  case TPC::BIv_u8_sel_leq_i8_b:
  case TPC::BIv_u8_sel_leq_u8_vb:
  case TPC::BIv_u8_sel_leq_u8_b:
//fp8
  case TPC::BIv_f8_sel_leq_f8_b:
  case TPC::BIv_f8_sel_leq_f8_vb:
  case TPC::BIv_f8_sel_leq_h8_b:
  case TPC::BIv_f8_sel_leq_h8_vb:
  case TPC::BIv_f8_sel_leq_i8_vb:
  case TPC::BIv_f8_sel_leq_i8_b:
  case TPC::BIv_f8_sel_leq_u8_vb:
  case TPC::BIv_f8_sel_leq_u8_b:
  case TPC::BIv_h8_sel_leq_f8_b:
  case TPC::BIv_h8_sel_leq_f8_vb:
  case TPC::BIv_h8_sel_leq_h8_b:
  case TPC::BIv_h8_sel_leq_h8_vb:
  case TPC::BIv_h8_sel_leq_i8_vb:
  case TPC::BIv_h8_sel_leq_i8_b:
  case TPC::BIv_h8_sel_leq_u8_vb:
  case TPC::BIv_h8_sel_leq_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel_leq);

  case TPC::BIv_f32_sel_grt_f32_vb:
  case TPC::BIv_f32_sel_grt_f32_b:
  case TPC::BIv_f32_sel_grt_i32_vb:
  case TPC::BIv_f32_sel_grt_i32_b:
  case TPC::BIv_f32_sel_grt_u32_vb:
  case TPC::BIv_f32_sel_grt_u32_b:
  case TPC::BIv_bf16_sel_grt_bf16_b:
  case TPC::BIv_bf16_sel_grt_bf16_vb:
  case TPC::BIv_bf16_sel_grt_f16_b:
  case TPC::BIv_bf16_sel_grt_f16_vb:
  case TPC::BIv_bf16_sel_grt_i16_vb:
  case TPC::BIv_bf16_sel_grt_i16_b:
  case TPC::BIv_bf16_sel_grt_u16_vb:
  case TPC::BIv_bf16_sel_grt_u16_b:
  case TPC::BIv_f16_sel_grt_bf16_b:
  case TPC::BIv_f16_sel_grt_bf16_vb:
  case TPC::BIv_f16_sel_grt_f16_b:
  case TPC::BIv_f16_sel_grt_f16_vb:
  case TPC::BIv_f16_sel_grt_i16_vb:
  case TPC::BIv_f16_sel_grt_i16_b:
  case TPC::BIv_f16_sel_grt_u16_vb:
  case TPC::BIv_f16_sel_grt_u16_b:
  case TPC::BIv_i32_sel_grt_f32_vb:
  case TPC::BIv_i32_sel_grt_f32_b:
  case TPC::BIv_i32_sel_grt_i32_vb:
  case TPC::BIv_i32_sel_grt_i32_b:
  case TPC::BIv_i32_sel_grt_u32_vb:
  case TPC::BIv_i32_sel_grt_u32_b:
  case TPC::BIv_u32_sel_grt_f32_vb:
  case TPC::BIv_u32_sel_grt_f32_b:
  case TPC::BIv_u32_sel_grt_i32_vb:
  case TPC::BIv_u32_sel_grt_i32_b:
  case TPC::BIv_u32_sel_grt_u32_vb:
  case TPC::BIv_u32_sel_grt_u32_b:
  case TPC::BIv_i16_sel_grt_bf16_vb:
  case TPC::BIv_i16_sel_grt_bf16_b:
  case TPC::BIv_i16_sel_grt_f16_vb:
  case TPC::BIv_i16_sel_grt_f16_b:
  case TPC::BIv_i16_sel_grt_i16_vb:
  case TPC::BIv_i16_sel_grt_i16_b:
  case TPC::BIv_i16_sel_grt_u16_vb:
  case TPC::BIv_i16_sel_grt_u16_b:
  case TPC::BIv_u16_sel_grt_bf16_vb:
  case TPC::BIv_u16_sel_grt_bf16_b:
  case TPC::BIv_u16_sel_grt_f16_vb:
  case TPC::BIv_u16_sel_grt_f16_b:
  case TPC::BIv_u16_sel_grt_i16_vb:
  case TPC::BIv_u16_sel_grt_i16_b:
  case TPC::BIv_u16_sel_grt_u16_vb:
  case TPC::BIv_u16_sel_grt_u16_b:
  case TPC::BIv_i8_sel_grt_i8_vb:
  case TPC::BIv_i8_sel_grt_i8_b:
  case TPC::BIv_i8_sel_grt_u8_vb:
  case TPC::BIv_i8_sel_grt_u8_b:
  case TPC::BIv_u8_sel_grt_i8_vb:
  case TPC::BIv_u8_sel_grt_i8_b:
  case TPC::BIv_u8_sel_grt_u8_vb:
  case TPC::BIv_u8_sel_grt_u8_b:
//fp8
  case TPC::BIv_f8_sel_grt_f8_b:
  case TPC::BIv_f8_sel_grt_f8_vb:
  case TPC::BIv_f8_sel_grt_h8_b:
  case TPC::BIv_f8_sel_grt_h8_vb:
  case TPC::BIv_f8_sel_grt_i8_vb:
  case TPC::BIv_f8_sel_grt_i8_b:
  case TPC::BIv_f8_sel_grt_u8_vb:
  case TPC::BIv_f8_sel_grt_u8_b:
  case TPC::BIv_h8_sel_grt_f8_b:
  case TPC::BIv_h8_sel_grt_f8_vb:
  case TPC::BIv_h8_sel_grt_h8_b:
  case TPC::BIv_h8_sel_grt_h8_vb:
  case TPC::BIv_h8_sel_grt_i8_vb:
  case TPC::BIv_h8_sel_grt_i8_b:
  case TPC::BIv_h8_sel_grt_u8_vb:
  case TPC::BIv_h8_sel_grt_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel_grt);

  case TPC::BIv_f32_sel_geq_f32_vb:
  case TPC::BIv_f32_sel_geq_f32_b:
  case TPC::BIv_f32_sel_geq_i32_vb:
  case TPC::BIv_f32_sel_geq_i32_b:
  case TPC::BIv_f32_sel_geq_u32_vb:
  case TPC::BIv_f32_sel_geq_u32_b:
  case TPC::BIv_bf16_sel_geq_bf16_b:
  case TPC::BIv_bf16_sel_geq_bf16_vb:
  case TPC::BIv_bf16_sel_geq_f16_b:
  case TPC::BIv_bf16_sel_geq_f16_vb:
  case TPC::BIv_bf16_sel_geq_i16_vb:
  case TPC::BIv_bf16_sel_geq_i16_b:
  case TPC::BIv_bf16_sel_geq_u16_vb:
  case TPC::BIv_bf16_sel_geq_u16_b:
  case TPC::BIv_f16_sel_geq_bf16_b:
  case TPC::BIv_f16_sel_geq_bf16_vb:
  case TPC::BIv_f16_sel_geq_f16_b:
  case TPC::BIv_f16_sel_geq_f16_vb:
  case TPC::BIv_f16_sel_geq_i16_vb:
  case TPC::BIv_f16_sel_geq_i16_b:
  case TPC::BIv_f16_sel_geq_u16_vb:
  case TPC::BIv_f16_sel_geq_u16_b:
  case TPC::BIv_i32_sel_geq_f32_vb:
  case TPC::BIv_i32_sel_geq_f32_b:
  case TPC::BIv_i32_sel_geq_i32_vb:
  case TPC::BIv_i32_sel_geq_i32_b:
  case TPC::BIv_i32_sel_geq_u32_vb:
  case TPC::BIv_i32_sel_geq_u32_b:
  case TPC::BIv_u32_sel_geq_f32_vb:
  case TPC::BIv_u32_sel_geq_f32_b:
  case TPC::BIv_u32_sel_geq_i32_vb:
  case TPC::BIv_u32_sel_geq_i32_b:
  case TPC::BIv_u32_sel_geq_u32_vb:
  case TPC::BIv_u32_sel_geq_u32_b:
  case TPC::BIv_i16_sel_geq_bf16_vb:
  case TPC::BIv_i16_sel_geq_bf16_b:
  case TPC::BIv_i16_sel_geq_f16_vb:
  case TPC::BIv_i16_sel_geq_f16_b:
  case TPC::BIv_i16_sel_geq_i16_vb:
  case TPC::BIv_i16_sel_geq_i16_b:
  case TPC::BIv_i16_sel_geq_u16_vb:
  case TPC::BIv_i16_sel_geq_u16_b:
  case TPC::BIv_u16_sel_geq_bf16_vb:
  case TPC::BIv_u16_sel_geq_bf16_b:
  case TPC::BIv_u16_sel_geq_f16_vb:
  case TPC::BIv_u16_sel_geq_f16_b:
  case TPC::BIv_u16_sel_geq_i16_vb:
  case TPC::BIv_u16_sel_geq_i16_b:
  case TPC::BIv_u16_sel_geq_u16_vb:
  case TPC::BIv_u16_sel_geq_u16_b:
  case TPC::BIv_i8_sel_geq_i8_vb:
  case TPC::BIv_i8_sel_geq_i8_b:
  case TPC::BIv_i8_sel_geq_u8_vb:
  case TPC::BIv_i8_sel_geq_u8_b:
  case TPC::BIv_u8_sel_geq_i8_vb:
  case TPC::BIv_u8_sel_geq_i8_b:
  case TPC::BIv_u8_sel_geq_u8_vb:
  case TPC::BIv_u8_sel_geq_u8_b:
//fp8
  case TPC::BIv_f8_sel_geq_f8_b:
  case TPC::BIv_f8_sel_geq_f8_vb:
  case TPC::BIv_f8_sel_geq_h8_b:
  case TPC::BIv_f8_sel_geq_h8_vb:
  case TPC::BIv_f8_sel_geq_i8_vb:
  case TPC::BIv_f8_sel_geq_i8_b:
  case TPC::BIv_f8_sel_geq_u8_vb:
  case TPC::BIv_f8_sel_geq_u8_b:
  case TPC::BIv_h8_sel_geq_f8_b:
  case TPC::BIv_h8_sel_geq_f8_vb:
  case TPC::BIv_h8_sel_geq_h8_b:
  case TPC::BIv_h8_sel_geq_h8_vb:
  case TPC::BIv_h8_sel_geq_i8_vb:
  case TPC::BIv_h8_sel_geq_i8_b:
  case TPC::BIv_h8_sel_geq_u8_vb:
  case TPC::BIv_h8_sel_geq_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel_geq);

  case TPC::BIv_f32_sel2_less_f32_vb:
  case TPC::BIv_f32_sel2_less_f32_b:
  case TPC::BIv_f32_sel2_less_i32_vb:
  case TPC::BIv_f32_sel2_less_i32_b:
  case TPC::BIv_f32_sel2_less_u32_vb:
  case TPC::BIv_f32_sel2_less_u32_b:
  case TPC::BIv_bf16_sel2_less_bf16_b:
  case TPC::BIv_bf16_sel2_less_bf16_vb:
  case TPC::BIv_bf16_sel2_less_f16_b:
  case TPC::BIv_bf16_sel2_less_f16_vb:
  case TPC::BIv_bf16_sel2_less_i16_vb:
  case TPC::BIv_bf16_sel2_less_i16_b:
  case TPC::BIv_bf16_sel2_less_u16_vb:
  case TPC::BIv_bf16_sel2_less_u16_b:
  case TPC::BIv_f16_sel2_less_bf16_b:
  case TPC::BIv_f16_sel2_less_bf16_vb:
  case TPC::BIv_f16_sel2_less_f16_b:
  case TPC::BIv_f16_sel2_less_f16_vb:
  case TPC::BIv_f16_sel2_less_i16_vb:
  case TPC::BIv_f16_sel2_less_i16_b:
  case TPC::BIv_f16_sel2_less_u16_vb:
  case TPC::BIv_f16_sel2_less_u16_b:
  case TPC::BIv_i32_sel2_less_f32_vb:
  case TPC::BIv_i32_sel2_less_f32_b:
  case TPC::BIv_i32_sel2_less_i32_vb:
  case TPC::BIv_i32_sel2_less_i32_b:
  case TPC::BIv_i32_sel2_less_u32_vb:
  case TPC::BIv_i32_sel2_less_u32_b:
  case TPC::BIv_u32_sel2_less_f32_vb:
  case TPC::BIv_u32_sel2_less_f32_b:
  case TPC::BIv_u32_sel2_less_i32_vb:
  case TPC::BIv_u32_sel2_less_i32_b:
  case TPC::BIv_u32_sel2_less_u32_vb:
  case TPC::BIv_u32_sel2_less_u32_b:
  case TPC::BIv_i16_sel2_less_bf16_vb:
  case TPC::BIv_i16_sel2_less_bf16_b:
  case TPC::BIv_i16_sel2_less_f16_vb:
  case TPC::BIv_i16_sel2_less_f16_b:
  case TPC::BIv_i16_sel2_less_i16_vb:
  case TPC::BIv_i16_sel2_less_i16_b:
  case TPC::BIv_i16_sel2_less_u16_vb:
  case TPC::BIv_i16_sel2_less_u16_b:
  case TPC::BIv_u16_sel2_less_bf16_vb:
  case TPC::BIv_u16_sel2_less_bf16_b:
  case TPC::BIv_u16_sel2_less_f16_vb:
  case TPC::BIv_u16_sel2_less_f16_b:
  case TPC::BIv_u16_sel2_less_i16_vb:
  case TPC::BIv_u16_sel2_less_i16_b:
  case TPC::BIv_u16_sel2_less_u16_vb:
  case TPC::BIv_u16_sel2_less_u16_b:
  case TPC::BIv_i8_sel2_less_i8_vb:
  case TPC::BIv_i8_sel2_less_i8_b:
  case TPC::BIv_i8_sel2_less_u8_vb:
  case TPC::BIv_i8_sel2_less_u8_b:
  case TPC::BIv_u8_sel2_less_i8_vb:
  case TPC::BIv_u8_sel2_less_i8_b:
  case TPC::BIv_u8_sel2_less_u8_vb:
  case TPC::BIv_u8_sel2_less_u8_b:
  // fp8
  case TPC::BIv_f8_sel2_less_f8_b:
  case TPC::BIv_f8_sel2_less_f8_vb:
  case TPC::BIv_f8_sel2_less_h8_b:
  case TPC::BIv_f8_sel2_less_h8_vb:
  case TPC::BIv_f8_sel2_less_i8_vb:
  case TPC::BIv_f8_sel2_less_i8_b:
  case TPC::BIv_f8_sel2_less_u8_vb:
  case TPC::BIv_f8_sel2_less_u8_b:
  case TPC::BIv_h8_sel2_less_f8_b:
  case TPC::BIv_h8_sel2_less_f8_vb:
  case TPC::BIv_h8_sel2_less_h8_b:
  case TPC::BIv_h8_sel2_less_h8_vb:
  case TPC::BIv_h8_sel2_less_i8_vb:
  case TPC::BIv_h8_sel2_less_i8_b:
  case TPC::BIv_h8_sel2_less_u8_vb:
  case TPC::BIv_h8_sel2_less_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel2_less);

  case TPC::BIv_f32_sel2_leq_f32_vb:
  case TPC::BIv_f32_sel2_leq_f32_b:
  case TPC::BIv_f32_sel2_leq_i32_vb:
  case TPC::BIv_f32_sel2_leq_i32_b:
  case TPC::BIv_f32_sel2_leq_u32_vb:
  case TPC::BIv_f32_sel2_leq_u32_b:
  case TPC::BIv_bf16_sel2_leq_bf16_b:
  case TPC::BIv_bf16_sel2_leq_bf16_vb:
  case TPC::BIv_bf16_sel2_leq_f16_b:
  case TPC::BIv_bf16_sel2_leq_f16_vb:
  case TPC::BIv_bf16_sel2_leq_i16_vb:
  case TPC::BIv_bf16_sel2_leq_i16_b:
  case TPC::BIv_bf16_sel2_leq_u16_vb:
  case TPC::BIv_bf16_sel2_leq_u16_b:
  case TPC::BIv_f16_sel2_leq_bf16_b:
  case TPC::BIv_f16_sel2_leq_bf16_vb:
  case TPC::BIv_f16_sel2_leq_f16_b:
  case TPC::BIv_f16_sel2_leq_f16_vb:
  case TPC::BIv_f16_sel2_leq_i16_vb:
  case TPC::BIv_f16_sel2_leq_i16_b:
  case TPC::BIv_f16_sel2_leq_u16_vb:
  case TPC::BIv_f16_sel2_leq_u16_b:
  case TPC::BIv_i32_sel2_leq_f32_vb:
  case TPC::BIv_i32_sel2_leq_f32_b:
  case TPC::BIv_i32_sel2_leq_i32_vb:
  case TPC::BIv_i32_sel2_leq_i32_b:
  case TPC::BIv_i32_sel2_leq_u32_vb:
  case TPC::BIv_i32_sel2_leq_u32_b:
  case TPC::BIv_u32_sel2_leq_f32_vb:
  case TPC::BIv_u32_sel2_leq_f32_b:
  case TPC::BIv_u32_sel2_leq_i32_vb:
  case TPC::BIv_u32_sel2_leq_i32_b:
  case TPC::BIv_u32_sel2_leq_u32_vb:
  case TPC::BIv_u32_sel2_leq_u32_b:
  case TPC::BIv_i16_sel2_leq_bf16_vb:
  case TPC::BIv_i16_sel2_leq_bf16_b:
  case TPC::BIv_i16_sel2_leq_f16_vb:
  case TPC::BIv_i16_sel2_leq_f16_b:
  case TPC::BIv_i16_sel2_leq_i16_vb:
  case TPC::BIv_i16_sel2_leq_i16_b:
  case TPC::BIv_i16_sel2_leq_u16_vb:
  case TPC::BIv_i16_sel2_leq_u16_b:
  case TPC::BIv_u16_sel2_leq_bf16_vb:
  case TPC::BIv_u16_sel2_leq_bf16_b:
  case TPC::BIv_u16_sel2_leq_f16_vb:
  case TPC::BIv_u16_sel2_leq_f16_b:
  case TPC::BIv_u16_sel2_leq_i16_vb:
  case TPC::BIv_u16_sel2_leq_i16_b:
  case TPC::BIv_u16_sel2_leq_u16_vb:
  case TPC::BIv_u16_sel2_leq_u16_b:
  case TPC::BIv_i8_sel2_leq_i8_vb:
  case TPC::BIv_i8_sel2_leq_i8_b:
  case TPC::BIv_i8_sel2_leq_u8_vb:
  case TPC::BIv_i8_sel2_leq_u8_b:
  case TPC::BIv_u8_sel2_leq_i8_vb:
  case TPC::BIv_u8_sel2_leq_i8_b:
  case TPC::BIv_u8_sel2_leq_u8_vb:
  case TPC::BIv_u8_sel2_leq_u8_b:
    // fp8
  case TPC::BIv_f8_sel2_leq_f8_b:
  case TPC::BIv_f8_sel2_leq_f8_vb:
  case TPC::BIv_f8_sel2_leq_h8_b:
  case TPC::BIv_f8_sel2_leq_h8_vb:
  case TPC::BIv_f8_sel2_leq_i8_vb:
  case TPC::BIv_f8_sel2_leq_i8_b:
  case TPC::BIv_f8_sel2_leq_u8_vb:
  case TPC::BIv_f8_sel2_leq_u8_b:
  case TPC::BIv_h8_sel2_leq_f8_b:
  case TPC::BIv_h8_sel2_leq_f8_vb:
  case TPC::BIv_h8_sel2_leq_h8_b:
  case TPC::BIv_h8_sel2_leq_h8_vb:
  case TPC::BIv_h8_sel2_leq_i8_vb:
  case TPC::BIv_h8_sel2_leq_i8_b:
  case TPC::BIv_h8_sel2_leq_u8_vb:
  case TPC::BIv_h8_sel2_leq_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel2_leq);

  case TPC::BIv_f32_sel2_grt_f32_vb:
  case TPC::BIv_f32_sel2_grt_f32_b:
  case TPC::BIv_f32_sel2_grt_i32_vb:
  case TPC::BIv_f32_sel2_grt_i32_b:
  case TPC::BIv_f32_sel2_grt_u32_vb:
  case TPC::BIv_f32_sel2_grt_u32_b:
  case TPC::BIv_bf16_sel2_grt_bf16_b:
  case TPC::BIv_bf16_sel2_grt_bf16_vb:
  case TPC::BIv_bf16_sel2_grt_f16_b:
  case TPC::BIv_bf16_sel2_grt_f16_vb:
  case TPC::BIv_bf16_sel2_grt_i16_vb:
  case TPC::BIv_bf16_sel2_grt_i16_b:
  case TPC::BIv_bf16_sel2_grt_u16_vb:
  case TPC::BIv_bf16_sel2_grt_u16_b:
  case TPC::BIv_f16_sel2_grt_bf16_b:
  case TPC::BIv_f16_sel2_grt_bf16_vb:
  case TPC::BIv_f16_sel2_grt_f16_b:
  case TPC::BIv_f16_sel2_grt_f16_vb:
  case TPC::BIv_f16_sel2_grt_i16_vb:
  case TPC::BIv_f16_sel2_grt_i16_b:
  case TPC::BIv_f16_sel2_grt_u16_vb:
  case TPC::BIv_f16_sel2_grt_u16_b:
  case TPC::BIv_i32_sel2_grt_f32_vb:
  case TPC::BIv_i32_sel2_grt_f32_b:
  case TPC::BIv_i32_sel2_grt_i32_vb:
  case TPC::BIv_i32_sel2_grt_i32_b:
  case TPC::BIv_i32_sel2_grt_u32_vb:
  case TPC::BIv_i32_sel2_grt_u32_b:
  case TPC::BIv_u32_sel2_grt_f32_vb:
  case TPC::BIv_u32_sel2_grt_f32_b:
  case TPC::BIv_u32_sel2_grt_i32_vb:
  case TPC::BIv_u32_sel2_grt_i32_b:
  case TPC::BIv_u32_sel2_grt_u32_vb:
  case TPC::BIv_u32_sel2_grt_u32_b:
  case TPC::BIv_i16_sel2_grt_bf16_vb:
  case TPC::BIv_i16_sel2_grt_bf16_b:
  case TPC::BIv_i16_sel2_grt_f16_vb:
  case TPC::BIv_i16_sel2_grt_f16_b:
  case TPC::BIv_i16_sel2_grt_i16_vb:
  case TPC::BIv_i16_sel2_grt_i16_b:
  case TPC::BIv_i16_sel2_grt_u16_vb:
  case TPC::BIv_i16_sel2_grt_u16_b:
  case TPC::BIv_u16_sel2_grt_bf16_vb:
  case TPC::BIv_u16_sel2_grt_bf16_b:
  case TPC::BIv_u16_sel2_grt_f16_vb:
  case TPC::BIv_u16_sel2_grt_f16_b:
  case TPC::BIv_u16_sel2_grt_i16_vb:
  case TPC::BIv_u16_sel2_grt_i16_b:
  case TPC::BIv_u16_sel2_grt_u16_vb:
  case TPC::BIv_u16_sel2_grt_u16_b:
  case TPC::BIv_i8_sel2_grt_i8_vb:
  case TPC::BIv_i8_sel2_grt_i8_b:
  case TPC::BIv_i8_sel2_grt_u8_vb:
  case TPC::BIv_i8_sel2_grt_u8_b:
  case TPC::BIv_u8_sel2_grt_i8_vb:
  case TPC::BIv_u8_sel2_grt_i8_b:
  case TPC::BIv_u8_sel2_grt_u8_vb:
  case TPC::BIv_u8_sel2_grt_u8_b:
  // fp8
  case TPC::BIv_f8_sel2_grt_f8_b:
  case TPC::BIv_f8_sel2_grt_f8_vb:
  case TPC::BIv_f8_sel2_grt_h8_b:
  case TPC::BIv_f8_sel2_grt_h8_vb:
  case TPC::BIv_f8_sel2_grt_i8_vb:
  case TPC::BIv_f8_sel2_grt_i8_b:
  case TPC::BIv_f8_sel2_grt_u8_vb:
  case TPC::BIv_f8_sel2_grt_u8_b:
  case TPC::BIv_h8_sel2_grt_f8_b:
  case TPC::BIv_h8_sel2_grt_f8_vb:
  case TPC::BIv_h8_sel2_grt_h8_b:
  case TPC::BIv_h8_sel2_grt_h8_vb:
  case TPC::BIv_h8_sel2_grt_i8_vb:
  case TPC::BIv_h8_sel2_grt_i8_b:
  case TPC::BIv_h8_sel2_grt_u8_vb:
  case TPC::BIv_h8_sel2_grt_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch,
                    Intrinsic::tpc_sel2_grt);

  case TPC::BIv_f32_sel2_geq_f32_vb:
  case TPC::BIv_f32_sel2_geq_f32_b:
  case TPC::BIv_f32_sel2_geq_i32_vb:
  case TPC::BIv_f32_sel2_geq_i32_b:
  case TPC::BIv_f32_sel2_geq_u32_vb:
  case TPC::BIv_f32_sel2_geq_u32_b:
  case TPC::BIv_bf16_sel2_geq_bf16_b:
  case TPC::BIv_bf16_sel2_geq_bf16_vb:
  case TPC::BIv_bf16_sel2_geq_f16_b:
  case TPC::BIv_bf16_sel2_geq_f16_vb:
  case TPC::BIv_bf16_sel2_geq_i16_vb:
  case TPC::BIv_bf16_sel2_geq_i16_b:
  case TPC::BIv_bf16_sel2_geq_u16_vb:
  case TPC::BIv_bf16_sel2_geq_u16_b:
  case TPC::BIv_f16_sel2_geq_bf16_b:
  case TPC::BIv_f16_sel2_geq_bf16_vb:
  case TPC::BIv_f16_sel2_geq_f16_b:
  case TPC::BIv_f16_sel2_geq_f16_vb:
  case TPC::BIv_f16_sel2_geq_i16_vb:
  case TPC::BIv_f16_sel2_geq_i16_b:
  case TPC::BIv_f16_sel2_geq_u16_vb:
  case TPC::BIv_f16_sel2_geq_u16_b:
  case TPC::BIv_i32_sel2_geq_f32_vb:
  case TPC::BIv_i32_sel2_geq_f32_b:
  case TPC::BIv_i32_sel2_geq_i32_vb:
  case TPC::BIv_i32_sel2_geq_i32_b:
  case TPC::BIv_i32_sel2_geq_u32_vb:
  case TPC::BIv_i32_sel2_geq_u32_b:
  case TPC::BIv_u32_sel2_geq_f32_vb:
  case TPC::BIv_u32_sel2_geq_f32_b:
  case TPC::BIv_u32_sel2_geq_i32_vb:
  case TPC::BIv_u32_sel2_geq_i32_b:
  case TPC::BIv_u32_sel2_geq_u32_vb:
  case TPC::BIv_u32_sel2_geq_u32_b:
  case TPC::BIv_i16_sel2_geq_bf16_vb:
  case TPC::BIv_i16_sel2_geq_bf16_b:
  case TPC::BIv_i16_sel2_geq_f16_vb:
  case TPC::BIv_i16_sel2_geq_f16_b:
  case TPC::BIv_i16_sel2_geq_i16_vb:
  case TPC::BIv_i16_sel2_geq_i16_b:
  case TPC::BIv_i16_sel2_geq_u16_vb:
  case TPC::BIv_i16_sel2_geq_u16_b:
  case TPC::BIv_u16_sel2_geq_bf16_vb:
  case TPC::BIv_u16_sel2_geq_bf16_b:
  case TPC::BIv_u16_sel2_geq_f16_vb:
  case TPC::BIv_u16_sel2_geq_f16_b:
  case TPC::BIv_u16_sel2_geq_i16_vb:
  case TPC::BIv_u16_sel2_geq_i16_b:
  case TPC::BIv_u16_sel2_geq_u16_vb:
  case TPC::BIv_u16_sel2_geq_u16_b:
  case TPC::BIv_i8_sel2_geq_i8_vb:
  case TPC::BIv_i8_sel2_geq_i8_b:
  case TPC::BIv_i8_sel2_geq_u8_vb:
  case TPC::BIv_i8_sel2_geq_u8_b:
  case TPC::BIv_u8_sel2_geq_i8_vb:
  case TPC::BIv_u8_sel2_geq_i8_b:
  case TPC::BIv_u8_sel2_geq_u8_vb:
  case TPC::BIv_u8_sel2_geq_u8_b:
  // fp8
  case TPC::BIv_f8_sel2_geq_f8_b:
  case TPC::BIv_f8_sel2_geq_f8_vb:
  case TPC::BIv_f8_sel2_geq_h8_b:
  case TPC::BIv_f8_sel2_geq_h8_vb:
  case TPC::BIv_f8_sel2_geq_i8_vb:
  case TPC::BIv_f8_sel2_geq_i8_b:
  case TPC::BIv_f8_sel2_geq_u8_vb:
  case TPC::BIv_f8_sel2_geq_u8_b:
  case TPC::BIv_h8_sel2_geq_f8_b:
  case TPC::BIv_h8_sel2_geq_f8_vb:
  case TPC::BIv_h8_sel2_geq_h8_b:
  case TPC::BIv_h8_sel2_geq_h8_vb:
  case TPC::BIv_h8_sel2_geq_i8_vb:
  case TPC::BIv_h8_sel2_geq_i8_b:
  case TPC::BIv_h8_sel2_geq_u8_vb:
  case TPC::BIv_h8_sel2_geq_u8_b:
    return emit_SEL(CGF, BuiltinID, E, ReturnValue, Arch, Intrinsic::tpc_sel2_geq);

//------ Store slot --------------------------------------------------------

  case TPC::BIs_f32_st_l:
  case TPC::BIs_f16_st_l:
  case TPC::BIs_bf16_st_l:
  case TPC::BIs_h8_st_l:
  case TPC::BIs_f8_st_l:
  case TPC::BIs_i32_st_l:
  case TPC::BIs_u32_st_l:
  case TPC::BIs_i8_st_l:
  case TPC::BIs_i16_st_l:
  case TPC::BIs_u16_st_l:
  case TPC::BIs_u8_st_l:
  case TPC::BIs_i1_st_l:
    return emit_ST_L(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_st_g:
  case TPC::BIs_bf16_st_g:
  case TPC::BIs_f16_st_g:
  case TPC::BIs_i32_st_g:
  case TPC::BIs_u32_st_g:
  case TPC::BIs_i32_x2_st_g:
  case TPC::BIs_u32_x2_st_g:
  case TPC::BIs_i16_st_g:
  case TPC::BIs_u16_st_g:
    return emit_ST_G(CGF, BuiltinID, E, ReturnValue, Arch, true);
  case TPC::BIs_f8_st_g:
  case TPC::BIs_h8_st_g:
  case TPC::BIs_i8_st_g:
  case TPC::BIs_u8_st_g:
  case TPC::BIs_i1_st_g:
    return emit_ST_G(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIs_f32_st_g_inc:
  case TPC::BIs_bf16_st_g_inc:
  case TPC::BIs_f16_st_g_inc:
  case TPC::BIs_f8_st_g_inc:
  case TPC::BIs_h8_st_g_inc:
  case TPC::BIs_i32_st_g_inc:
  case TPC::BIs_u32_st_g_inc:
  case TPC::BIs_i32_x2_st_g_inc:
  case TPC::BIs_u32_x2_st_g_inc:
  case TPC::BIs_i16_st_g_inc:
  case TPC::BIs_u16_st_g_inc:
  case TPC::BIs_i8_st_g_inc:
  case TPC::BIs_u8_st_g_inc:
  case TPC::BIs_i1_st_g_inc:
    return emit_ST_G_INC(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_l_v:
  case TPC::BIv_bf16_st_l_v:
  case TPC::BIv_f16_st_l_v:
  case TPC::BIv_i32_st_l_v:
  case TPC::BIv_u32_st_l_v:
  case TPC::BIv_i16_st_l_v:
  case TPC::BIv_u16_st_l_v:
  case TPC::BIv_i8_st_l_v:
  case TPC::BIv_u8_st_l_v:
  case TPC::BIv_i1_st_l_v:
  case TPC::BIv_f8_st_l_v_b:
  case TPC::BIv_h8_st_l_v_b:
  case TPC::BIv_f32_st_l_v_vb:
  case TPC::BIv_bf16_st_l_v_vb:
  case TPC::BIv_f16_st_l_v_vb:
  case TPC::BIv_i32_st_l_v_vb:
  case TPC::BIv_u32_st_l_v_vb:
  case TPC::BIv_i16_st_l_v_vb:
  case TPC::BIv_u16_st_l_v_vb:
  case TPC::BIv_i8_st_l_v_vb:
  case TPC::BIv_u8_st_l_v_vb:
  case TPC::BIv_i1_st_l_v_vb:
  case TPC::BIv_f8_st_l_v_vb:
  case TPC::BIv_h8_st_l_v_vb:
    return emit_ST_L_V(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_l_v_low:
  case TPC::BIv_bf16_st_l_v_low:
  case TPC::BIv_f16_st_l_v_low:
  case TPC::BIv_i32_st_l_v_low:
  case TPC::BIv_u32_st_l_v_low:
  case TPC::BIv_i16_st_l_v_low:
  case TPC::BIv_u16_st_l_v_low:
  case TPC::BIv_i8_st_l_v_low:
  case TPC::BIv_u8_st_l_v_low:
  case TPC::BIv_i1_st_l_v_low:
  case TPC::BIv_f8_st_l_v_low_b:
  case TPC::BIv_h8_st_l_v_low_b:
  case TPC::BIv_f32_st_l_v_low_vb:
  case TPC::BIv_bf16_st_l_v_low_vb:
  case TPC::BIv_f16_st_l_v_low_vb:
  case TPC::BIv_i32_st_l_v_low_vb:
  case TPC::BIv_u32_st_l_v_low_vb:
  case TPC::BIv_i16_st_l_v_low_vb:
  case TPC::BIv_u16_st_l_v_low_vb:
  case TPC::BIv_i8_st_l_v_low_vb:
  case TPC::BIv_u8_st_l_v_low_vb:
  case TPC::BIv_i1_st_l_v_low_vb:
  case TPC::BIv_f8_st_l_v_low_vb:
  case TPC::BIv_h8_st_l_v_low_vb:
    return emit_ST_L_V_LOW(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_l_v_high:
  case TPC::BIv_bf16_st_l_v_high:
  case TPC::BIv_f16_st_l_v_high:
  case TPC::BIv_i32_st_l_v_high:
  case TPC::BIv_u32_st_l_v_high:
  case TPC::BIv_i16_st_l_v_high:
  case TPC::BIv_u16_st_l_v_high:
  case TPC::BIv_i8_st_l_v_high:
  case TPC::BIv_u8_st_l_v_high:
  case TPC::BIv_i1_st_l_v_high:
  case TPC::BIv_f8_st_l_v_high_b:
  case TPC::BIv_h8_st_l_v_high_b:
  case TPC::BIv_f32_st_l_v_high_vb:
  case TPC::BIv_bf16_st_l_v_high_vb:
  case TPC::BIv_f16_st_l_v_high_vb:
  case TPC::BIv_i32_st_l_v_high_vb:
  case TPC::BIv_u32_st_l_v_high_vb:
  case TPC::BIv_i16_st_l_v_high_vb:
  case TPC::BIv_u16_st_l_v_high_vb:
  case TPC::BIv_i8_st_l_v_high_vb:
  case TPC::BIv_u8_st_l_v_high_vb:
  case TPC::BIv_i1_st_l_v_high_vb:
  case TPC::BIv_f8_st_l_v_high_vb:
  case TPC::BIv_h8_st_l_v_high_vb:
    return emit_ST_L_V_HIGH(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIaso:
    return emit_ASO(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_tnsr:
  case TPC::BIv_bf16_st_tnsr:
  case TPC::BIv_f16_st_tnsr:
  case TPC::BIv_f8_st_tnsr:
  case TPC::BIv_h8_st_tnsr:
  case TPC::BIv_i32_st_tnsr:
  case TPC::BIv_u32_st_tnsr:
  case TPC::BIv_i16_st_tnsr:
  case TPC::BIv_u16_st_tnsr:
  case TPC::BIv_i8_st_tnsr:
  case TPC::BIv_u8_st_tnsr:
  case TPC::BIv_i1_st_tnsr:
  case TPC::BIv_f32_st_tnsr_rmw:
  case TPC::BIv_bf16_st_tnsr_rmw:
  case TPC::BIv_f16_st_tnsr_rmw:
  case TPC::BIv_i32_st_tnsr_rmw:
  case TPC::BIv_u32_st_tnsr_rmw:
  case TPC::BIv_i16_st_tnsr_rmw:
  case TPC::BIv_u16_st_tnsr_rmw:
  case TPC::BIv_i8_st_tnsr_rmw:
  case TPC::BIv_u8_st_tnsr_rmw:
  case TPC::BIv_h8_st_tnsr_rmw:
  case TPC::BIv_f32_st_tnsr_partial:
  case TPC::BIv_bf16_st_tnsr_partial:
  case TPC::BIv_f16_st_tnsr_partial:
  case TPC::BIv_f8_st_tnsr_partial:
  case TPC::BIv_h8_st_tnsr_partial:
  case TPC::BIv_i32_st_tnsr_partial:
  case TPC::BIv_u32_st_tnsr_partial:
  case TPC::BIv_i16_st_tnsr_partial:
  case TPC::BIv_u16_st_tnsr_partial:
  case TPC::BIv_i8_st_tnsr_partial:
  case TPC::BIv_u8_st_tnsr_partial:
  case TPC::BIv_i1_st_tnsr_partial:
  case TPC::BIv_f32_st_tnsr_partial_rmw:
  case TPC::BIv_bf16_st_tnsr_partial_rmw:
  case TPC::BIv_f16_st_tnsr_partial_rmw:
  case TPC::BIv_h8_st_tnsr_partial_rmw:
  case TPC::BIv_i32_st_tnsr_partial_rmw:
  case TPC::BIv_u32_st_tnsr_partial_rmw:
  case TPC::BIv_i16_st_tnsr_partial_rmw:
  case TPC::BIv_u16_st_tnsr_partial_rmw:
  case TPC::BIv_i8_st_tnsr_partial_rmw:
  case TPC::BIv_u8_st_tnsr_partial_rmw:
    return emit_ST_TNSR(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_tnsr_low:
  case TPC::BIv_bf16_st_tnsr_low:
  case TPC::BIv_f16_st_tnsr_low:
  case TPC::BIv_f8_st_tnsr_low:
  case TPC::BIv_h8_st_tnsr_low:
  case TPC::BIv_i32_st_tnsr_low:
  case TPC::BIv_u32_st_tnsr_low:
  case TPC::BIv_i16_st_tnsr_low:
  case TPC::BIv_u16_st_tnsr_low:
  case TPC::BIv_i8_st_tnsr_low:
  case TPC::BIv_u8_st_tnsr_low:
  case TPC::BIv_i1_st_tnsr_low:
  case TPC::BIv_f32_st_tnsr_low_rmw:
  case TPC::BIv_bf16_st_tnsr_low_rmw:
  case TPC::BIv_f16_st_tnsr_low_rmw:
  case TPC::BIv_h8_st_tnsr_low_rmw:
  case TPC::BIv_i32_st_tnsr_low_rmw:
  case TPC::BIv_u32_st_tnsr_low_rmw:
  case TPC::BIv_i16_st_tnsr_low_rmw:
  case TPC::BIv_u16_st_tnsr_low_rmw:
  case TPC::BIv_i8_st_tnsr_low_rmw:
  case TPC::BIv_u8_st_tnsr_low_rmw:
    return emit_ST_TNSR_LOW(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_tnsr_high:
  case TPC::BIv_bf16_st_tnsr_high:
  case TPC::BIv_f16_st_tnsr_high:
  case TPC::BIv_f8_st_tnsr_high:
  case TPC::BIv_h8_st_tnsr_high:
  case TPC::BIv_i32_st_tnsr_high:
  case TPC::BIv_u32_st_tnsr_high:
  case TPC::BIv_i16_st_tnsr_high:
  case TPC::BIv_u16_st_tnsr_high:
  case TPC::BIv_i8_st_tnsr_high:
  case TPC::BIv_u8_st_tnsr_high:
  case TPC::BIv_i1_st_tnsr_high:
  case TPC::BIv_f32_st_tnsr_high_rmw:
  case TPC::BIv_bf16_st_tnsr_high_rmw:
  case TPC::BIv_f16_st_tnsr_high_rmw:
  case TPC::BIv_h8_st_tnsr_high_rmw:
  case TPC::BIv_i32_st_tnsr_high_rmw:
  case TPC::BIv_u32_st_tnsr_high_rmw:
  case TPC::BIv_i16_st_tnsr_high_rmw:
  case TPC::BIv_u16_st_tnsr_high_rmw:
  case TPC::BIv_i8_st_tnsr_high_rmw:
  case TPC::BIv_u8_st_tnsr_high_rmw:
    return emit_ST_TNSR_HIGH(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIv_f32_st_tnsr_direct:
  case TPC::BIv_bf16_st_tnsr_direct:
  case TPC::BIv_f16_st_tnsr_direct: 
  case TPC::BIv_f8_st_tnsr_direct:
  case TPC::BIv_h8_st_tnsr_direct:
  case TPC::BIv_i32_st_tnsr_direct: 
  case TPC::BIv_u32_st_tnsr_direct: 
  case TPC::BIv_i16_st_tnsr_direct: 
  case TPC::BIv_u16_st_tnsr_direct: 
  case TPC::BIv_i8_st_tnsr_direct:
  case TPC::BIv_u8_st_tnsr_direct:
  case TPC::BIv_i1_st_tnsr_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_direct, false, false);

  case TPC::BIv_f32_st_tnsr_partial_direct: 
  case TPC::BIv_bf16_st_tnsr_partial_direct:
  case TPC::BIv_f16_st_tnsr_partial_direct: 
  case TPC::BIv_f8_st_tnsr_partial_direct:
  case TPC::BIv_h8_st_tnsr_partial_direct:
  case TPC::BIv_i32_st_tnsr_partial_direct: 
  case TPC::BIv_u32_st_tnsr_partial_direct: 
  case TPC::BIv_i16_st_tnsr_partial_direct: 
  case TPC::BIv_u16_st_tnsr_partial_direct: 
  case TPC::BIv_i8_st_tnsr_partial_direct:
  case TPC::BIv_u8_st_tnsr_partial_direct:
  case TPC::BIv_i1_st_tnsr_partial_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_partial_direct, true, false);

  case TPC::BIv_f32_st_tnsr_rmw_direct: 
  case TPC::BIv_bf16_st_tnsr_rmw_direct:
  case TPC::BIv_f16_st_tnsr_rmw_direct:
  case TPC::BIv_h8_st_tnsr_rmw_direct:
  case TPC::BIv_i32_st_tnsr_rmw_direct: 
  case TPC::BIv_u32_st_tnsr_rmw_direct: 
  case TPC::BIv_i16_st_tnsr_rmw_direct: 
  case TPC::BIv_u16_st_tnsr_rmw_direct: 
  case TPC::BIv_i8_st_tnsr_rmw_direct:
  case TPC::BIv_u8_st_tnsr_rmw_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_rmw_direct, false, true);

  case TPC::BIv_f32_st_tnsr_partial_rmw_direct: 
  case TPC::BIv_bf16_st_tnsr_partial_rmw_direct:
  case TPC::BIv_f16_st_tnsr_partial_rmw_direct: 
  case TPC::BIv_h8_st_tnsr_partial_rmw_direct:
  case TPC::BIv_i32_st_tnsr_partial_rmw_direct: 
  case TPC::BIv_u32_st_tnsr_partial_rmw_direct: 
  case TPC::BIv_i16_st_tnsr_partial_rmw_direct: 
  case TPC::BIv_u16_st_tnsr_partial_rmw_direct: 
  case TPC::BIv_i8_st_tnsr_partial_rmw_direct:
  case TPC::BIv_u8_st_tnsr_partial_rmw_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_partial_rmw_direct, true, true);

  case TPC::BIv_f32_st_tnsr_high_direct: 
  case TPC::BIv_bf16_st_tnsr_high_direct:
  case TPC::BIv_f16_st_tnsr_high_direct: 
  case TPC::BIv_f8_st_tnsr_high_direct:
  case TPC::BIv_h8_st_tnsr_high_direct:
  case TPC::BIv_i32_st_tnsr_high_direct: 
  case TPC::BIv_u32_st_tnsr_high_direct: 
  case TPC::BIv_i16_st_tnsr_high_direct: 
  case TPC::BIv_u16_st_tnsr_high_direct: 
  case TPC::BIv_i8_st_tnsr_high_direct:
  case TPC::BIv_u8_st_tnsr_high_direct:
  case TPC::BIv_i1_st_tnsr_high_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_high_direct, false, false);

  case TPC::BIv_f32_st_tnsr_high_rmw_direct: 
  case TPC::BIv_bf16_st_tnsr_high_rmw_direct:
  case TPC::BIv_f16_st_tnsr_high_rmw_direct: 
  case TPC::BIv_h8_st_tnsr_high_rmw_direct:
  case TPC::BIv_i32_st_tnsr_high_rmw_direct: 
  case TPC::BIv_u32_st_tnsr_high_rmw_direct: 
  case TPC::BIv_i16_st_tnsr_high_rmw_direct: 
  case TPC::BIv_u16_st_tnsr_high_rmw_direct: 
  case TPC::BIv_i8_st_tnsr_high_rmw_direct:
  case TPC::BIv_u8_st_tnsr_high_rmw_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_high_rmw_direct, false, true);

  case TPC::BIv_f32_st_tnsr_low_direct: 
  case TPC::BIv_bf16_st_tnsr_low_direct:
  case TPC::BIv_f16_st_tnsr_low_direct: 
  case TPC::BIv_f8_st_tnsr_low_direct:
  case TPC::BIv_h8_st_tnsr_low_direct:
  case TPC::BIv_i32_st_tnsr_low_direct: 
  case TPC::BIv_u32_st_tnsr_low_direct: 
  case TPC::BIv_i16_st_tnsr_low_direct: 
  case TPC::BIv_u16_st_tnsr_low_direct: 
  case TPC::BIv_i8_st_tnsr_low_direct:
  case TPC::BIv_u8_st_tnsr_low_direct:
  case TPC::BIv_i1_st_tnsr_low_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_low_direct, false, false);

  case TPC::BIv_f32_st_tnsr_low_rmw_direct: 
  case TPC::BIv_bf16_st_tnsr_low_rmw_direct:
  case TPC::BIv_f16_st_tnsr_low_rmw_direct: 
  case TPC::BIv_h8_st_tnsr_low_rmw_direct:
  case TPC::BIv_i32_st_tnsr_low_rmw_direct: 
  case TPC::BIv_u32_st_tnsr_low_rmw_direct: 
  case TPC::BIv_i16_st_tnsr_low_rmw_direct: 
  case TPC::BIv_u16_st_tnsr_low_rmw_direct: 
  case TPC::BIv_i8_st_tnsr_low_rmw_direct:
  case TPC::BIv_u8_st_tnsr_low_rmw_direct:
    return emit_ST_TNSR_DIRECT(CGF, BuiltinID, E, Arch, Intrinsic::tpc_st_tnsr_low_rmw_direct, false, true);

  case TPC::BIv_f32_st_tnsr_sqz:
  case TPC::BIv_i32_st_tnsr_sqz:
  case TPC::BIv_u32_st_tnsr_sqz:
  case TPC::BIv_f32_st_tnsr_sqz_rmw:
  case TPC::BIv_i32_st_tnsr_sqz_rmw:
  case TPC::BIv_u32_st_tnsr_sqz_rmw:
    return emit_ST_TNSR_SQZ(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIreset_sqz_cntr:
    return emit_reset_sqz_cntr(CGF, BuiltinID, E, Arch);

  case TPC::BIs_f32_st_tnsr_s:
  case TPC::BIs_bf16_st_tnsr_s:
  case TPC::BIs_f16_st_tnsr_s:
  case TPC::BIs_f8_st_tnsr_s:
  case TPC::BIs_h8_st_tnsr_s:
  case TPC::BIs_i32_st_tnsr_s:
  case TPC::BIs_u32_st_tnsr_s:
  case TPC::BIs_i16_st_tnsr_s:
  case TPC::BIs_u16_st_tnsr_s:
  case TPC::BIs_i8_st_tnsr_s:
  case TPC::BIs_u8_st_tnsr_s:
  case TPC::BIs_f32_st_tnsr_s_rmw:
  case TPC::BIs_bf16_st_tnsr_s_rmw:
  case TPC::BIs_f16_st_tnsr_s_rmw:
  case TPC::BIs_h8_st_tnsr_s_rmw:
  case TPC::BIs_i32_st_tnsr_s_rmw:
  case TPC::BIs_u32_st_tnsr_s_rmw:
  case TPC::BIs_i16_st_tnsr_s_rmw:
  case TPC::BIs_u16_st_tnsr_s_rmw:
  case TPC::BIs_i8_st_tnsr_s_rmw:
  case TPC::BIs_u8_st_tnsr_s_rmw:
  case TPC::BIst_tnsr_s_hwr:
  case TPC::BIst_tnsr_s_hwr_rmw:
    return emit_ST_TNSR_S(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIcache_flush:
    return emit_CACHE_FLUSH(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIcache_invalidate:
    return emit_CACHE_INVALIDATE(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIcache_flush_addr:
  case TPC::BIcache_invalidate_addr :
    return emit_CACHE_FLUSH_INVALIDATE(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIconvert_int64_to_float64:
  case TPC::BIconvert_uint64_to_float64:
  case TPC::BIconvert_bfloat128_to_float128:
  case TPC::BIconvert_half128_to_float128:
  case TPC::BIconvert_int128_to_float128:
  case TPC::BIconvert_uint128_to_float128:
  case TPC::BIconvert_short128_to_float128:
  case TPC::BIconvert_ushort128_to_float128:
  case TPC::BIconvert_bfloat256_to_float256:
  case TPC::BIconvert_half256_to_float256:
  case TPC::BIconvert_minifloat256_to_float256:
  case TPC::BIconvert_minihalf256_to_float256:
  case TPC::BIconvert_int256_to_float256:
  case TPC::BIconvert_uint256_to_float256:
  case TPC::BIconvert_short256_to_float256:
  case TPC::BIconvert_ushort256_to_float256:
  case TPC::BIconvert_char256_to_float256:
  case TPC::BIconvert_uchar256_to_float256:
  case TPC::BIconvert_float128_to_bfloat128:
  case TPC::BIconvert_half128_to_bfloat128:
  case TPC::BIconvert_int128_to_bfloat128:
  case TPC::BIconvert_uint128_to_bfloat128:
  case TPC::BIconvert_short128_to_bfloat128:
  case TPC::BIconvert_ushort128_to_bfloat128:
  case TPC::BIconvert_float256_to_bfloat256:
  case TPC::BIconvert_half256_to_bfloat256:
  case TPC::BIconvert_minifloat256_to_bfloat256:
  case TPC::BIconvert_minihalf256_to_bfloat256:
  case TPC::BIconvert_int256_to_bfloat256:
  case TPC::BIconvert_uint256_to_bfloat256:
  case TPC::BIconvert_short256_to_bfloat256:
  case TPC::BIconvert_ushort256_to_bfloat256:
  case TPC::BIconvert_char256_to_bfloat256:
  case TPC::BIconvert_uchar256_to_bfloat256:
  case TPC::BIconvert_float128_to_half128:
  case TPC::BIconvert_bfloat128_to_half128:
  case TPC::BIconvert_int128_to_half128:
  case TPC::BIconvert_uint128_to_half128:
  case TPC::BIconvert_short128_to_half128:
  case TPC::BIconvert_ushort128_to_half128:
  case TPC::BIconvert_float256_to_half256:
  case TPC::BIconvert_bfloat256_to_half256:
  case TPC::BIconvert_minifloat256_to_half256:
  case TPC::BIconvert_minihalf256_to_half256:
  case TPC::BIconvert_int256_to_half256:
  case TPC::BIconvert_uint256_to_half256:
  case TPC::BIconvert_short256_to_half256:
  case TPC::BIconvert_ushort256_to_half256:

  case TPC::BIconvert_char256_to_half256:
  case TPC::BIconvert_uchar256_to_half256:
  case TPC::BIconvert_float256_to_minifloat256:
  case TPC::BIconvert_bfloat256_to_minifloat256:
  case TPC::BIconvert_half256_to_minifloat256:
  case TPC::BIconvert_minihalf256_to_minifloat256:
  case TPC::BIconvert_char256_to_minifloat256:
  case TPC::BIconvert_uchar256_to_minifloat256:
  case TPC::BIconvert_minihalf512_to_minifloat512:
  case TPC::BIconvert_char512_to_minifloat512:
  case TPC::BIconvert_uchar512_to_minifloat512:
  case TPC::BIconvert_float256_to_minihalf256:
  case TPC::BIconvert_bfloat256_to_minihalf256:
  case TPC::BIconvert_half256_to_minihalf256:
  case TPC::BIconvert_minifloat256_to_minihalf256:
  case TPC::BIconvert_char256_to_minihalf256:
  case TPC::BIconvert_uchar256_to_minihalf256:

  case TPC::BIconvert_short256_to_minihalf256:
  case TPC::BIconvert_ushort256_to_minihalf256:
  case TPC::BIconvert_short256_to_minifloat256:
  case TPC::BIconvert_ushort256_to_minifloat256:

  case TPC::BIconvert_int256_to_minihalf256:
  case TPC::BIconvert_uint256_to_minihalf256:
  case TPC::BIconvert_int256_to_minifloat256:
  case TPC::BIconvert_uint256_to_minifloat256:

  case TPC::BIconvert_minifloat512_to_minihalf512:
  case TPC::BIconvert_char512_to_minihalf512:
  case TPC::BIconvert_uchar512_to_minihalf512:
  case TPC::BIconvert_float64_to_int64:
  case TPC::BIconvert_uint64_to_int64:
  case TPC::BIconvert_float128_to_int128:
  case TPC::BIconvert_bfloat128_to_int128:
  case TPC::BIconvert_half128_to_int128:
  case TPC::BIconvert_uint128_to_int128:
  case TPC::BIconvert_short128_to_int128:
  case TPC::BIconvert_ushort128_to_int128:
  case TPC::BIconvert_float256_to_int256:
  case TPC::BIconvert_bfloat256_to_int256:
  case TPC::BIconvert_half256_to_int256:
  case TPC::BIconvert_minifloat256_to_int256:
  case TPC::BIconvert_minihalf256_to_int256:
  case TPC::BIconvert_uint256_to_int256:
  case TPC::BIconvert_short256_to_int256:
  case TPC::BIconvert_ushort256_to_int256:
  case TPC::BIconvert_char256_to_int256:
  case TPC::BIconvert_uchar256_to_int256:
  case TPC::BIconvert_float64_to_uint64:
  case TPC::BIconvert_int64_to_uint64:
  case TPC::BIconvert_float128_to_uint128:
  case TPC::BIconvert_bfloat128_to_uint128:
  case TPC::BIconvert_half128_to_uint128:
  case TPC::BIconvert_int128_to_uint128:
  case TPC::BIconvert_short128_to_uint128:
  case TPC::BIconvert_ushort128_to_uint128:
  case TPC::BIconvert_float256_to_uint256:
  case TPC::BIconvert_bfloat256_to_uint256:
  case TPC::BIconvert_half256_to_uint256:
  case TPC::BIconvert_minifloat256_to_uint256:
  case TPC::BIconvert_minihalf256_to_uint256:
  case TPC::BIconvert_int256_to_uint256:
  case TPC::BIconvert_short256_to_uint256:
  case TPC::BIconvert_ushort256_to_uint256:
  case TPC::BIconvert_char256_to_uint256:
  case TPC::BIconvert_uchar256_to_uint256:
  case TPC::BIconvert_float128_to_short128:
  case TPC::BIconvert_bfloat128_to_short128:
  case TPC::BIconvert_half128_to_short128:
  case TPC::BIconvert_int128_to_short128:
  case TPC::BIconvert_uint128_to_short128:
  case TPC::BIconvert_ushort128_to_short128:
  case TPC::BIconvert_float256_to_short256:
  case TPC::BIconvert_bfloat256_to_short256:
  case TPC::BIconvert_half256_to_short256:
  case TPC::BIconvert_minifloat256_to_short256:
  case TPC::BIconvert_minihalf256_to_short256:
  case TPC::BIconvert_int256_to_short256:
  case TPC::BIconvert_uint256_to_short256:
  case TPC::BIconvert_ushort256_to_short256:
  case TPC::BIconvert_char256_to_short256:
  case TPC::BIconvert_uchar256_to_short256:
  case TPC::BIconvert_float128_to_ushort128:
  case TPC::BIconvert_bfloat128_to_ushort128:
  case TPC::BIconvert_half128_to_ushort128:
  case TPC::BIconvert_int128_to_ushort128:
  case TPC::BIconvert_uint128_to_ushort128:
  case TPC::BIconvert_short128_to_ushort128:
  case TPC::BIconvert_float256_to_ushort256:
  case TPC::BIconvert_bfloat256_to_ushort256:
  case TPC::BIconvert_half256_to_ushort256:
  case TPC::BIconvert_minifloat256_to_ushort256:
  case TPC::BIconvert_minihalf256_to_ushort256:
  case TPC::BIconvert_int256_to_ushort256:
  case TPC::BIconvert_uint256_to_ushort256:
  case TPC::BIconvert_short256_to_ushort256:
  case TPC::BIconvert_char256_to_ushort256:
  case TPC::BIconvert_uchar256_to_ushort256:
  case TPC::BIconvert_float256_to_char256:
  case TPC::BIconvert_bfloat256_to_char256:
  case TPC::BIconvert_half256_to_char256:
  case TPC::BIconvert_minifloat256_to_char256:
  case TPC::BIconvert_minihalf256_to_char256:
  case TPC::BIconvert_int256_to_char256:
  case TPC::BIconvert_uint256_to_char256:
  case TPC::BIconvert_short256_to_char256:
  case TPC::BIconvert_ushort256_to_char256:
  case TPC::BIconvert_uchar256_to_char256:
  case TPC::BIconvert_float256_to_uchar256:
  case TPC::BIconvert_bfloat256_to_uchar256:
  case TPC::BIconvert_half256_to_uchar256:
  case TPC::BIconvert_minifloat256_to_uchar256:
  case TPC::BIconvert_minihalf256_to_uchar256:
  case TPC::BIconvert_int256_to_uchar256:
  case TPC::BIconvert_uint256_to_uchar256:
  case TPC::BIconvert_short256_to_uchar256:
  case TPC::BIconvert_ushort256_to_uchar256:
  case TPC::BIconvert_char256_to_uchar256:
    return emit_CONVERT_TO(CGF, BuiltinID, E, ReturnValue, Arch);

  case TPC::BIint_convert_short256_to_char256:
  case TPC::BIint_convert_int256_to_char256:
  case TPC::BIint_convert_int128_to_short128:
    return emit_INT_CONVERT_TO(CGF, BuiltinID, E, ReturnValue, Arch, false);
  case TPC::BIuint_convert_ushort256_to_uchar256:
  case TPC::BIuint_convert_uint256_to_uchar256:
  case TPC::BIuint_convert_uint128_to_ushort128:
    return emit_INT_CONVERT_TO(CGF, BuiltinID, E, ReturnValue, Arch, true);
    

  case TPC::BIread_lfsr_b:
  case TPC::BIread_lfsr_vb:
    return emit_READ_LFSR(CGF, BuiltinID, E, ReturnValue, Arch);
    
  case TPC::BIwrite_lfsr_b:
  case TPC::BIwrite_lfsr_vb: {
    Value *Predicate = emitPredicate(CGF, E->getArg(1));
    return CGF->Builder.CreateCall(
        CGF->CGM.getIntrinsic(Intrinsic::tpc_write_lfsr, {Predicate->getType()}),
        { emitOperand(CGF, E->getArg(0)),
          Predicate,
          CGF->EvaluateExprAsBool(E->getArg(2))});
  }
    
  case TPC::BIs_read_lfsr:
    return emit_S_READ_LFSR(CGF, BuiltinID, E, ReturnValue, Arch);
    
  case TPC::BIwrite_lfsr_s:
    return CGF->Builder.CreateCall(
        CGF->CGM.getIntrinsic(Intrinsic::tpc_write_lfsr_s),
        { emitOperand(CGF, E->getArg(0)),
          emitPredicate(CGF, E->getArg(1)),
          CGF->EvaluateExprAsBool(E->getArg(2))});
  
  case TPC::BIread_lane_id_4b_b:
  case TPC::BIread_lane_id_4b_vb:
  case TPC::BIread_lane_id_2b_b:
  case TPC::BIread_lane_id_2b_vb:
  case TPC::BIread_lane_id_1b_b:
  case TPC::BIread_lane_id_1b_vb:
    return emit_READ_LANE_ID(CGF, BuiltinID, E, ReturnValue, Arch);

    // MMIO access intrinsics.
  case TPC::BIget_dim_size:
    return emit_GET_DIM_SIZE(*CGF, *E);
  case TPC::BIset_dim_size:
    return emit_SET_DIM_SIZE(*CGF, *E);
  case TPC::BIget_dim_stride:
    return emit_GET_DIM_STRIDE(*CGF, *E);
  case TPC::BIset_dim_stride:
    return emit_SET_DIM_STRIDE(*CGF, *E);
  case TPC::BIget_pad_value_uint:
  case TPC::BIget_pad_value_int:
  case TPC::BIget_pad_value_float:
  case TPC::BIget_pad_value_bf16:
  case TPC::BIget_pad_value_ushort:
  case TPC::BIget_pad_value_short:
  case TPC::BIget_pad_value_uchar:
  case TPC::BIget_pad_value_char:
    return emit_GET_PAD_VALUE(*CGF, *E);
  case TPC::BIset_pad_value_uint:
  case TPC::BIset_pad_value_int:
  case TPC::BIset_pad_value_float:
  case TPC::BIset_pad_value_bf16:
  case TPC::BIset_pad_value_ushort:
  case TPC::BIset_pad_value_short:
  case TPC::BIset_pad_value_uchar:
  case TPC::BIset_pad_value_char:
    return emit_SET_PAD_VALUE(*CGF, *E);
  case TPC::BIget_tensor_hwpref_stride:
    return emit_GET_TENSOR_HWPREF_STRIDE(*CGF, *E);
  case TPC::BIset_tensor_hwpref_stride:
    return emit_SET_TENSOR_HWPREF_STRIDE(*CGF, *E);
  case TPC::BIget_semaphore_value:
    return emit_GET_SEMAPHORE_VALUE(*CGF, *E);
  case TPC::BIset_semaphore_value:
    return emit_SET_SEMAPHORE_VALUE(*CGF, *E);
  case TPC::BIget_csr_value:
    return emit_GET_CSR_VALUE(*CGF, *E);
  case TPC::BIset_csr_value:
    return emit_SET_CSR_VALUE(*CGF, *E);
  case TPC::BIget_convert_csr_value:
    return emit_GET_CONVERT_CSR_VALUE(*CGF, *E);
  case TPC::BIset_convert_csr_value:
    return emit_SET_CONVERT_CSR_VALUE(*CGF, *E);

  }
}
